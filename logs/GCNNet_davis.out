cuda_name: cuda:0
Learning rate:  0.0005
Epochs:  1000

running on  GCNNet_davis
Pre-processed data found: data/processed/davis_train.pt, loading ...
Pre-processed data found: data/processed/davis_test.pt, loading ...
Device:  cuda:0 cuda name: cuda:0
Training on 25046 samples...
Train epoch: 1 [0/25046 (0%)]	Loss: 30.248755
Train epoch: 1 [330140/25046 (41%)]	Loss: 1.489485
Train epoch: 1 [656800/25046 (82%)]	Loss: 0.973260
Make prediction for 5010 samples...
rmse improved at epoch  1 ; best_mse,best_ci: 0.7487627 0.6252188360000018 GCNNet davis
Training on 25046 samples...
Train epoch: 2 [0/25046 (0%)]	Loss: 0.798279
Train epoch: 2 [331100/25046 (41%)]	Loss: 1.037309
Train epoch: 2 [652080/25046 (82%)]	Loss: 0.666427
Make prediction for 5010 samples...
rmse improved at epoch  2 ; best_mse,best_ci: 0.7152879 0.672517429920791 GCNNet davis
Training on 25046 samples...
Train epoch: 3 [0/25046 (0%)]	Loss: 0.687939
Train epoch: 3 [331340/25046 (41%)]	Loss: 0.816353
Train epoch: 3 [662400/25046 (82%)]	Loss: 0.729317
Make prediction for 5010 samples...
rmse improved at epoch  3 ; best_mse,best_ci: 0.65261585 0.7312090498516487 GCNNet davis
Training on 25046 samples...
Train epoch: 4 [0/25046 (0%)]	Loss: 0.821403
Train epoch: 4 [330500/25046 (41%)]	Loss: 0.713373
Train epoch: 4 [655800/25046 (82%)]	Loss: 0.690353
Make prediction for 5010 samples...
0.66458976 No improvement since epoch  3 ; best_mse,best_ci: 0.65261585 0.7312090498516487 GCNNet davis
Training on 25046 samples...
Train epoch: 5 [0/25046 (0%)]	Loss: 0.717143
Train epoch: 5 [327180/25046 (41%)]	Loss: 0.831699
Train epoch: 5 [643920/25046 (82%)]	Loss: 0.664838
Make prediction for 5010 samples...
rmse improved at epoch  5 ; best_mse,best_ci: 0.58961713 0.7772161074322993 GCNNet davis
Training on 25046 samples...
Train epoch: 6 [0/25046 (0%)]	Loss: 0.611961
Train epoch: 6 [327860/25046 (41%)]	Loss: 0.664607
Train epoch: 6 [649960/25046 (82%)]	Loss: 0.661257
Make prediction for 5010 samples...
rmse improved at epoch  6 ; best_mse,best_ci: 0.57540244 0.7849876091844422 GCNNet davis
Training on 25046 samples...
Train epoch: 7 [0/25046 (0%)]	Loss: 0.554197
Train epoch: 7 [331640/25046 (41%)]	Loss: 0.552827
Train epoch: 7 [661000/25046 (82%)]	Loss: 0.642819
Make prediction for 5010 samples...
0.6346809 No improvement since epoch  6 ; best_mse,best_ci: 0.57540244 0.7849876091844422 GCNNet davis
Training on 25046 samples...
Train epoch: 8 [0/25046 (0%)]	Loss: 0.686217
Train epoch: 8 [330260/25046 (41%)]	Loss: 0.655413
Train epoch: 8 [662240/25046 (82%)]	Loss: 0.576054
Make prediction for 5010 samples...
rmse improved at epoch  8 ; best_mse,best_ci: 0.55698425 0.7893639463028413 GCNNet davis
Training on 25046 samples...
Train epoch: 9 [0/25046 (0%)]	Loss: 0.669219
Train epoch: 9 [330800/25046 (41%)]	Loss: 0.612025
Train epoch: 9 [652160/25046 (82%)]	Loss: 0.658575
Make prediction for 5010 samples...
rmse improved at epoch  9 ; best_mse,best_ci: 0.55689853 0.7877448164335249 GCNNet davis
Training on 25046 samples...
Train epoch: 10 [0/25046 (0%)]	Loss: 0.652649
Train epoch: 10 [333180/25046 (41%)]	Loss: 0.635540
Train epoch: 10 [655880/25046 (82%)]	Loss: 0.592182
Make prediction for 5010 samples...
0.57739085 No improvement since epoch  9 ; best_mse,best_ci: 0.55689853 0.7877448164335249 GCNNet davis
Training on 25046 samples...
Train epoch: 11 [0/25046 (0%)]	Loss: 0.481972
Train epoch: 11 [330200/25046 (41%)]	Loss: 0.704232
Train epoch: 11 [653360/25046 (82%)]	Loss: 0.512123
Make prediction for 5010 samples...
rmse improved at epoch  11 ; best_mse,best_ci: 0.53689283 0.7946360733006985 GCNNet davis
Training on 25046 samples...
Train epoch: 12 [0/25046 (0%)]	Loss: 0.587927
Train epoch: 12 [326640/25046 (41%)]	Loss: 0.436926
Train epoch: 12 [658400/25046 (82%)]	Loss: 0.565000
Make prediction for 5010 samples...
rmse improved at epoch  12 ; best_mse,best_ci: 0.53525716 0.7999117228096222 GCNNet davis
Training on 25046 samples...
Train epoch: 13 [0/25046 (0%)]	Loss: 0.606423
Train epoch: 13 [330400/25046 (41%)]	Loss: 0.622158
Train epoch: 13 [665400/25046 (82%)]	Loss: 0.604879
Make prediction for 5010 samples...
rmse improved at epoch  13 ; best_mse,best_ci: 0.5286432 0.7963425001834004 GCNNet davis
Training on 25046 samples...
Train epoch: 14 [0/25046 (0%)]	Loss: 0.471126
Train epoch: 14 [327020/25046 (41%)]	Loss: 0.647367
Train epoch: 14 [664520/25046 (82%)]	Loss: 0.523442
Make prediction for 5010 samples...
0.6309976 No improvement since epoch  13 ; best_mse,best_ci: 0.5286432 0.7963425001834004 GCNNet davis
Training on 25046 samples...
Train epoch: 15 [0/25046 (0%)]	Loss: 0.631373
Train epoch: 15 [326540/25046 (41%)]	Loss: 0.599269
Train epoch: 15 [657240/25046 (82%)]	Loss: 0.657547
Make prediction for 5010 samples...
0.54775906 No improvement since epoch  13 ; best_mse,best_ci: 0.5286432 0.7963425001834004 GCNNet davis
Training on 25046 samples...
Train epoch: 16 [0/25046 (0%)]	Loss: 0.507984
Train epoch: 16 [328720/25046 (41%)]	Loss: 0.595079
Train epoch: 16 [653480/25046 (82%)]	Loss: 0.494675
Make prediction for 5010 samples...
0.59962124 No improvement since epoch  13 ; best_mse,best_ci: 0.5286432 0.7963425001834004 GCNNet davis
Training on 25046 samples...
Train epoch: 17 [0/25046 (0%)]	Loss: 0.518455
Train epoch: 17 [326400/25046 (41%)]	Loss: 0.513345
Train epoch: 17 [668120/25046 (82%)]	Loss: 0.503843
Make prediction for 5010 samples...
0.53621227 No improvement since epoch  13 ; best_mse,best_ci: 0.5286432 0.7963425001834004 GCNNet davis
Training on 25046 samples...
Train epoch: 18 [0/25046 (0%)]	Loss: 0.488908
Train epoch: 18 [330320/25046 (41%)]	Loss: 0.643265
Train epoch: 18 [654920/25046 (82%)]	Loss: 0.655530
Make prediction for 5010 samples...
0.5449944 No improvement since epoch  13 ; best_mse,best_ci: 0.5286432 0.7963425001834004 GCNNet davis
Training on 25046 samples...
Train epoch: 19 [0/25046 (0%)]	Loss: 0.632063
Train epoch: 19 [329260/25046 (41%)]	Loss: 0.502764
Train epoch: 19 [671280/25046 (82%)]	Loss: 0.567465
Make prediction for 5010 samples...
rmse improved at epoch  19 ; best_mse,best_ci: 0.506169 0.8006163015992354 GCNNet davis
Training on 25046 samples...
Train epoch: 20 [0/25046 (0%)]	Loss: 0.554598
Train epoch: 20 [328700/25046 (41%)]	Loss: 0.580963
Train epoch: 20 [663480/25046 (82%)]	Loss: 0.579962
Make prediction for 5010 samples...
0.50841856 No improvement since epoch  19 ; best_mse,best_ci: 0.506169 0.8006163015992354 GCNNet davis
Training on 25046 samples...
Train epoch: 21 [0/25046 (0%)]	Loss: 0.443060
Train epoch: 21 [330300/25046 (41%)]	Loss: 0.560314
Train epoch: 21 [657520/25046 (82%)]	Loss: 0.552994
Make prediction for 5010 samples...
rmse improved at epoch  21 ; best_mse,best_ci: 0.49535894 0.8034875310000118 GCNNet davis
Training on 25046 samples...
Train epoch: 22 [0/25046 (0%)]	Loss: 0.585585
Train epoch: 22 [327480/25046 (41%)]	Loss: 0.481589
Train epoch: 22 [655880/25046 (82%)]	Loss: 0.620061
Make prediction for 5010 samples...
rmse improved at epoch  22 ; best_mse,best_ci: 0.4903625 0.8080326423442893 GCNNet davis
Training on 25046 samples...
Train epoch: 23 [0/25046 (0%)]	Loss: 0.458915
Train epoch: 23 [327020/25046 (41%)]	Loss: 0.420216
Train epoch: 23 [659720/25046 (82%)]	Loss: 0.537433
Make prediction for 5010 samples...
0.5137056 No improvement since epoch  22 ; best_mse,best_ci: 0.4903625 0.8080326423442893 GCNNet davis
Training on 25046 samples...
Train epoch: 24 [0/25046 (0%)]	Loss: 0.528426
Train epoch: 24 [329420/25046 (41%)]	Loss: 0.536808
Train epoch: 24 [662280/25046 (82%)]	Loss: 0.506458
Make prediction for 5010 samples...
0.49529076 No improvement since epoch  22 ; best_mse,best_ci: 0.4903625 0.8080326423442893 GCNNet davis
Training on 25046 samples...
Train epoch: 25 [0/25046 (0%)]	Loss: 0.518302
Train epoch: 25 [329240/25046 (41%)]	Loss: 0.752145
Train epoch: 25 [661360/25046 (82%)]	Loss: 0.592086
Make prediction for 5010 samples...
0.5095999 No improvement since epoch  22 ; best_mse,best_ci: 0.4903625 0.8080326423442893 GCNNet davis
Training on 25046 samples...
Train epoch: 26 [0/25046 (0%)]	Loss: 0.544894
Train epoch: 26 [327040/25046 (41%)]	Loss: 0.435562
Train epoch: 26 [660080/25046 (82%)]	Loss: 0.537222
Make prediction for 5010 samples...
0.51017505 No improvement since epoch  22 ; best_mse,best_ci: 0.4903625 0.8080326423442893 GCNNet davis
Training on 25046 samples...
Train epoch: 27 [0/25046 (0%)]	Loss: 0.511633
Train epoch: 27 [329080/25046 (41%)]	Loss: 0.517408
Train epoch: 27 [653120/25046 (82%)]	Loss: 0.465905
Make prediction for 5010 samples...
rmse improved at epoch  27 ; best_mse,best_ci: 0.4752822 0.8132558370688542 GCNNet davis
Training on 25046 samples...
Train epoch: 28 [0/25046 (0%)]	Loss: 0.429412
Train epoch: 28 [326080/25046 (41%)]	Loss: 0.480755
Train epoch: 28 [650120/25046 (82%)]	Loss: 0.441542
Make prediction for 5010 samples...
0.58708346 No improvement since epoch  27 ; best_mse,best_ci: 0.4752822 0.8132558370688542 GCNNet davis
Training on 25046 samples...
Train epoch: 29 [0/25046 (0%)]	Loss: 0.566922
Train epoch: 29 [328560/25046 (41%)]	Loss: 0.480370
Train epoch: 29 [654080/25046 (82%)]	Loss: 0.430528
Make prediction for 5010 samples...
0.4834425 No improvement since epoch  27 ; best_mse,best_ci: 0.4752822 0.8132558370688542 GCNNet davis
Training on 25046 samples...
Train epoch: 30 [0/25046 (0%)]	Loss: 0.453185
Train epoch: 30 [327320/25046 (41%)]	Loss: 0.454838
Train epoch: 30 [652000/25046 (82%)]	Loss: 0.534208
Make prediction for 5010 samples...
0.5242209 No improvement since epoch  27 ; best_mse,best_ci: 0.4752822 0.8132558370688542 GCNNet davis
Training on 25046 samples...
Train epoch: 31 [0/25046 (0%)]	Loss: 0.501292
Train epoch: 31 [329840/25046 (41%)]	Loss: 0.506175
Train epoch: 31 [659000/25046 (82%)]	Loss: 0.540600
Make prediction for 5010 samples...
0.5454658 No improvement since epoch  27 ; best_mse,best_ci: 0.4752822 0.8132558370688542 GCNNet davis
Training on 25046 samples...
Train epoch: 32 [0/25046 (0%)]	Loss: 0.565972
Train epoch: 32 [325260/25046 (41%)]	Loss: 0.581655
Train epoch: 32 [666640/25046 (82%)]	Loss: 0.691555
Make prediction for 5010 samples...
0.47551167 No improvement since epoch  27 ; best_mse,best_ci: 0.4752822 0.8132558370688542 GCNNet davis
Training on 25046 samples...
Train epoch: 33 [0/25046 (0%)]	Loss: 0.512778
Train epoch: 33 [325220/25046 (41%)]	Loss: 0.489574
Train epoch: 33 [659720/25046 (82%)]	Loss: 0.485793
Make prediction for 5010 samples...
0.4979034 No improvement since epoch  27 ; best_mse,best_ci: 0.4752822 0.8132558370688542 GCNNet davis
Training on 25046 samples...
Train epoch: 34 [0/25046 (0%)]	Loss: 0.411406
Train epoch: 34 [327480/25046 (41%)]	Loss: 0.502321
Train epoch: 34 [654480/25046 (82%)]	Loss: 0.566294
Make prediction for 5010 samples...
rmse improved at epoch  34 ; best_mse,best_ci: 0.47313392 0.8178893940714301 GCNNet davis
Training on 25046 samples...
Train epoch: 35 [0/25046 (0%)]	Loss: 0.512230
Train epoch: 35 [329140/25046 (41%)]	Loss: 0.505964
Train epoch: 35 [651400/25046 (82%)]	Loss: 0.648151
Make prediction for 5010 samples...
0.5228464 No improvement since epoch  34 ; best_mse,best_ci: 0.47313392 0.8178893940714301 GCNNet davis
Training on 25046 samples...
Train epoch: 36 [0/25046 (0%)]	Loss: 0.462436
Train epoch: 36 [326920/25046 (41%)]	Loss: 0.405379
Train epoch: 36 [660640/25046 (82%)]	Loss: 0.481487
Make prediction for 5010 samples...
0.4930744 No improvement since epoch  34 ; best_mse,best_ci: 0.47313392 0.8178893940714301 GCNNet davis
Training on 25046 samples...
Train epoch: 37 [0/25046 (0%)]	Loss: 0.506395
Train epoch: 37 [329600/25046 (41%)]	Loss: 0.449006
Train epoch: 37 [659440/25046 (82%)]	Loss: 0.440273
Make prediction for 5010 samples...
0.514336 No improvement since epoch  34 ; best_mse,best_ci: 0.47313392 0.8178893940714301 GCNNet davis
Training on 25046 samples...
Train epoch: 38 [0/25046 (0%)]	Loss: 0.486687
Train epoch: 38 [323520/25046 (41%)]	Loss: 0.451304
Train epoch: 38 [655640/25046 (82%)]	Loss: 0.450996
Make prediction for 5010 samples...
rmse improved at epoch  38 ; best_mse,best_ci: 0.4573508 0.8301894666811038 GCNNet davis
Training on 25046 samples...
Train epoch: 39 [0/25046 (0%)]	Loss: 0.494725
Train epoch: 39 [323320/25046 (41%)]	Loss: 0.376699
Train epoch: 39 [657920/25046 (82%)]	Loss: 0.429985
Make prediction for 5010 samples...
0.4706267 No improvement since epoch  38 ; best_mse,best_ci: 0.4573508 0.8301894666811038 GCNNet davis
Training on 25046 samples...
Train epoch: 40 [0/25046 (0%)]	Loss: 0.521825
Train epoch: 40 [329700/25046 (41%)]	Loss: 0.584277
Train epoch: 40 [662120/25046 (82%)]	Loss: 0.560155
Make prediction for 5010 samples...
0.6014766 No improvement since epoch  38 ; best_mse,best_ci: 0.4573508 0.8301894666811038 GCNNet davis
Training on 25046 samples...
Train epoch: 41 [0/25046 (0%)]	Loss: 0.624292
Train epoch: 41 [325120/25046 (41%)]	Loss: 0.428266
Train epoch: 41 [666000/25046 (82%)]	Loss: 0.448765
Make prediction for 5010 samples...
rmse improved at epoch  41 ; best_mse,best_ci: 0.44846556 0.8274877006931536 GCNNet davis
Training on 25046 samples...
Train epoch: 42 [0/25046 (0%)]	Loss: 0.422992
Train epoch: 42 [324920/25046 (41%)]	Loss: 0.403627
Train epoch: 42 [652760/25046 (82%)]	Loss: 0.364475
Make prediction for 5010 samples...
0.45584026 No improvement since epoch  41 ; best_mse,best_ci: 0.44846556 0.8274877006931536 GCNNet davis
Training on 25046 samples...
Train epoch: 43 [0/25046 (0%)]	Loss: 0.415596
Train epoch: 43 [336200/25046 (41%)]	Loss: 0.489912
Train epoch: 43 [647920/25046 (82%)]	Loss: 0.524920
Make prediction for 5010 samples...
0.46943676 No improvement since epoch  41 ; best_mse,best_ci: 0.44846556 0.8274877006931536 GCNNet davis
Training on 25046 samples...
Train epoch: 44 [0/25046 (0%)]	Loss: 0.555386
Train epoch: 44 [325760/25046 (41%)]	Loss: 0.475754
Train epoch: 44 [651160/25046 (82%)]	Loss: 0.616195
Make prediction for 5010 samples...
0.45530257 No improvement since epoch  41 ; best_mse,best_ci: 0.44846556 0.8274877006931536 GCNNet davis
Training on 25046 samples...
Train epoch: 45 [0/25046 (0%)]	Loss: 0.335697
Train epoch: 45 [329720/25046 (41%)]	Loss: 0.438945
Train epoch: 45 [660560/25046 (82%)]	Loss: 0.588678
Make prediction for 5010 samples...
0.44862005 No improvement since epoch  41 ; best_mse,best_ci: 0.44846556 0.8274877006931536 GCNNet davis
Training on 25046 samples...
Train epoch: 46 [0/25046 (0%)]	Loss: 0.351659
Train epoch: 46 [328100/25046 (41%)]	Loss: 0.387236
Train epoch: 46 [652920/25046 (82%)]	Loss: 0.535867
Make prediction for 5010 samples...
0.49429676 No improvement since epoch  41 ; best_mse,best_ci: 0.44846556 0.8274877006931536 GCNNet davis
Training on 25046 samples...
Train epoch: 47 [0/25046 (0%)]	Loss: 0.459249
Train epoch: 47 [327260/25046 (41%)]	Loss: 0.382185
Train epoch: 47 [653160/25046 (82%)]	Loss: 0.418091
Make prediction for 5010 samples...
0.47354326 No improvement since epoch  41 ; best_mse,best_ci: 0.44846556 0.8274877006931536 GCNNet davis
Training on 25046 samples...
Train epoch: 48 [0/25046 (0%)]	Loss: 0.605193
Train epoch: 48 [329760/25046 (41%)]	Loss: 0.383172
Train epoch: 48 [656760/25046 (82%)]	Loss: 0.463128
Make prediction for 5010 samples...
rmse improved at epoch  48 ; best_mse,best_ci: 0.4432211 0.8273664803666719 GCNNet davis
Training on 25046 samples...
Train epoch: 49 [0/25046 (0%)]	Loss: 0.458116
Train epoch: 49 [332040/25046 (41%)]	Loss: 0.432770
Train epoch: 49 [651280/25046 (82%)]	Loss: 0.410621
Make prediction for 5010 samples...
rmse improved at epoch  49 ; best_mse,best_ci: 0.4395409 0.8269007431426282 GCNNet davis
Training on 25046 samples...
Train epoch: 50 [0/25046 (0%)]	Loss: 0.467861
Train epoch: 50 [326280/25046 (41%)]	Loss: 0.403098
Train epoch: 50 [660400/25046 (82%)]	Loss: 0.385943
Make prediction for 5010 samples...
rmse improved at epoch  50 ; best_mse,best_ci: 0.43356138 0.8273929757759977 GCNNet davis
Training on 25046 samples...
Train epoch: 51 [0/25046 (0%)]	Loss: 0.453869
Train epoch: 51 [330200/25046 (41%)]	Loss: 0.541014
Train epoch: 51 [660040/25046 (82%)]	Loss: 0.443439
Make prediction for 5010 samples...
rmse improved at epoch  51 ; best_mse,best_ci: 0.42855448 0.8314663003663565 GCNNet davis
Training on 25046 samples...
Train epoch: 52 [0/25046 (0%)]	Loss: 0.364655
Train epoch: 52 [330860/25046 (41%)]	Loss: 0.444387
Train epoch: 52 [662280/25046 (82%)]	Loss: 0.476667
Make prediction for 5010 samples...
rmse improved at epoch  52 ; best_mse,best_ci: 0.4199824 0.832362013669487 GCNNet davis
Training on 25046 samples...
Train epoch: 53 [0/25046 (0%)]	Loss: 0.390246
Train epoch: 53 [325140/25046 (41%)]	Loss: 0.448032
Train epoch: 53 [669160/25046 (82%)]	Loss: 0.392810
Make prediction for 5010 samples...
0.44021532 No improvement since epoch  52 ; best_mse,best_ci: 0.4199824 0.832362013669487 GCNNet davis
Training on 25046 samples...
Train epoch: 54 [0/25046 (0%)]	Loss: 0.344647
Train epoch: 54 [328560/25046 (41%)]	Loss: 0.399072
Train epoch: 54 [661760/25046 (82%)]	Loss: 0.348901
Make prediction for 5010 samples...
0.49306408 No improvement since epoch  52 ; best_mse,best_ci: 0.4199824 0.832362013669487 GCNNet davis
Training on 25046 samples...
Train epoch: 55 [0/25046 (0%)]	Loss: 0.485656
Train epoch: 55 [329520/25046 (41%)]	Loss: 0.421465
Train epoch: 55 [651680/25046 (82%)]	Loss: 0.505234
Make prediction for 5010 samples...
0.4525507 No improvement since epoch  52 ; best_mse,best_ci: 0.4199824 0.832362013669487 GCNNet davis
Training on 25046 samples...
Train epoch: 56 [0/25046 (0%)]	Loss: 0.406180
Train epoch: 56 [324200/25046 (41%)]	Loss: 0.400036
Train epoch: 56 [655520/25046 (82%)]	Loss: 0.363448
Make prediction for 5010 samples...
rmse improved at epoch  56 ; best_mse,best_ci: 0.4156792 0.8268218695252711 GCNNet davis
Training on 25046 samples...
Train epoch: 57 [0/25046 (0%)]	Loss: 0.424673
Train epoch: 57 [328820/25046 (41%)]	Loss: 0.373182
Train epoch: 57 [657640/25046 (82%)]	Loss: 0.444802
Make prediction for 5010 samples...
rmse improved at epoch  57 ; best_mse,best_ci: 0.4152008 0.8336811174875368 GCNNet davis
Training on 25046 samples...
Train epoch: 58 [0/25046 (0%)]	Loss: 0.349350
Train epoch: 58 [330780/25046 (41%)]	Loss: 0.421326
Train epoch: 58 [657160/25046 (82%)]	Loss: 0.400229
Make prediction for 5010 samples...
rmse improved at epoch  58 ; best_mse,best_ci: 0.4057452 0.8371357819277723 GCNNet davis
Training on 25046 samples...
Train epoch: 59 [0/25046 (0%)]	Loss: 0.431226
Train epoch: 59 [328660/25046 (41%)]	Loss: 0.393246
Train epoch: 59 [659480/25046 (82%)]	Loss: 0.472837
Make prediction for 5010 samples...
0.4075821 No improvement since epoch  58 ; best_mse,best_ci: 0.4057452 0.8371357819277723 GCNNet davis
Training on 25046 samples...
Train epoch: 60 [0/25046 (0%)]	Loss: 0.327272
Train epoch: 60 [324480/25046 (41%)]	Loss: 0.415516
Train epoch: 60 [651920/25046 (82%)]	Loss: 0.408327
Make prediction for 5010 samples...
0.40948582 No improvement since epoch  58 ; best_mse,best_ci: 0.4057452 0.8371357819277723 GCNNet davis
Training on 25046 samples...
Train epoch: 61 [0/25046 (0%)]	Loss: 0.287137
Train epoch: 61 [332960/25046 (41%)]	Loss: 0.410065
Train epoch: 61 [656240/25046 (82%)]	Loss: 0.418173
Make prediction for 5010 samples...
0.4633878 No improvement since epoch  58 ; best_mse,best_ci: 0.4057452 0.8371357819277723 GCNNet davis
Training on 25046 samples...
Train epoch: 62 [0/25046 (0%)]	Loss: 0.491610
Train epoch: 62 [324620/25046 (41%)]	Loss: 0.423411
Train epoch: 62 [643960/25046 (82%)]	Loss: 0.371411
Make prediction for 5010 samples...
rmse improved at epoch  62 ; best_mse,best_ci: 0.39630163 0.8388518574277429 GCNNet davis
Training on 25046 samples...
Train epoch: 63 [0/25046 (0%)]	Loss: 0.387673
Train epoch: 63 [329200/25046 (41%)]	Loss: 0.376963
Train epoch: 63 [651760/25046 (82%)]	Loss: 0.414011
Make prediction for 5010 samples...
rmse improved at epoch  63 ; best_mse,best_ci: 0.39110634 0.8422591976975643 GCNNet davis
Training on 25046 samples...
Train epoch: 64 [0/25046 (0%)]	Loss: 0.392320
Train epoch: 64 [331020/25046 (41%)]	Loss: 0.461794
Train epoch: 64 [665040/25046 (82%)]	Loss: 0.345578
Make prediction for 5010 samples...
0.3935214 No improvement since epoch  63 ; best_mse,best_ci: 0.39110634 0.8422591976975643 GCNNet davis
Training on 25046 samples...
Train epoch: 65 [0/25046 (0%)]	Loss: 0.444439
Train epoch: 65 [333280/25046 (41%)]	Loss: 0.444207
Train epoch: 65 [655080/25046 (82%)]	Loss: 0.401372
Make prediction for 5010 samples...
0.40966338 No improvement since epoch  63 ; best_mse,best_ci: 0.39110634 0.8422591976975643 GCNNet davis
Training on 25046 samples...
Train epoch: 66 [0/25046 (0%)]	Loss: 0.439469
Train epoch: 66 [327200/25046 (41%)]	Loss: 0.338911
Train epoch: 66 [657200/25046 (82%)]	Loss: 0.407674
Make prediction for 5010 samples...
0.4187835 No improvement since epoch  63 ; best_mse,best_ci: 0.39110634 0.8422591976975643 GCNNet davis
Training on 25046 samples...
Train epoch: 67 [0/25046 (0%)]	Loss: 0.409059
Train epoch: 67 [325420/25046 (41%)]	Loss: 0.320936
Train epoch: 67 [654640/25046 (82%)]	Loss: 0.352284
Make prediction for 5010 samples...
0.40350285 No improvement since epoch  63 ; best_mse,best_ci: 0.39110634 0.8422591976975643 GCNNet davis
Training on 25046 samples...
Train epoch: 68 [0/25046 (0%)]	Loss: 0.262972
Train epoch: 68 [329880/25046 (41%)]	Loss: 0.368341
Train epoch: 68 [660040/25046 (82%)]	Loss: 0.419732
Make prediction for 5010 samples...
0.3973556 No improvement since epoch  63 ; best_mse,best_ci: 0.39110634 0.8422591976975643 GCNNet davis
Training on 25046 samples...
Train epoch: 69 [0/25046 (0%)]	Loss: 0.364999
Train epoch: 69 [322020/25046 (41%)]	Loss: 0.325474
Train epoch: 69 [660800/25046 (82%)]	Loss: 0.377552
Make prediction for 5010 samples...
0.412616 No improvement since epoch  63 ; best_mse,best_ci: 0.39110634 0.8422591976975643 GCNNet davis
Training on 25046 samples...
Train epoch: 70 [0/25046 (0%)]	Loss: 0.483995
Train epoch: 70 [323260/25046 (41%)]	Loss: 0.373873
Train epoch: 70 [658840/25046 (82%)]	Loss: 0.417323
Make prediction for 5010 samples...
rmse improved at epoch  70 ; best_mse,best_ci: 0.38851765 0.8413703762639114 GCNNet davis
Training on 25046 samples...
Train epoch: 71 [0/25046 (0%)]	Loss: 0.289179
Train epoch: 71 [326680/25046 (41%)]	Loss: 0.385674
Train epoch: 71 [652360/25046 (82%)]	Loss: 0.411789
Make prediction for 5010 samples...
rmse improved at epoch  71 ; best_mse,best_ci: 0.3834903 0.8385579574826788 GCNNet davis
Training on 25046 samples...
Train epoch: 72 [0/25046 (0%)]	Loss: 0.288321
Train epoch: 72 [331320/25046 (41%)]	Loss: 0.391826
Train epoch: 72 [656320/25046 (82%)]	Loss: 0.444395
Make prediction for 5010 samples...
0.41527912 No improvement since epoch  71 ; best_mse,best_ci: 0.3834903 0.8385579574826788 GCNNet davis
Training on 25046 samples...
Train epoch: 73 [0/25046 (0%)]	Loss: 0.276202
Train epoch: 73 [326960/25046 (41%)]	Loss: 0.370369
Train epoch: 73 [659800/25046 (82%)]	Loss: 0.371580
Make prediction for 5010 samples...
0.39982918 No improvement since epoch  71 ; best_mse,best_ci: 0.3834903 0.8385579574826788 GCNNet davis
Training on 25046 samples...
Train epoch: 74 [0/25046 (0%)]	Loss: 0.336407
Train epoch: 74 [327740/25046 (41%)]	Loss: 0.348548
Train epoch: 74 [658480/25046 (82%)]	Loss: 0.362470
Make prediction for 5010 samples...
0.39322528 No improvement since epoch  71 ; best_mse,best_ci: 0.3834903 0.8385579574826788 GCNNet davis
Training on 25046 samples...
Train epoch: 75 [0/25046 (0%)]	Loss: 0.318048
Train epoch: 75 [329380/25046 (41%)]	Loss: 0.315171
Train epoch: 75 [640200/25046 (82%)]	Loss: 0.425593
Make prediction for 5010 samples...
0.39910668 No improvement since epoch  71 ; best_mse,best_ci: 0.3834903 0.8385579574826788 GCNNet davis
Training on 25046 samples...
Train epoch: 76 [0/25046 (0%)]	Loss: 0.297140
Train epoch: 76 [327300/25046 (41%)]	Loss: 0.449479
Train epoch: 76 [664160/25046 (82%)]	Loss: 0.350738
Make prediction for 5010 samples...
0.41192994 No improvement since epoch  71 ; best_mse,best_ci: 0.3834903 0.8385579574826788 GCNNet davis
Training on 25046 samples...
Train epoch: 77 [0/25046 (0%)]	Loss: 0.415111
Train epoch: 77 [331260/25046 (41%)]	Loss: 0.390473
Train epoch: 77 [656880/25046 (82%)]	Loss: 0.411630
Make prediction for 5010 samples...
rmse improved at epoch  77 ; best_mse,best_ci: 0.3748124 0.8344886148613516 GCNNet davis
Training on 25046 samples...
Train epoch: 78 [0/25046 (0%)]	Loss: 0.345093
Train epoch: 78 [326480/25046 (41%)]	Loss: 0.327583
Train epoch: 78 [655200/25046 (82%)]	Loss: 0.411824
Make prediction for 5010 samples...
0.3783681 No improvement since epoch  77 ; best_mse,best_ci: 0.3748124 0.8344886148613516 GCNNet davis
Training on 25046 samples...
Train epoch: 79 [0/25046 (0%)]	Loss: 0.318982
Train epoch: 79 [329960/25046 (41%)]	Loss: 0.302482
Train epoch: 79 [651440/25046 (82%)]	Loss: 0.380951
Make prediction for 5010 samples...
0.44513482 No improvement since epoch  77 ; best_mse,best_ci: 0.3748124 0.8344886148613516 GCNNet davis
Training on 25046 samples...
Train epoch: 80 [0/25046 (0%)]	Loss: 0.420082
Train epoch: 80 [328000/25046 (41%)]	Loss: 0.325112
Train epoch: 80 [662680/25046 (82%)]	Loss: 0.409936
Make prediction for 5010 samples...
0.3836525 No improvement since epoch  77 ; best_mse,best_ci: 0.3748124 0.8344886148613516 GCNNet davis
Training on 25046 samples...
Train epoch: 81 [0/25046 (0%)]	Loss: 0.334871
Train epoch: 81 [328740/25046 (41%)]	Loss: 0.350553
Train epoch: 81 [658520/25046 (82%)]	Loss: 0.425686
Make prediction for 5010 samples...
0.3820093 No improvement since epoch  77 ; best_mse,best_ci: 0.3748124 0.8344886148613516 GCNNet davis
Training on 25046 samples...
Train epoch: 82 [0/25046 (0%)]	Loss: 0.332339
Train epoch: 82 [334140/25046 (41%)]	Loss: 0.363908
Train epoch: 82 [655680/25046 (82%)]	Loss: 0.383206
Make prediction for 5010 samples...
rmse improved at epoch  82 ; best_mse,best_ci: 0.3745051 0.8447032843433725 GCNNet davis
Training on 25046 samples...
Train epoch: 83 [0/25046 (0%)]	Loss: 0.344608
Train epoch: 83 [332720/25046 (41%)]	Loss: 0.435515
Train epoch: 83 [650840/25046 (82%)]	Loss: 0.345104
Make prediction for 5010 samples...
rmse improved at epoch  83 ; best_mse,best_ci: 0.3709831 0.8445295326562046 GCNNet davis
Training on 25046 samples...
Train epoch: 84 [0/25046 (0%)]	Loss: 0.321794
Train epoch: 84 [331260/25046 (41%)]	Loss: 0.290235
Train epoch: 84 [658080/25046 (82%)]	Loss: 0.424901
Make prediction for 5010 samples...
0.38224322 No improvement since epoch  83 ; best_mse,best_ci: 0.3709831 0.8445295326562046 GCNNet davis
Training on 25046 samples...
Train epoch: 85 [0/25046 (0%)]	Loss: 0.362480
Train epoch: 85 [327980/25046 (41%)]	Loss: 0.390419
Train epoch: 85 [653240/25046 (82%)]	Loss: 0.349132
Make prediction for 5010 samples...
0.373833 No improvement since epoch  83 ; best_mse,best_ci: 0.3709831 0.8445295326562046 GCNNet davis
Training on 25046 samples...
Train epoch: 86 [0/25046 (0%)]	Loss: 0.327430
Train epoch: 86 [325980/25046 (41%)]	Loss: 0.297723
Train epoch: 86 [658160/25046 (82%)]	Loss: 0.297257
Make prediction for 5010 samples...
0.379915 No improvement since epoch  83 ; best_mse,best_ci: 0.3709831 0.8445295326562046 GCNNet davis
Training on 25046 samples...
Train epoch: 87 [0/25046 (0%)]	Loss: 0.369290
Train epoch: 87 [328860/25046 (41%)]	Loss: 0.346914
Train epoch: 87 [655160/25046 (82%)]	Loss: 0.396400
Make prediction for 5010 samples...
0.38933706 No improvement since epoch  83 ; best_mse,best_ci: 0.3709831 0.8445295326562046 GCNNet davis
Training on 25046 samples...
Train epoch: 88 [0/25046 (0%)]	Loss: 0.322763
Train epoch: 88 [327300/25046 (41%)]	Loss: 0.289698
Train epoch: 88 [657200/25046 (82%)]	Loss: 0.348386
Make prediction for 5010 samples...
0.37655732 No improvement since epoch  83 ; best_mse,best_ci: 0.3709831 0.8445295326562046 GCNNet davis
Training on 25046 samples...
Train epoch: 89 [0/25046 (0%)]	Loss: 0.356630
Train epoch: 89 [328300/25046 (41%)]	Loss: 0.434091
Train epoch: 89 [650200/25046 (82%)]	Loss: 0.350691
Make prediction for 5010 samples...
0.3722941 No improvement since epoch  83 ; best_mse,best_ci: 0.3709831 0.8445295326562046 GCNNet davis
Training on 25046 samples...
Train epoch: 90 [0/25046 (0%)]	Loss: 0.395600
Train epoch: 90 [324680/25046 (41%)]	Loss: 0.272162
Train epoch: 90 [655160/25046 (82%)]	Loss: 0.300268
Make prediction for 5010 samples...
rmse improved at epoch  90 ; best_mse,best_ci: 0.36186367 0.8424875483062618 GCNNet davis
Training on 25046 samples...
Train epoch: 91 [0/25046 (0%)]	Loss: 0.339509
Train epoch: 91 [332160/25046 (41%)]	Loss: 0.278209
Train epoch: 91 [654800/25046 (82%)]	Loss: 0.375021
Make prediction for 5010 samples...
0.42935857 No improvement since epoch  90 ; best_mse,best_ci: 0.36186367 0.8424875483062618 GCNNet davis
Training on 25046 samples...
Train epoch: 92 [0/25046 (0%)]	Loss: 0.373323
Train epoch: 92 [329240/25046 (41%)]	Loss: 0.377832
Train epoch: 92 [662960/25046 (82%)]	Loss: 0.313855
Make prediction for 5010 samples...
0.37016392 No improvement since epoch  90 ; best_mse,best_ci: 0.36186367 0.8424875483062618 GCNNet davis
Training on 25046 samples...
Train epoch: 93 [0/25046 (0%)]	Loss: 0.337622
Train epoch: 93 [328920/25046 (41%)]	Loss: 0.337117
Train epoch: 93 [658080/25046 (82%)]	Loss: 0.253586
Make prediction for 5010 samples...
0.3819132 No improvement since epoch  90 ; best_mse,best_ci: 0.36186367 0.8424875483062618 GCNNet davis
Training on 25046 samples...
Train epoch: 94 [0/25046 (0%)]	Loss: 0.289332
Train epoch: 94 [330320/25046 (41%)]	Loss: 0.362357
Train epoch: 94 [662080/25046 (82%)]	Loss: 0.404423
Make prediction for 5010 samples...
0.41417873 No improvement since epoch  90 ; best_mse,best_ci: 0.36186367 0.8424875483062618 GCNNet davis
Training on 25046 samples...
Train epoch: 95 [0/25046 (0%)]	Loss: 0.376885
Train epoch: 95 [330920/25046 (41%)]	Loss: 0.285800
Train epoch: 95 [654840/25046 (82%)]	Loss: 0.393430
Make prediction for 5010 samples...
rmse improved at epoch  95 ; best_mse,best_ci: 0.36015376 0.8442405335961024 GCNNet davis
Training on 25046 samples...
Train epoch: 96 [0/25046 (0%)]	Loss: 0.343987
Train epoch: 96 [329240/25046 (41%)]	Loss: 0.307355
Train epoch: 96 [642720/25046 (82%)]	Loss: 0.457722
Make prediction for 5010 samples...
0.37879255 No improvement since epoch  95 ; best_mse,best_ci: 0.36015376 0.8442405335961024 GCNNet davis
Training on 25046 samples...
Train epoch: 97 [0/25046 (0%)]	Loss: 0.348213
Train epoch: 97 [335980/25046 (41%)]	Loss: 0.310817
Train epoch: 97 [654400/25046 (82%)]	Loss: 0.319024
Make prediction for 5010 samples...
0.39606956 No improvement since epoch  95 ; best_mse,best_ci: 0.36015376 0.8442405335961024 GCNNet davis
Training on 25046 samples...
Train epoch: 98 [0/25046 (0%)]	Loss: 0.369618
Train epoch: 98 [326420/25046 (41%)]	Loss: 0.266689
Train epoch: 98 [654000/25046 (82%)]	Loss: 0.300145
Make prediction for 5010 samples...
0.3807407 No improvement since epoch  95 ; best_mse,best_ci: 0.36015376 0.8442405335961024 GCNNet davis
Training on 25046 samples...
Train epoch: 99 [0/25046 (0%)]	Loss: 0.303008
Train epoch: 99 [325300/25046 (41%)]	Loss: 0.332291
Train epoch: 99 [658120/25046 (82%)]	Loss: 0.422731
Make prediction for 5010 samples...
rmse improved at epoch  99 ; best_mse,best_ci: 0.35601187 0.8351671576996043 GCNNet davis
Training on 25046 samples...
Train epoch: 100 [0/25046 (0%)]	Loss: 0.301608
Train epoch: 100 [323440/25046 (41%)]	Loss: 0.298347
Train epoch: 100 [671280/25046 (82%)]	Loss: 0.383674
Make prediction for 5010 samples...
0.39117375 No improvement since epoch  99 ; best_mse,best_ci: 0.35601187 0.8351671576996043 GCNNet davis
Training on 25046 samples...
Train epoch: 101 [0/25046 (0%)]	Loss: 0.334019
Train epoch: 101 [335860/25046 (41%)]	Loss: 0.299366
Train epoch: 101 [639320/25046 (82%)]	Loss: 0.321333
Make prediction for 5010 samples...
0.40057155 No improvement since epoch  99 ; best_mse,best_ci: 0.35601187 0.8351671576996043 GCNNet davis
Training on 25046 samples...
Train epoch: 102 [0/25046 (0%)]	Loss: 0.310125
Train epoch: 102 [328240/25046 (41%)]	Loss: 0.266039
Train epoch: 102 [661520/25046 (82%)]	Loss: 0.371638
Make prediction for 5010 samples...
rmse improved at epoch  102 ; best_mse,best_ci: 0.35557634 0.836031168403137 GCNNet davis
Training on 25046 samples...
Train epoch: 103 [0/25046 (0%)]	Loss: 0.323833
Train epoch: 103 [328100/25046 (41%)]	Loss: 0.299371
Train epoch: 103 [660160/25046 (82%)]	Loss: 0.295376
Make prediction for 5010 samples...
rmse improved at epoch  103 ; best_mse,best_ci: 0.34911123 0.8470667361162907 GCNNet davis
Training on 25046 samples...
Train epoch: 104 [0/25046 (0%)]	Loss: 0.272258
Train epoch: 104 [326640/25046 (41%)]	Loss: 0.353489
Train epoch: 104 [654640/25046 (82%)]	Loss: 0.323223
Make prediction for 5010 samples...
0.40743044 No improvement since epoch  103 ; best_mse,best_ci: 0.34911123 0.8470667361162907 GCNNet davis
Training on 25046 samples...
Train epoch: 105 [0/25046 (0%)]	Loss: 0.310430
Train epoch: 105 [329980/25046 (41%)]	Loss: 0.346039
Train epoch: 105 [657920/25046 (82%)]	Loss: 0.325529
Make prediction for 5010 samples...
0.35971645 No improvement since epoch  103 ; best_mse,best_ci: 0.34911123 0.8470667361162907 GCNNet davis
Training on 25046 samples...
Train epoch: 106 [0/25046 (0%)]	Loss: 0.319257
Train epoch: 106 [325920/25046 (41%)]	Loss: 0.305321
Train epoch: 106 [645360/25046 (82%)]	Loss: 0.288627
Make prediction for 5010 samples...
0.35139883 No improvement since epoch  103 ; best_mse,best_ci: 0.34911123 0.8470667361162907 GCNNet davis
Training on 25046 samples...
Train epoch: 107 [0/25046 (0%)]	Loss: 0.292115
Train epoch: 107 [330320/25046 (41%)]	Loss: 0.337035
Train epoch: 107 [643360/25046 (82%)]	Loss: 0.356908
Make prediction for 5010 samples...
0.41210598 No improvement since epoch  103 ; best_mse,best_ci: 0.34911123 0.8470667361162907 GCNNet davis
Training on 25046 samples...
Train epoch: 108 [0/25046 (0%)]	Loss: 0.370826
Train epoch: 108 [330400/25046 (41%)]	Loss: 0.328121
Train epoch: 108 [657080/25046 (82%)]	Loss: 0.352411
Make prediction for 5010 samples...
0.387988 No improvement since epoch  103 ; best_mse,best_ci: 0.34911123 0.8470667361162907 GCNNet davis
Training on 25046 samples...
Train epoch: 109 [0/25046 (0%)]	Loss: 0.303122
Train epoch: 109 [329400/25046 (41%)]	Loss: 0.367401
Train epoch: 109 [660040/25046 (82%)]	Loss: 0.280692
Make prediction for 5010 samples...
0.3634759 No improvement since epoch  103 ; best_mse,best_ci: 0.34911123 0.8470667361162907 GCNNet davis
Training on 25046 samples...
Train epoch: 110 [0/25046 (0%)]	Loss: 0.305044
Train epoch: 110 [333940/25046 (41%)]	Loss: 0.312595
Train epoch: 110 [652280/25046 (82%)]	Loss: 0.303031
Make prediction for 5010 samples...
0.35759473 No improvement since epoch  103 ; best_mse,best_ci: 0.34911123 0.8470667361162907 GCNNet davis
Training on 25046 samples...
Train epoch: 111 [0/25046 (0%)]	Loss: 0.279128
Train epoch: 111 [326980/25046 (41%)]	Loss: 0.302453
Train epoch: 111 [659600/25046 (82%)]	Loss: 0.399377
Make prediction for 5010 samples...
0.3645096 No improvement since epoch  103 ; best_mse,best_ci: 0.34911123 0.8470667361162907 GCNNet davis
Training on 25046 samples...
Train epoch: 112 [0/25046 (0%)]	Loss: 0.336736
Train epoch: 112 [328340/25046 (41%)]	Loss: 0.252053
Train epoch: 112 [653040/25046 (82%)]	Loss: 0.306906
Make prediction for 5010 samples...
0.35921788 No improvement since epoch  103 ; best_mse,best_ci: 0.34911123 0.8470667361162907 GCNNet davis
Training on 25046 samples...
Train epoch: 113 [0/25046 (0%)]	Loss: 0.279726
Train epoch: 113 [333260/25046 (41%)]	Loss: 0.303067
Train epoch: 113 [652360/25046 (82%)]	Loss: 0.326848
Make prediction for 5010 samples...
0.37150723 No improvement since epoch  103 ; best_mse,best_ci: 0.34911123 0.8470667361162907 GCNNet davis
Training on 25046 samples...
Train epoch: 114 [0/25046 (0%)]	Loss: 0.331701
Train epoch: 114 [330680/25046 (41%)]	Loss: 0.312254
Train epoch: 114 [668080/25046 (82%)]	Loss: 0.243717
Make prediction for 5010 samples...
rmse improved at epoch  114 ; best_mse,best_ci: 0.34359372 0.8519357653260244 GCNNet davis
Training on 25046 samples...
Train epoch: 115 [0/25046 (0%)]	Loss: 0.284521
Train epoch: 115 [329040/25046 (41%)]	Loss: 0.342017
Train epoch: 115 [660320/25046 (82%)]	Loss: 0.338614
Make prediction for 5010 samples...
0.37449977 No improvement since epoch  114 ; best_mse,best_ci: 0.34359372 0.8519357653260244 GCNNet davis
Training on 25046 samples...
Train epoch: 116 [0/25046 (0%)]	Loss: 0.277692
Train epoch: 116 [330700/25046 (41%)]	Loss: 0.273316
Train epoch: 116 [662360/25046 (82%)]	Loss: 0.394780
Make prediction for 5010 samples...
0.39023972 No improvement since epoch  114 ; best_mse,best_ci: 0.34359372 0.8519357653260244 GCNNet davis
Training on 25046 samples...
Train epoch: 117 [0/25046 (0%)]	Loss: 0.302455
Train epoch: 117 [327300/25046 (41%)]	Loss: 0.247489
Train epoch: 117 [651520/25046 (82%)]	Loss: 0.357505
Make prediction for 5010 samples...
0.36651433 No improvement since epoch  114 ; best_mse,best_ci: 0.34359372 0.8519357653260244 GCNNet davis
Training on 25046 samples...
Train epoch: 118 [0/25046 (0%)]	Loss: 0.242384
Train epoch: 118 [332320/25046 (41%)]	Loss: 0.316438
Train epoch: 118 [664160/25046 (82%)]	Loss: 0.263056
Make prediction for 5010 samples...
0.3707239 No improvement since epoch  114 ; best_mse,best_ci: 0.34359372 0.8519357653260244 GCNNet davis
Training on 25046 samples...
Train epoch: 119 [0/25046 (0%)]	Loss: 0.255034
Train epoch: 119 [325000/25046 (41%)]	Loss: 0.303698
Train epoch: 119 [657000/25046 (82%)]	Loss: 0.292969
Make prediction for 5010 samples...
0.3460307 No improvement since epoch  114 ; best_mse,best_ci: 0.34359372 0.8519357653260244 GCNNet davis
Training on 25046 samples...
Train epoch: 120 [0/25046 (0%)]	Loss: 0.265382
Train epoch: 120 [325340/25046 (41%)]	Loss: 0.269732
Train epoch: 120 [662000/25046 (82%)]	Loss: 0.335300
Make prediction for 5010 samples...
0.36975944 No improvement since epoch  114 ; best_mse,best_ci: 0.34359372 0.8519357653260244 GCNNet davis
Training on 25046 samples...
Train epoch: 121 [0/25046 (0%)]	Loss: 0.270857
Train epoch: 121 [328440/25046 (41%)]	Loss: 0.300275
Train epoch: 121 [657560/25046 (82%)]	Loss: 0.315664
Make prediction for 5010 samples...
0.3476006 No improvement since epoch  114 ; best_mse,best_ci: 0.34359372 0.8519357653260244 GCNNet davis
Training on 25046 samples...
Train epoch: 122 [0/25046 (0%)]	Loss: 0.292363
Train epoch: 122 [334340/25046 (41%)]	Loss: 0.291917
Train epoch: 122 [666240/25046 (82%)]	Loss: 0.302750
Make prediction for 5010 samples...
0.35013846 No improvement since epoch  114 ; best_mse,best_ci: 0.34359372 0.8519357653260244 GCNNet davis
Training on 25046 samples...
Train epoch: 123 [0/25046 (0%)]	Loss: 0.276309
Train epoch: 123 [329960/25046 (41%)]	Loss: 0.270640
Train epoch: 123 [655480/25046 (82%)]	Loss: 0.343908
Make prediction for 5010 samples...
0.35300297 No improvement since epoch  114 ; best_mse,best_ci: 0.34359372 0.8519357653260244 GCNNet davis
Training on 25046 samples...
Train epoch: 124 [0/25046 (0%)]	Loss: 0.251661
Train epoch: 124 [325620/25046 (41%)]	Loss: 0.365267
Train epoch: 124 [650240/25046 (82%)]	Loss: 0.330955
Make prediction for 5010 samples...
0.3539081 No improvement since epoch  114 ; best_mse,best_ci: 0.34359372 0.8519357653260244 GCNNet davis
Training on 25046 samples...
Train epoch: 125 [0/25046 (0%)]	Loss: 0.247824
Train epoch: 125 [328700/25046 (41%)]	Loss: 0.262479
Train epoch: 125 [661600/25046 (82%)]	Loss: 0.279217
Make prediction for 5010 samples...
0.34714544 No improvement since epoch  114 ; best_mse,best_ci: 0.34359372 0.8519357653260244 GCNNet davis
Training on 25046 samples...
Train epoch: 126 [0/25046 (0%)]	Loss: 0.219340
Train epoch: 126 [333280/25046 (41%)]	Loss: 0.255278
Train epoch: 126 [656400/25046 (82%)]	Loss: 0.331817
Make prediction for 5010 samples...
0.34405646 No improvement since epoch  114 ; best_mse,best_ci: 0.34359372 0.8519357653260244 GCNNet davis
Training on 25046 samples...
Train epoch: 127 [0/25046 (0%)]	Loss: 0.293511
Train epoch: 127 [333200/25046 (41%)]	Loss: 0.303636
Train epoch: 127 [660920/25046 (82%)]	Loss: 0.286415
Make prediction for 5010 samples...
rmse improved at epoch  127 ; best_mse,best_ci: 0.33562163 0.8476359279588289 GCNNet davis
Training on 25046 samples...
Train epoch: 128 [0/25046 (0%)]	Loss: 0.249406
Train epoch: 128 [323140/25046 (41%)]	Loss: 0.270221
Train epoch: 128 [652000/25046 (82%)]	Loss: 0.284852
Make prediction for 5010 samples...
0.34384155 No improvement since epoch  127 ; best_mse,best_ci: 0.33562163 0.8476359279588289 GCNNet davis
Training on 25046 samples...
Train epoch: 129 [0/25046 (0%)]	Loss: 0.292169
Train epoch: 129 [326980/25046 (41%)]	Loss: 0.276591
Train epoch: 129 [654120/25046 (82%)]	Loss: 0.377766
Make prediction for 5010 samples...
0.3517892 No improvement since epoch  127 ; best_mse,best_ci: 0.33562163 0.8476359279588289 GCNNet davis
Training on 25046 samples...
Train epoch: 130 [0/25046 (0%)]	Loss: 0.307619
Train epoch: 130 [332880/25046 (41%)]	Loss: 0.317094
Train epoch: 130 [656240/25046 (82%)]	Loss: 0.222756
Make prediction for 5010 samples...
0.395186 No improvement since epoch  127 ; best_mse,best_ci: 0.33562163 0.8476359279588289 GCNNet davis
Training on 25046 samples...
Train epoch: 131 [0/25046 (0%)]	Loss: 0.305365
Train epoch: 131 [328800/25046 (41%)]	Loss: 0.322332
Train epoch: 131 [652320/25046 (82%)]	Loss: 0.337046
Make prediction for 5010 samples...
0.38520396 No improvement since epoch  127 ; best_mse,best_ci: 0.33562163 0.8476359279588289 GCNNet davis
Training on 25046 samples...
Train epoch: 132 [0/25046 (0%)]	Loss: 0.331263
Train epoch: 132 [325260/25046 (41%)]	Loss: 0.305572
Train epoch: 132 [657560/25046 (82%)]	Loss: 0.298004
Make prediction for 5010 samples...
0.35938475 No improvement since epoch  127 ; best_mse,best_ci: 0.33562163 0.8476359279588289 GCNNet davis
Training on 25046 samples...
Train epoch: 133 [0/25046 (0%)]	Loss: 0.278871
Train epoch: 133 [327080/25046 (41%)]	Loss: 0.251396
Train epoch: 133 [657400/25046 (82%)]	Loss: 0.276716
Make prediction for 5010 samples...
0.40022528 No improvement since epoch  127 ; best_mse,best_ci: 0.33562163 0.8476359279588289 GCNNet davis
Training on 25046 samples...
Train epoch: 134 [0/25046 (0%)]	Loss: 0.326283
Train epoch: 134 [331160/25046 (41%)]	Loss: 0.272502
Train epoch: 134 [658640/25046 (82%)]	Loss: 0.316107
Make prediction for 5010 samples...
0.3373422 No improvement since epoch  127 ; best_mse,best_ci: 0.33562163 0.8476359279588289 GCNNet davis
Training on 25046 samples...
Train epoch: 135 [0/25046 (0%)]	Loss: 0.258660
Train epoch: 135 [325400/25046 (41%)]	Loss: 0.269711
Train epoch: 135 [657360/25046 (82%)]	Loss: 0.277930
Make prediction for 5010 samples...
rmse improved at epoch  135 ; best_mse,best_ci: 0.33464432 0.849676227629566 GCNNet davis
Training on 25046 samples...
Train epoch: 136 [0/25046 (0%)]	Loss: 0.263089
Train epoch: 136 [330800/25046 (41%)]	Loss: 0.312032
Train epoch: 136 [656320/25046 (82%)]	Loss: 0.263085
Make prediction for 5010 samples...
rmse improved at epoch  136 ; best_mse,best_ci: 0.33254564 0.8494178591004763 GCNNet davis
Training on 25046 samples...
Train epoch: 137 [0/25046 (0%)]	Loss: 0.250422
Train epoch: 137 [323400/25046 (41%)]	Loss: 0.308319
Train epoch: 137 [651640/25046 (82%)]	Loss: 0.258214
Make prediction for 5010 samples...
0.3653282 No improvement since epoch  136 ; best_mse,best_ci: 0.33254564 0.8494178591004763 GCNNet davis
Training on 25046 samples...
Train epoch: 138 [0/25046 (0%)]	Loss: 0.294290
Train epoch: 138 [323780/25046 (41%)]	Loss: 0.236413
Train epoch: 138 [656280/25046 (82%)]	Loss: 0.237487
Make prediction for 5010 samples...
0.38557425 No improvement since epoch  136 ; best_mse,best_ci: 0.33254564 0.8494178591004763 GCNNet davis
Training on 25046 samples...
Train epoch: 139 [0/25046 (0%)]	Loss: 0.284794
Train epoch: 139 [327200/25046 (41%)]	Loss: 0.280634
Train epoch: 139 [653000/25046 (82%)]	Loss: 0.325996
Make prediction for 5010 samples...
0.39610267 No improvement since epoch  136 ; best_mse,best_ci: 0.33254564 0.8494178591004763 GCNNet davis
Training on 25046 samples...
Train epoch: 140 [0/25046 (0%)]	Loss: 0.329715
Train epoch: 140 [327920/25046 (41%)]	Loss: 0.290288
Train epoch: 140 [668800/25046 (82%)]	Loss: 0.376439
Make prediction for 5010 samples...
0.36707547 No improvement since epoch  136 ; best_mse,best_ci: 0.33254564 0.8494178591004763 GCNNet davis
Training on 25046 samples...
Train epoch: 141 [0/25046 (0%)]	Loss: 0.372167
Train epoch: 141 [325220/25046 (41%)]	Loss: 0.269644
Train epoch: 141 [663000/25046 (82%)]	Loss: 0.281526
Make prediction for 5010 samples...
0.3398993 No improvement since epoch  136 ; best_mse,best_ci: 0.33254564 0.8494178591004763 GCNNet davis
Training on 25046 samples...
Train epoch: 142 [0/25046 (0%)]	Loss: 0.245373
Train epoch: 142 [323020/25046 (41%)]	Loss: 0.286717
Train epoch: 142 [659000/25046 (82%)]	Loss: 0.274258
Make prediction for 5010 samples...
0.3342759 No improvement since epoch  136 ; best_mse,best_ci: 0.33254564 0.8494178591004763 GCNNet davis
Training on 25046 samples...
Train epoch: 143 [0/25046 (0%)]	Loss: 0.291787
Train epoch: 143 [328700/25046 (41%)]	Loss: 0.320274
Train epoch: 143 [655800/25046 (82%)]	Loss: 0.304163
Make prediction for 5010 samples...
0.3344079 No improvement since epoch  136 ; best_mse,best_ci: 0.33254564 0.8494178591004763 GCNNet davis
Training on 25046 samples...
Train epoch: 144 [0/25046 (0%)]	Loss: 0.208397
Train epoch: 144 [325180/25046 (41%)]	Loss: 0.221379
Train epoch: 144 [661640/25046 (82%)]	Loss: 0.259716
Make prediction for 5010 samples...
0.37693235 No improvement since epoch  136 ; best_mse,best_ci: 0.33254564 0.8494178591004763 GCNNet davis
Training on 25046 samples...
Train epoch: 145 [0/25046 (0%)]	Loss: 0.246917
Train epoch: 145 [328840/25046 (41%)]	Loss: 0.307792
Train epoch: 145 [662880/25046 (82%)]	Loss: 0.299819
Make prediction for 5010 samples...
0.33825767 No improvement since epoch  136 ; best_mse,best_ci: 0.33254564 0.8494178591004763 GCNNet davis
Training on 25046 samples...
Train epoch: 146 [0/25046 (0%)]	Loss: 0.287664
Train epoch: 146 [325900/25046 (41%)]	Loss: 0.242188
Train epoch: 146 [678400/25046 (82%)]	Loss: 0.269073
Make prediction for 5010 samples...
0.34512767 No improvement since epoch  136 ; best_mse,best_ci: 0.33254564 0.8494178591004763 GCNNet davis
Training on 25046 samples...
Train epoch: 147 [0/25046 (0%)]	Loss: 0.249357
Train epoch: 147 [326100/25046 (41%)]	Loss: 0.279037
Train epoch: 147 [647360/25046 (82%)]	Loss: 0.309934
Make prediction for 5010 samples...
0.3431814 No improvement since epoch  136 ; best_mse,best_ci: 0.33254564 0.8494178591004763 GCNNet davis
Training on 25046 samples...
Train epoch: 148 [0/25046 (0%)]	Loss: 0.247302
Train epoch: 148 [328240/25046 (41%)]	Loss: 0.300535
Train epoch: 148 [663520/25046 (82%)]	Loss: 0.297891
Make prediction for 5010 samples...
rmse improved at epoch  148 ; best_mse,best_ci: 0.33077526 0.8488888698298919 GCNNet davis
Training on 25046 samples...
Train epoch: 149 [0/25046 (0%)]	Loss: 0.322177
Train epoch: 149 [331100/25046 (41%)]	Loss: 0.287739
Train epoch: 149 [654040/25046 (82%)]	Loss: 0.273281
Make prediction for 5010 samples...
0.38129097 No improvement since epoch  148 ; best_mse,best_ci: 0.33077526 0.8488888698298919 GCNNet davis
Training on 25046 samples...
Train epoch: 150 [0/25046 (0%)]	Loss: 0.248280
Train epoch: 150 [328660/25046 (41%)]	Loss: 0.198435
Train epoch: 150 [658000/25046 (82%)]	Loss: 0.338001
Make prediction for 5010 samples...
0.34489003 No improvement since epoch  148 ; best_mse,best_ci: 0.33077526 0.8488888698298919 GCNNet davis
Training on 25046 samples...
Train epoch: 151 [0/25046 (0%)]	Loss: 0.295028
Train epoch: 151 [327240/25046 (41%)]	Loss: 0.247179
Train epoch: 151 [659080/25046 (82%)]	Loss: 0.240861
Make prediction for 5010 samples...
0.3595806 No improvement since epoch  148 ; best_mse,best_ci: 0.33077526 0.8488888698298919 GCNNet davis
Training on 25046 samples...
Train epoch: 152 [0/25046 (0%)]	Loss: 0.230550
Train epoch: 152 [333960/25046 (41%)]	Loss: 0.271814
Train epoch: 152 [648920/25046 (82%)]	Loss: 0.310217
Make prediction for 5010 samples...
rmse improved at epoch  152 ; best_mse,best_ci: 0.32975012 0.8535883590504719 GCNNet davis
Training on 25046 samples...
Train epoch: 153 [0/25046 (0%)]	Loss: 0.203866
Train epoch: 153 [326600/25046 (41%)]	Loss: 0.289535
Train epoch: 153 [652080/25046 (82%)]	Loss: 0.278485
Make prediction for 5010 samples...
0.36556026 No improvement since epoch  152 ; best_mse,best_ci: 0.32975012 0.8535883590504719 GCNNet davis
Training on 25046 samples...
Train epoch: 154 [0/25046 (0%)]	Loss: 0.336371
Train epoch: 154 [327380/25046 (41%)]	Loss: 0.251908
Train epoch: 154 [654560/25046 (82%)]	Loss: 0.241005
Make prediction for 5010 samples...
0.34505635 No improvement since epoch  152 ; best_mse,best_ci: 0.32975012 0.8535883590504719 GCNNet davis
Training on 25046 samples...
Train epoch: 155 [0/25046 (0%)]	Loss: 0.238877
Train epoch: 155 [323280/25046 (41%)]	Loss: 0.233378
Train epoch: 155 [659040/25046 (82%)]	Loss: 0.241901
Make prediction for 5010 samples...
0.33244887 No improvement since epoch  152 ; best_mse,best_ci: 0.32975012 0.8535883590504719 GCNNet davis
Training on 25046 samples...
Train epoch: 156 [0/25046 (0%)]	Loss: 0.284080
Train epoch: 156 [328660/25046 (41%)]	Loss: 0.249590
Train epoch: 156 [649640/25046 (82%)]	Loss: 0.293296
Make prediction for 5010 samples...
0.3474889 No improvement since epoch  152 ; best_mse,best_ci: 0.32975012 0.8535883590504719 GCNNet davis
Training on 25046 samples...
Train epoch: 157 [0/25046 (0%)]	Loss: 0.236339
Train epoch: 157 [327180/25046 (41%)]	Loss: 0.215318
Train epoch: 157 [658040/25046 (82%)]	Loss: 0.249444
Make prediction for 5010 samples...
rmse improved at epoch  157 ; best_mse,best_ci: 0.32930705 0.849428350057348 GCNNet davis
Training on 25046 samples...
Train epoch: 158 [0/25046 (0%)]	Loss: 0.186760
Train epoch: 158 [330580/25046 (41%)]	Loss: 0.274099
Train epoch: 158 [650080/25046 (82%)]	Loss: 0.199515
Make prediction for 5010 samples...
rmse improved at epoch  158 ; best_mse,best_ci: 0.3233479 0.8535704401898296 GCNNet davis
Training on 25046 samples...
Train epoch: 159 [0/25046 (0%)]	Loss: 0.244092
Train epoch: 159 [330380/25046 (41%)]	Loss: 0.275778
Train epoch: 159 [659440/25046 (82%)]	Loss: 0.293274
Make prediction for 5010 samples...
rmse improved at epoch  159 ; best_mse,best_ci: 0.32094693 0.8482892006089963 GCNNet davis
Training on 25046 samples...
Train epoch: 160 [0/25046 (0%)]	Loss: 0.259036
Train epoch: 160 [327920/25046 (41%)]	Loss: 0.282507
Train epoch: 160 [656360/25046 (82%)]	Loss: 0.236002
Make prediction for 5010 samples...
0.33324698 No improvement since epoch  159 ; best_mse,best_ci: 0.32094693 0.8482892006089963 GCNNet davis
Training on 25046 samples...
Train epoch: 161 [0/25046 (0%)]	Loss: 0.254420
Train epoch: 161 [328520/25046 (41%)]	Loss: 0.235950
Train epoch: 161 [652000/25046 (82%)]	Loss: 0.333489
Make prediction for 5010 samples...
0.3935702 No improvement since epoch  159 ; best_mse,best_ci: 0.32094693 0.8482892006089963 GCNNet davis
Training on 25046 samples...
Train epoch: 162 [0/25046 (0%)]	Loss: 0.309274
Train epoch: 162 [331080/25046 (41%)]	Loss: 0.256969
Train epoch: 162 [650360/25046 (82%)]	Loss: 0.282902
Make prediction for 5010 samples...
0.33753917 No improvement since epoch  159 ; best_mse,best_ci: 0.32094693 0.8482892006089963 GCNNet davis
Training on 25046 samples...
Train epoch: 163 [0/25046 (0%)]	Loss: 0.209573
Train epoch: 163 [329580/25046 (41%)]	Loss: 0.206908
Train epoch: 163 [659960/25046 (82%)]	Loss: 0.193514
Make prediction for 5010 samples...
0.3297342 No improvement since epoch  159 ; best_mse,best_ci: 0.32094693 0.8482892006089963 GCNNet davis
Training on 25046 samples...
Train epoch: 164 [0/25046 (0%)]	Loss: 0.207767
Train epoch: 164 [330680/25046 (41%)]	Loss: 0.242662
Train epoch: 164 [658120/25046 (82%)]	Loss: 0.239592
Make prediction for 5010 samples...
0.33283105 No improvement since epoch  159 ; best_mse,best_ci: 0.32094693 0.8482892006089963 GCNNet davis
Training on 25046 samples...
Train epoch: 165 [0/25046 (0%)]	Loss: 0.191862
Train epoch: 165 [328380/25046 (41%)]	Loss: 0.215414
Train epoch: 165 [656240/25046 (82%)]	Loss: 0.217920
Make prediction for 5010 samples...
0.3436669 No improvement since epoch  159 ; best_mse,best_ci: 0.32094693 0.8482892006089963 GCNNet davis
Training on 25046 samples...
Train epoch: 166 [0/25046 (0%)]	Loss: 0.208000
Train epoch: 166 [326040/25046 (41%)]	Loss: 0.265678
Train epoch: 166 [649240/25046 (82%)]	Loss: 0.325755
Make prediction for 5010 samples...
0.3340141 No improvement since epoch  159 ; best_mse,best_ci: 0.32094693 0.8482892006089963 GCNNet davis
Training on 25046 samples...
Train epoch: 167 [0/25046 (0%)]	Loss: 0.223823
Train epoch: 167 [331100/25046 (41%)]	Loss: 0.283137
Train epoch: 167 [648640/25046 (82%)]	Loss: 0.370182
Make prediction for 5010 samples...
0.32792488 No improvement since epoch  159 ; best_mse,best_ci: 0.32094693 0.8482892006089963 GCNNet davis
Training on 25046 samples...
Train epoch: 168 [0/25046 (0%)]	Loss: 0.247833
Train epoch: 168 [329740/25046 (41%)]	Loss: 0.273479
Train epoch: 168 [658200/25046 (82%)]	Loss: 0.283395
Make prediction for 5010 samples...
0.3263953 No improvement since epoch  159 ; best_mse,best_ci: 0.32094693 0.8482892006089963 GCNNet davis
Training on 25046 samples...
Train epoch: 169 [0/25046 (0%)]	Loss: 0.207241
Train epoch: 169 [326580/25046 (41%)]	Loss: 0.208415
Train epoch: 169 [656080/25046 (82%)]	Loss: 0.311527
Make prediction for 5010 samples...
0.3375837 No improvement since epoch  159 ; best_mse,best_ci: 0.32094693 0.8482892006089963 GCNNet davis
Training on 25046 samples...
Train epoch: 170 [0/25046 (0%)]	Loss: 0.288466
Train epoch: 170 [329700/25046 (41%)]	Loss: 0.248649
Train epoch: 170 [658400/25046 (82%)]	Loss: 0.226769
Make prediction for 5010 samples...
0.3282271 No improvement since epoch  159 ; best_mse,best_ci: 0.32094693 0.8482892006089963 GCNNet davis
Training on 25046 samples...
Train epoch: 171 [0/25046 (0%)]	Loss: 0.219827
Train epoch: 171 [328940/25046 (41%)]	Loss: 0.260585
Train epoch: 171 [658200/25046 (82%)]	Loss: 0.223911
Make prediction for 5010 samples...
0.34006488 No improvement since epoch  159 ; best_mse,best_ci: 0.32094693 0.8482892006089963 GCNNet davis
Training on 25046 samples...
Train epoch: 172 [0/25046 (0%)]	Loss: 0.249808
Train epoch: 172 [330460/25046 (41%)]	Loss: 0.280232
Train epoch: 172 [665360/25046 (82%)]	Loss: 0.191176
Make prediction for 5010 samples...
0.3421905 No improvement since epoch  159 ; best_mse,best_ci: 0.32094693 0.8482892006089963 GCNNet davis
Training on 25046 samples...
Train epoch: 173 [0/25046 (0%)]	Loss: 0.202035
Train epoch: 173 [328380/25046 (41%)]	Loss: 0.228615
Train epoch: 173 [653680/25046 (82%)]	Loss: 0.237444
Make prediction for 5010 samples...
rmse improved at epoch  173 ; best_mse,best_ci: 0.31937253 0.8576130576728485 GCNNet davis
Training on 25046 samples...
Train epoch: 174 [0/25046 (0%)]	Loss: 0.210860
Train epoch: 174 [329180/25046 (41%)]	Loss: 0.252344
Train epoch: 174 [655080/25046 (82%)]	Loss: 0.262270
Make prediction for 5010 samples...
0.3298864 No improvement since epoch  173 ; best_mse,best_ci: 0.31937253 0.8576130576728485 GCNNet davis
Training on 25046 samples...
Train epoch: 175 [0/25046 (0%)]	Loss: 0.212113
Train epoch: 175 [325640/25046 (41%)]	Loss: 0.223745
Train epoch: 175 [660080/25046 (82%)]	Loss: 0.253345
Make prediction for 5010 samples...
0.35267523 No improvement since epoch  173 ; best_mse,best_ci: 0.31937253 0.8576130576728485 GCNNet davis
Training on 25046 samples...
Train epoch: 176 [0/25046 (0%)]	Loss: 0.213045
Train epoch: 176 [330280/25046 (41%)]	Loss: 0.311824
Train epoch: 176 [652640/25046 (82%)]	Loss: 0.217759
Make prediction for 5010 samples...
0.3496948 No improvement since epoch  173 ; best_mse,best_ci: 0.31937253 0.8576130576728485 GCNNet davis
Training on 25046 samples...
Train epoch: 177 [0/25046 (0%)]	Loss: 0.273240
Train epoch: 177 [331140/25046 (41%)]	Loss: 0.263592
Train epoch: 177 [659280/25046 (82%)]	Loss: 0.228339
Make prediction for 5010 samples...
0.3863405 No improvement since epoch  173 ; best_mse,best_ci: 0.31937253 0.8576130576728485 GCNNet davis
Training on 25046 samples...
Train epoch: 178 [0/25046 (0%)]	Loss: 0.244922
Train epoch: 178 [328340/25046 (41%)]	Loss: 0.231050
Train epoch: 178 [675440/25046 (82%)]	Loss: 0.268774
Make prediction for 5010 samples...
rmse improved at epoch  178 ; best_mse,best_ci: 0.31683305 0.8510138629188783 GCNNet davis
Training on 25046 samples...
Train epoch: 179 [0/25046 (0%)]	Loss: 0.194130
Train epoch: 179 [334520/25046 (41%)]	Loss: 0.199725
Train epoch: 179 [654600/25046 (82%)]	Loss: 0.254966
Make prediction for 5010 samples...
0.32734793 No improvement since epoch  178 ; best_mse,best_ci: 0.31683305 0.8510138629188783 GCNNet davis
Training on 25046 samples...
Train epoch: 180 [0/25046 (0%)]	Loss: 0.197445
Train epoch: 180 [329400/25046 (41%)]	Loss: 0.276179
Train epoch: 180 [666800/25046 (82%)]	Loss: 0.202473
Make prediction for 5010 samples...
0.31785718 No improvement since epoch  178 ; best_mse,best_ci: 0.31683305 0.8510138629188783 GCNNet davis
Training on 25046 samples...
Train epoch: 181 [0/25046 (0%)]	Loss: 0.198726
Train epoch: 181 [329460/25046 (41%)]	Loss: 0.232638
Train epoch: 181 [660320/25046 (82%)]	Loss: 0.272265
Make prediction for 5010 samples...
0.39841264 No improvement since epoch  178 ; best_mse,best_ci: 0.31683305 0.8510138629188783 GCNNet davis
Training on 25046 samples...
Train epoch: 182 [0/25046 (0%)]	Loss: 0.312108
Train epoch: 182 [327080/25046 (41%)]	Loss: 0.207097
Train epoch: 182 [663880/25046 (82%)]	Loss: 0.261481
Make prediction for 5010 samples...
0.32591274 No improvement since epoch  178 ; best_mse,best_ci: 0.31683305 0.8510138629188783 GCNNet davis
Training on 25046 samples...
Train epoch: 183 [0/25046 (0%)]	Loss: 0.181624
Train epoch: 183 [329580/25046 (41%)]	Loss: 0.206418
Train epoch: 183 [654840/25046 (82%)]	Loss: 0.221653
Make prediction for 5010 samples...
0.32858315 No improvement since epoch  178 ; best_mse,best_ci: 0.31683305 0.8510138629188783 GCNNet davis
Training on 25046 samples...
Train epoch: 184 [0/25046 (0%)]	Loss: 0.267683
Train epoch: 184 [325220/25046 (41%)]	Loss: 0.202113
Train epoch: 184 [661160/25046 (82%)]	Loss: 0.272060
Make prediction for 5010 samples...
0.32647032 No improvement since epoch  178 ; best_mse,best_ci: 0.31683305 0.8510138629188783 GCNNet davis
Training on 25046 samples...
Train epoch: 185 [0/25046 (0%)]	Loss: 0.201938
Train epoch: 185 [323940/25046 (41%)]	Loss: 0.177512
Train epoch: 185 [658080/25046 (82%)]	Loss: 0.230780
Make prediction for 5010 samples...
0.33038965 No improvement since epoch  178 ; best_mse,best_ci: 0.31683305 0.8510138629188783 GCNNet davis
Training on 25046 samples...
Train epoch: 186 [0/25046 (0%)]	Loss: 0.241882
Train epoch: 186 [324980/25046 (41%)]	Loss: 0.195498
Train epoch: 186 [653080/25046 (82%)]	Loss: 0.269889
Make prediction for 5010 samples...
0.3354762 No improvement since epoch  178 ; best_mse,best_ci: 0.31683305 0.8510138629188783 GCNNet davis
Training on 25046 samples...
Train epoch: 187 [0/25046 (0%)]	Loss: 0.205294
Train epoch: 187 [327440/25046 (41%)]	Loss: 0.213903
Train epoch: 187 [648440/25046 (82%)]	Loss: 0.224540
Make prediction for 5010 samples...
0.3184883 No improvement since epoch  178 ; best_mse,best_ci: 0.31683305 0.8510138629188783 GCNNet davis
Training on 25046 samples...
Train epoch: 188 [0/25046 (0%)]	Loss: 0.233500
Train epoch: 188 [329760/25046 (41%)]	Loss: 0.229064
Train epoch: 188 [659480/25046 (82%)]	Loss: 0.244294
Make prediction for 5010 samples...
0.31864056 No improvement since epoch  178 ; best_mse,best_ci: 0.31683305 0.8510138629188783 GCNNet davis
Training on 25046 samples...
Train epoch: 189 [0/25046 (0%)]	Loss: 0.199819
Train epoch: 189 [324440/25046 (41%)]	Loss: 0.214230
Train epoch: 189 [658040/25046 (82%)]	Loss: 0.219676
Make prediction for 5010 samples...
0.38209125 No improvement since epoch  178 ; best_mse,best_ci: 0.31683305 0.8510138629188783 GCNNet davis
Training on 25046 samples...
Train epoch: 190 [0/25046 (0%)]	Loss: 0.311486
Train epoch: 190 [327680/25046 (41%)]	Loss: 0.240084
Train epoch: 190 [663280/25046 (82%)]	Loss: 0.281753
Make prediction for 5010 samples...
0.34534743 No improvement since epoch  178 ; best_mse,best_ci: 0.31683305 0.8510138629188783 GCNNet davis
Training on 25046 samples...
Train epoch: 191 [0/25046 (0%)]	Loss: 0.262713
Train epoch: 191 [330000/25046 (41%)]	Loss: 0.193226
Train epoch: 191 [648360/25046 (82%)]	Loss: 0.220641
Make prediction for 5010 samples...
0.33145773 No improvement since epoch  178 ; best_mse,best_ci: 0.31683305 0.8510138629188783 GCNNet davis
Training on 25046 samples...
Train epoch: 192 [0/25046 (0%)]	Loss: 0.293855
Train epoch: 192 [328320/25046 (41%)]	Loss: 0.211024
Train epoch: 192 [665800/25046 (82%)]	Loss: 0.174448
Make prediction for 5010 samples...
0.3261224 No improvement since epoch  178 ; best_mse,best_ci: 0.31683305 0.8510138629188783 GCNNet davis
Training on 25046 samples...
Train epoch: 193 [0/25046 (0%)]	Loss: 0.242901
Train epoch: 193 [330700/25046 (41%)]	Loss: 0.252013
Train epoch: 193 [659200/25046 (82%)]	Loss: 0.246940
Make prediction for 5010 samples...
rmse improved at epoch  193 ; best_mse,best_ci: 0.30717558 0.8623734250738158 GCNNet davis
Training on 25046 samples...
Train epoch: 194 [0/25046 (0%)]	Loss: 0.166448
Train epoch: 194 [326200/25046 (41%)]	Loss: 0.232035
Train epoch: 194 [654480/25046 (82%)]	Loss: 0.211253
Make prediction for 5010 samples...
0.3151855 No improvement since epoch  193 ; best_mse,best_ci: 0.30717558 0.8623734250738158 GCNNet davis
Training on 25046 samples...
Train epoch: 195 [0/25046 (0%)]	Loss: 0.193018
Train epoch: 195 [321840/25046 (41%)]	Loss: 0.256107
Train epoch: 195 [662200/25046 (82%)]	Loss: 0.203837
Make prediction for 5010 samples...
0.3406574 No improvement since epoch  193 ; best_mse,best_ci: 0.30717558 0.8623734250738158 GCNNet davis
Training on 25046 samples...
Train epoch: 196 [0/25046 (0%)]	Loss: 0.250649
Train epoch: 196 [334540/25046 (41%)]	Loss: 0.235201
Train epoch: 196 [662080/25046 (82%)]	Loss: 0.224225
Make prediction for 5010 samples...
0.34964266 No improvement since epoch  193 ; best_mse,best_ci: 0.30717558 0.8623734250738158 GCNNet davis
Training on 25046 samples...
Train epoch: 197 [0/25046 (0%)]	Loss: 0.246039
Train epoch: 197 [330320/25046 (41%)]	Loss: 0.251914
Train epoch: 197 [652120/25046 (82%)]	Loss: 0.263809
Make prediction for 5010 samples...
0.3374349 No improvement since epoch  193 ; best_mse,best_ci: 0.30717558 0.8623734250738158 GCNNet davis
Training on 25046 samples...
Train epoch: 198 [0/25046 (0%)]	Loss: 0.184716
Train epoch: 198 [327840/25046 (41%)]	Loss: 0.212916
Train epoch: 198 [657000/25046 (82%)]	Loss: 0.246405
Make prediction for 5010 samples...
0.31909 No improvement since epoch  193 ; best_mse,best_ci: 0.30717558 0.8623734250738158 GCNNet davis
Training on 25046 samples...
Train epoch: 199 [0/25046 (0%)]	Loss: 0.229063
Train epoch: 199 [328200/25046 (41%)]	Loss: 0.172605
Train epoch: 199 [648680/25046 (82%)]	Loss: 0.191583
Make prediction for 5010 samples...
0.32807145 No improvement since epoch  193 ; best_mse,best_ci: 0.30717558 0.8623734250738158 GCNNet davis
Training on 25046 samples...
Train epoch: 200 [0/25046 (0%)]	Loss: 0.186220
Train epoch: 200 [332840/25046 (41%)]	Loss: 0.238170
Train epoch: 200 [662720/25046 (82%)]	Loss: 0.234968
Make prediction for 5010 samples...
0.32785755 No improvement since epoch  193 ; best_mse,best_ci: 0.30717558 0.8623734250738158 GCNNet davis
Training on 25046 samples...
Train epoch: 201 [0/25046 (0%)]	Loss: 0.251982
Train epoch: 201 [330560/25046 (41%)]	Loss: 0.229285
Train epoch: 201 [652720/25046 (82%)]	Loss: 0.215442
Make prediction for 5010 samples...
0.33564755 No improvement since epoch  193 ; best_mse,best_ci: 0.30717558 0.8623734250738158 GCNNet davis
Training on 25046 samples...
Train epoch: 202 [0/25046 (0%)]	Loss: 0.194079
Train epoch: 202 [329100/25046 (41%)]	Loss: 0.214888
Train epoch: 202 [663920/25046 (82%)]	Loss: 0.223421
Make prediction for 5010 samples...
0.31750047 No improvement since epoch  193 ; best_mse,best_ci: 0.30717558 0.8623734250738158 GCNNet davis
Training on 25046 samples...
Train epoch: 203 [0/25046 (0%)]	Loss: 0.222482
Train epoch: 203 [327740/25046 (41%)]	Loss: 0.174276
Train epoch: 203 [666440/25046 (82%)]	Loss: 0.224973
Make prediction for 5010 samples...
0.32868248 No improvement since epoch  193 ; best_mse,best_ci: 0.30717558 0.8623734250738158 GCNNet davis
Training on 25046 samples...
Train epoch: 204 [0/25046 (0%)]	Loss: 0.196481
Train epoch: 204 [330920/25046 (41%)]	Loss: 0.185754
Train epoch: 204 [658520/25046 (82%)]	Loss: 0.211342
Make prediction for 5010 samples...
0.332259 No improvement since epoch  193 ; best_mse,best_ci: 0.30717558 0.8623734250738158 GCNNet davis
Training on 25046 samples...
Train epoch: 205 [0/25046 (0%)]	Loss: 0.252742
Train epoch: 205 [337160/25046 (41%)]	Loss: 0.265019
Train epoch: 205 [652960/25046 (82%)]	Loss: 0.210084
Make prediction for 5010 samples...
0.36498982 No improvement since epoch  193 ; best_mse,best_ci: 0.30717558 0.8623734250738158 GCNNet davis
Training on 25046 samples...
Train epoch: 206 [0/25046 (0%)]	Loss: 0.238259
Train epoch: 206 [326380/25046 (41%)]	Loss: 0.221110
Train epoch: 206 [648520/25046 (82%)]	Loss: 0.261240
Make prediction for 5010 samples...
0.3221085 No improvement since epoch  193 ; best_mse,best_ci: 0.30717558 0.8623734250738158 GCNNet davis
Training on 25046 samples...
Train epoch: 207 [0/25046 (0%)]	Loss: 0.150970
Train epoch: 207 [331540/25046 (41%)]	Loss: 0.215785
Train epoch: 207 [652400/25046 (82%)]	Loss: 0.265862
Make prediction for 5010 samples...
0.31929985 No improvement since epoch  193 ; best_mse,best_ci: 0.30717558 0.8623734250738158 GCNNet davis
Training on 25046 samples...
Train epoch: 208 [0/25046 (0%)]	Loss: 0.228383
Train epoch: 208 [326780/25046 (41%)]	Loss: 0.243736
Train epoch: 208 [660000/25046 (82%)]	Loss: 0.249920
Make prediction for 5010 samples...
0.31174558 No improvement since epoch  193 ; best_mse,best_ci: 0.30717558 0.8623734250738158 GCNNet davis
Training on 25046 samples...
Train epoch: 209 [0/25046 (0%)]	Loss: 0.226966
Train epoch: 209 [329000/25046 (41%)]	Loss: 0.241319
Train epoch: 209 [662200/25046 (82%)]	Loss: 0.211284
Make prediction for 5010 samples...
rmse improved at epoch  209 ; best_mse,best_ci: 0.30402872 0.865557239043574 GCNNet davis
Training on 25046 samples...
Train epoch: 210 [0/25046 (0%)]	Loss: 0.198536
Train epoch: 210 [330480/25046 (41%)]	Loss: 0.246516
Train epoch: 210 [666400/25046 (82%)]	Loss: 0.255654
Make prediction for 5010 samples...
0.3179663 No improvement since epoch  209 ; best_mse,best_ci: 0.30402872 0.865557239043574 GCNNet davis
Training on 25046 samples...
Train epoch: 211 [0/25046 (0%)]	Loss: 0.196436
Train epoch: 211 [330600/25046 (41%)]	Loss: 0.262722
Train epoch: 211 [652760/25046 (82%)]	Loss: 0.238720
Make prediction for 5010 samples...
0.31006858 No improvement since epoch  209 ; best_mse,best_ci: 0.30402872 0.865557239043574 GCNNet davis
Training on 25046 samples...
Train epoch: 212 [0/25046 (0%)]	Loss: 0.175503
Train epoch: 212 [328740/25046 (41%)]	Loss: 0.193797
Train epoch: 212 [658680/25046 (82%)]	Loss: 0.193609
Make prediction for 5010 samples...
0.33676988 No improvement since epoch  209 ; best_mse,best_ci: 0.30402872 0.865557239043574 GCNNet davis
Training on 25046 samples...
Train epoch: 213 [0/25046 (0%)]	Loss: 0.168533
Train epoch: 213 [323500/25046 (41%)]	Loss: 0.213778
Train epoch: 213 [656640/25046 (82%)]	Loss: 0.218909
Make prediction for 5010 samples...
0.3247816 No improvement since epoch  209 ; best_mse,best_ci: 0.30402872 0.865557239043574 GCNNet davis
Training on 25046 samples...
Train epoch: 214 [0/25046 (0%)]	Loss: 0.166102
Train epoch: 214 [328400/25046 (41%)]	Loss: 0.231370
Train epoch: 214 [656560/25046 (82%)]	Loss: 0.220043
Make prediction for 5010 samples...
0.3125519 No improvement since epoch  209 ; best_mse,best_ci: 0.30402872 0.865557239043574 GCNNet davis
Training on 25046 samples...
Train epoch: 215 [0/25046 (0%)]	Loss: 0.186294
Train epoch: 215 [328000/25046 (41%)]	Loss: 0.227684
Train epoch: 215 [663000/25046 (82%)]	Loss: 0.210629
Make prediction for 5010 samples...
0.3439578 No improvement since epoch  209 ; best_mse,best_ci: 0.30402872 0.865557239043574 GCNNet davis
Training on 25046 samples...
Train epoch: 216 [0/25046 (0%)]	Loss: 0.177006
Train epoch: 216 [331480/25046 (41%)]	Loss: 0.192317
Train epoch: 216 [652160/25046 (82%)]	Loss: 0.204526
Make prediction for 5010 samples...
0.34229457 No improvement since epoch  209 ; best_mse,best_ci: 0.30402872 0.865557239043574 GCNNet davis
Training on 25046 samples...
Train epoch: 217 [0/25046 (0%)]	Loss: 0.194524
Train epoch: 217 [330620/25046 (41%)]	Loss: 0.279488
Train epoch: 217 [657840/25046 (82%)]	Loss: 0.182069
Make prediction for 5010 samples...
0.3269468 No improvement since epoch  209 ; best_mse,best_ci: 0.30402872 0.865557239043574 GCNNet davis
Training on 25046 samples...
Train epoch: 218 [0/25046 (0%)]	Loss: 0.178473
Train epoch: 218 [325700/25046 (41%)]	Loss: 0.179234
Train epoch: 218 [649440/25046 (82%)]	Loss: 0.210628
Make prediction for 5010 samples...
0.31146353 No improvement since epoch  209 ; best_mse,best_ci: 0.30402872 0.865557239043574 GCNNet davis
Training on 25046 samples...
Train epoch: 219 [0/25046 (0%)]	Loss: 0.186990
Train epoch: 219 [330960/25046 (41%)]	Loss: 0.224317
Train epoch: 219 [652400/25046 (82%)]	Loss: 0.196474
Make prediction for 5010 samples...
0.43231943 No improvement since epoch  209 ; best_mse,best_ci: 0.30402872 0.865557239043574 GCNNet davis
Training on 25046 samples...
Train epoch: 220 [0/25046 (0%)]	Loss: 0.262212
Train epoch: 220 [335940/25046 (41%)]	Loss: 0.215030
Train epoch: 220 [651160/25046 (82%)]	Loss: 0.181757
Make prediction for 5010 samples...
0.31491342 No improvement since epoch  209 ; best_mse,best_ci: 0.30402872 0.865557239043574 GCNNet davis
Training on 25046 samples...
Train epoch: 221 [0/25046 (0%)]	Loss: 0.187813
Train epoch: 221 [326560/25046 (41%)]	Loss: 0.183046
Train epoch: 221 [656760/25046 (82%)]	Loss: 0.247793
Make prediction for 5010 samples...
0.34106168 No improvement since epoch  209 ; best_mse,best_ci: 0.30402872 0.865557239043574 GCNNet davis
Training on 25046 samples...
Train epoch: 222 [0/25046 (0%)]	Loss: 0.195497
Train epoch: 222 [330600/25046 (41%)]	Loss: 0.182696
Train epoch: 222 [651280/25046 (82%)]	Loss: 0.239683
Make prediction for 5010 samples...
0.31266385 No improvement since epoch  209 ; best_mse,best_ci: 0.30402872 0.865557239043574 GCNNet davis
Training on 25046 samples...
Train epoch: 223 [0/25046 (0%)]	Loss: 0.199236
Train epoch: 223 [332500/25046 (41%)]	Loss: 0.180297
Train epoch: 223 [656640/25046 (82%)]	Loss: 0.185591
Make prediction for 5010 samples...
0.32272077 No improvement since epoch  209 ; best_mse,best_ci: 0.30402872 0.865557239043574 GCNNet davis
Training on 25046 samples...
Train epoch: 224 [0/25046 (0%)]	Loss: 0.192739
Train epoch: 224 [331520/25046 (41%)]	Loss: 0.190697
Train epoch: 224 [656600/25046 (82%)]	Loss: 0.236385
Make prediction for 5010 samples...
0.3135831 No improvement since epoch  209 ; best_mse,best_ci: 0.30402872 0.865557239043574 GCNNet davis
Training on 25046 samples...
Train epoch: 225 [0/25046 (0%)]	Loss: 0.180334
Train epoch: 225 [331420/25046 (41%)]	Loss: 0.188438
Train epoch: 225 [652800/25046 (82%)]	Loss: 0.196564
Make prediction for 5010 samples...
0.34267473 No improvement since epoch  209 ; best_mse,best_ci: 0.30402872 0.865557239043574 GCNNet davis
Training on 25046 samples...
Train epoch: 226 [0/25046 (0%)]	Loss: 0.259743
Train epoch: 226 [324740/25046 (41%)]	Loss: 0.205822
Train epoch: 226 [654920/25046 (82%)]	Loss: 0.188604
Make prediction for 5010 samples...
0.3079656 No improvement since epoch  209 ; best_mse,best_ci: 0.30402872 0.865557239043574 GCNNet davis
Training on 25046 samples...
Train epoch: 227 [0/25046 (0%)]	Loss: 0.217314
Train epoch: 227 [328200/25046 (41%)]	Loss: 0.166097
Train epoch: 227 [649240/25046 (82%)]	Loss: 0.180924
Make prediction for 5010 samples...
0.3053896 No improvement since epoch  209 ; best_mse,best_ci: 0.30402872 0.865557239043574 GCNNet davis
Training on 25046 samples...
Train epoch: 228 [0/25046 (0%)]	Loss: 0.236491
Train epoch: 228 [332540/25046 (41%)]	Loss: 0.206527
Train epoch: 228 [650520/25046 (82%)]	Loss: 0.202610
Make prediction for 5010 samples...
0.3251063 No improvement since epoch  209 ; best_mse,best_ci: 0.30402872 0.865557239043574 GCNNet davis
Training on 25046 samples...
Train epoch: 229 [0/25046 (0%)]	Loss: 0.171968
Train epoch: 229 [328860/25046 (41%)]	Loss: 0.192324
Train epoch: 229 [658480/25046 (82%)]	Loss: 0.219424
Make prediction for 5010 samples...
rmse improved at epoch  229 ; best_mse,best_ci: 0.29713008 0.8657724185239362 GCNNet davis
Training on 25046 samples...
Train epoch: 230 [0/25046 (0%)]	Loss: 0.192090
Train epoch: 230 [328640/25046 (41%)]	Loss: 0.185439
Train epoch: 230 [662840/25046 (82%)]	Loss: 0.205964
Make prediction for 5010 samples...
0.31515378 No improvement since epoch  229 ; best_mse,best_ci: 0.29713008 0.8657724185239362 GCNNet davis
Training on 25046 samples...
Train epoch: 231 [0/25046 (0%)]	Loss: 0.133261
Train epoch: 231 [327080/25046 (41%)]	Loss: 0.229849
Train epoch: 231 [661680/25046 (82%)]	Loss: 0.227144
Make prediction for 5010 samples...
0.33721897 No improvement since epoch  229 ; best_mse,best_ci: 0.29713008 0.8657724185239362 GCNNet davis
Training on 25046 samples...
Train epoch: 232 [0/25046 (0%)]	Loss: 0.206255
Train epoch: 232 [325980/25046 (41%)]	Loss: 0.213546
Train epoch: 232 [659360/25046 (82%)]	Loss: 0.151643
Make prediction for 5010 samples...
0.31048962 No improvement since epoch  229 ; best_mse,best_ci: 0.29713008 0.8657724185239362 GCNNet davis
Training on 25046 samples...
Train epoch: 233 [0/25046 (0%)]	Loss: 0.161053
Train epoch: 233 [333800/25046 (41%)]	Loss: 0.176134
Train epoch: 233 [656760/25046 (82%)]	Loss: 0.249832
Make prediction for 5010 samples...
0.304193 No improvement since epoch  229 ; best_mse,best_ci: 0.29713008 0.8657724185239362 GCNNet davis
Training on 25046 samples...
Train epoch: 234 [0/25046 (0%)]	Loss: 0.165731
Train epoch: 234 [329060/25046 (41%)]	Loss: 0.196630
Train epoch: 234 [648080/25046 (82%)]	Loss: 0.207592
Make prediction for 5010 samples...
0.38409135 No improvement since epoch  229 ; best_mse,best_ci: 0.29713008 0.8657724185239362 GCNNet davis
Training on 25046 samples...
Train epoch: 235 [0/25046 (0%)]	Loss: 0.237706
Train epoch: 235 [325680/25046 (41%)]	Loss: 0.164223
Train epoch: 235 [656280/25046 (82%)]	Loss: 0.233391
Make prediction for 5010 samples...
0.3143382 No improvement since epoch  229 ; best_mse,best_ci: 0.29713008 0.8657724185239362 GCNNet davis
Training on 25046 samples...
Train epoch: 236 [0/25046 (0%)]	Loss: 0.171615
Train epoch: 236 [327020/25046 (41%)]	Loss: 0.172527
Train epoch: 236 [668280/25046 (82%)]	Loss: 0.237802
Make prediction for 5010 samples...
0.3138136 No improvement since epoch  229 ; best_mse,best_ci: 0.29713008 0.8657724185239362 GCNNet davis
Training on 25046 samples...
Train epoch: 237 [0/25046 (0%)]	Loss: 0.229543
Train epoch: 237 [327920/25046 (41%)]	Loss: 0.208770
Train epoch: 237 [649920/25046 (82%)]	Loss: 0.194077
Make prediction for 5010 samples...
0.33601812 No improvement since epoch  229 ; best_mse,best_ci: 0.29713008 0.8657724185239362 GCNNet davis
Training on 25046 samples...
Train epoch: 238 [0/25046 (0%)]	Loss: 0.221063
Train epoch: 238 [330040/25046 (41%)]	Loss: 0.185610
Train epoch: 238 [642040/25046 (82%)]	Loss: 0.201667
Make prediction for 5010 samples...
0.31267193 No improvement since epoch  229 ; best_mse,best_ci: 0.29713008 0.8657724185239362 GCNNet davis
Training on 25046 samples...
Train epoch: 239 [0/25046 (0%)]	Loss: 0.173101
Train epoch: 239 [323500/25046 (41%)]	Loss: 0.181893
Train epoch: 239 [671160/25046 (82%)]	Loss: 0.175323
Make prediction for 5010 samples...
0.30698264 No improvement since epoch  229 ; best_mse,best_ci: 0.29713008 0.8657724185239362 GCNNet davis
Training on 25046 samples...
Train epoch: 240 [0/25046 (0%)]	Loss: 0.155611
Train epoch: 240 [327000/25046 (41%)]	Loss: 0.181990
Train epoch: 240 [651400/25046 (82%)]	Loss: 0.198487
Make prediction for 5010 samples...
0.30351084 No improvement since epoch  229 ; best_mse,best_ci: 0.29713008 0.8657724185239362 GCNNet davis
Training on 25046 samples...
Train epoch: 241 [0/25046 (0%)]	Loss: 0.186544
Train epoch: 241 [328660/25046 (41%)]	Loss: 0.177513
Train epoch: 241 [657720/25046 (82%)]	Loss: 0.223774
Make prediction for 5010 samples...
0.32359284 No improvement since epoch  229 ; best_mse,best_ci: 0.29713008 0.8657724185239362 GCNNet davis
Training on 25046 samples...
Train epoch: 242 [0/25046 (0%)]	Loss: 0.190758
Train epoch: 242 [325520/25046 (41%)]	Loss: 0.252422
Train epoch: 242 [663240/25046 (82%)]	Loss: 0.206273
Make prediction for 5010 samples...
0.30175665 No improvement since epoch  229 ; best_mse,best_ci: 0.29713008 0.8657724185239362 GCNNet davis
Training on 25046 samples...
Train epoch: 243 [0/25046 (0%)]	Loss: 0.188218
Train epoch: 243 [331200/25046 (41%)]	Loss: 0.245445
Train epoch: 243 [648160/25046 (82%)]	Loss: 0.250177
Make prediction for 5010 samples...
0.31238762 No improvement since epoch  229 ; best_mse,best_ci: 0.29713008 0.8657724185239362 GCNNet davis
Training on 25046 samples...
Train epoch: 244 [0/25046 (0%)]	Loss: 0.167810
Train epoch: 244 [326800/25046 (41%)]	Loss: 0.245771
Train epoch: 244 [660680/25046 (82%)]	Loss: 0.200861
Make prediction for 5010 samples...
0.30668172 No improvement since epoch  229 ; best_mse,best_ci: 0.29713008 0.8657724185239362 GCNNet davis
Training on 25046 samples...
Train epoch: 245 [0/25046 (0%)]	Loss: 0.169094
Train epoch: 245 [329680/25046 (41%)]	Loss: 0.200021
Train epoch: 245 [648880/25046 (82%)]	Loss: 0.204563
Make prediction for 5010 samples...
0.3002612 No improvement since epoch  229 ; best_mse,best_ci: 0.29713008 0.8657724185239362 GCNNet davis
Training on 25046 samples...
Train epoch: 246 [0/25046 (0%)]	Loss: 0.167507
Train epoch: 246 [332340/25046 (41%)]	Loss: 0.237548
Train epoch: 246 [660360/25046 (82%)]	Loss: 0.231100
Make prediction for 5010 samples...
0.3007849 No improvement since epoch  229 ; best_mse,best_ci: 0.29713008 0.8657724185239362 GCNNet davis
Training on 25046 samples...
Train epoch: 247 [0/25046 (0%)]	Loss: 0.175647
Train epoch: 247 [328740/25046 (41%)]	Loss: 0.234683
Train epoch: 247 [655920/25046 (82%)]	Loss: 0.251914
Make prediction for 5010 samples...
0.35526082 No improvement since epoch  229 ; best_mse,best_ci: 0.29713008 0.8657724185239362 GCNNet davis
Training on 25046 samples...
Train epoch: 248 [0/25046 (0%)]	Loss: 0.179809
Train epoch: 248 [328180/25046 (41%)]	Loss: 0.176183
Train epoch: 248 [651640/25046 (82%)]	Loss: 0.172810
Make prediction for 5010 samples...
0.36344612 No improvement since epoch  229 ; best_mse,best_ci: 0.29713008 0.8657724185239362 GCNNet davis
Training on 25046 samples...
Train epoch: 249 [0/25046 (0%)]	Loss: 0.210149
Train epoch: 249 [326020/25046 (41%)]	Loss: 0.215517
Train epoch: 249 [654720/25046 (82%)]	Loss: 0.169287
Make prediction for 5010 samples...
rmse improved at epoch  249 ; best_mse,best_ci: 0.29511398 0.8706095919814171 GCNNet davis
Training on 25046 samples...
Train epoch: 250 [0/25046 (0%)]	Loss: 0.169037
Train epoch: 250 [326640/25046 (41%)]	Loss: 0.181190
Train epoch: 250 [666400/25046 (82%)]	Loss: 0.211670
Make prediction for 5010 samples...
0.29875392 No improvement since epoch  249 ; best_mse,best_ci: 0.29511398 0.8706095919814171 GCNNet davis
Training on 25046 samples...
Train epoch: 251 [0/25046 (0%)]	Loss: 0.136418
Train epoch: 251 [327040/25046 (41%)]	Loss: 0.199019
Train epoch: 251 [657680/25046 (82%)]	Loss: 0.143037
Make prediction for 5010 samples...
0.29573056 No improvement since epoch  249 ; best_mse,best_ci: 0.29511398 0.8706095919814171 GCNNet davis
Training on 25046 samples...
Train epoch: 252 [0/25046 (0%)]	Loss: 0.178604
Train epoch: 252 [327900/25046 (41%)]	Loss: 0.197242
Train epoch: 252 [656880/25046 (82%)]	Loss: 0.265024
Make prediction for 5010 samples...
0.29827893 No improvement since epoch  249 ; best_mse,best_ci: 0.29511398 0.8706095919814171 GCNNet davis
Training on 25046 samples...
Train epoch: 253 [0/25046 (0%)]	Loss: 0.160426
Train epoch: 253 [327560/25046 (41%)]	Loss: 0.211332
Train epoch: 253 [653320/25046 (82%)]	Loss: 0.175723
Make prediction for 5010 samples...
0.3560228 No improvement since epoch  249 ; best_mse,best_ci: 0.29511398 0.8706095919814171 GCNNet davis
Training on 25046 samples...
Train epoch: 254 [0/25046 (0%)]	Loss: 0.203549
Train epoch: 254 [330680/25046 (41%)]	Loss: 0.198909
Train epoch: 254 [649040/25046 (82%)]	Loss: 0.184598
Make prediction for 5010 samples...
0.3085533 No improvement since epoch  249 ; best_mse,best_ci: 0.29511398 0.8706095919814171 GCNNet davis
Training on 25046 samples...
Train epoch: 255 [0/25046 (0%)]	Loss: 0.202086
Train epoch: 255 [327880/25046 (41%)]	Loss: 0.168269
Train epoch: 255 [649800/25046 (82%)]	Loss: 0.212175
Make prediction for 5010 samples...
0.31190774 No improvement since epoch  249 ; best_mse,best_ci: 0.29511398 0.8706095919814171 GCNNet davis
Training on 25046 samples...
Train epoch: 256 [0/25046 (0%)]	Loss: 0.184613
Train epoch: 256 [328600/25046 (41%)]	Loss: 0.180681
Train epoch: 256 [657200/25046 (82%)]	Loss: 0.240206
Make prediction for 5010 samples...
0.33600262 No improvement since epoch  249 ; best_mse,best_ci: 0.29511398 0.8706095919814171 GCNNet davis
Training on 25046 samples...
Train epoch: 257 [0/25046 (0%)]	Loss: 0.239584
Train epoch: 257 [326560/25046 (41%)]	Loss: 0.238833
Train epoch: 257 [652080/25046 (82%)]	Loss: 0.170242
Make prediction for 5010 samples...
0.31436566 No improvement since epoch  249 ; best_mse,best_ci: 0.29511398 0.8706095919814171 GCNNet davis
Training on 25046 samples...
Train epoch: 258 [0/25046 (0%)]	Loss: 0.156285
Train epoch: 258 [326980/25046 (41%)]	Loss: 0.199737
Train epoch: 258 [640840/25046 (82%)]	Loss: 0.212003
Make prediction for 5010 samples...
0.29741472 No improvement since epoch  249 ; best_mse,best_ci: 0.29511398 0.8706095919814171 GCNNet davis
Training on 25046 samples...
Train epoch: 259 [0/25046 (0%)]	Loss: 0.163290
Train epoch: 259 [331520/25046 (41%)]	Loss: 0.198024
Train epoch: 259 [649960/25046 (82%)]	Loss: 0.192369
Make prediction for 5010 samples...
0.302103 No improvement since epoch  249 ; best_mse,best_ci: 0.29511398 0.8706095919814171 GCNNet davis
Training on 25046 samples...
Train epoch: 260 [0/25046 (0%)]	Loss: 0.200346
Train epoch: 260 [329440/25046 (41%)]	Loss: 0.180185
Train epoch: 260 [659840/25046 (82%)]	Loss: 0.237712
Make prediction for 5010 samples...
0.30292284 No improvement since epoch  249 ; best_mse,best_ci: 0.29511398 0.8706095919814171 GCNNet davis
Training on 25046 samples...
Train epoch: 261 [0/25046 (0%)]	Loss: 0.170975
Train epoch: 261 [330300/25046 (41%)]	Loss: 0.178358
Train epoch: 261 [654960/25046 (82%)]	Loss: 0.175977
Make prediction for 5010 samples...
0.2960838 No improvement since epoch  249 ; best_mse,best_ci: 0.29511398 0.8706095919814171 GCNNet davis
Training on 25046 samples...
Train epoch: 262 [0/25046 (0%)]	Loss: 0.152318
Train epoch: 262 [326640/25046 (41%)]	Loss: 0.192892
Train epoch: 262 [647760/25046 (82%)]	Loss: 0.208162
Make prediction for 5010 samples...
0.30392155 No improvement since epoch  249 ; best_mse,best_ci: 0.29511398 0.8706095919814171 GCNNet davis
Training on 25046 samples...
Train epoch: 263 [0/25046 (0%)]	Loss: 0.163880
Train epoch: 263 [332320/25046 (41%)]	Loss: 0.193954
Train epoch: 263 [660840/25046 (82%)]	Loss: 0.187099
Make prediction for 5010 samples...
0.31435195 No improvement since epoch  249 ; best_mse,best_ci: 0.29511398 0.8706095919814171 GCNNet davis
Training on 25046 samples...
Train epoch: 264 [0/25046 (0%)]	Loss: 0.196429
Train epoch: 264 [322620/25046 (41%)]	Loss: 0.211081
Train epoch: 264 [661800/25046 (82%)]	Loss: 0.174979
Make prediction for 5010 samples...
0.3078916 No improvement since epoch  249 ; best_mse,best_ci: 0.29511398 0.8706095919814171 GCNNet davis
Training on 25046 samples...
Train epoch: 265 [0/25046 (0%)]	Loss: 0.146337
Train epoch: 265 [326100/25046 (41%)]	Loss: 0.160759
Train epoch: 265 [657200/25046 (82%)]	Loss: 0.163296
Make prediction for 5010 samples...
0.2976509 No improvement since epoch  249 ; best_mse,best_ci: 0.29511398 0.8706095919814171 GCNNet davis
Training on 25046 samples...
Train epoch: 266 [0/25046 (0%)]	Loss: 0.195504
Train epoch: 266 [327860/25046 (41%)]	Loss: 0.143532
Train epoch: 266 [658880/25046 (82%)]	Loss: 0.156382
Make prediction for 5010 samples...
0.3229881 No improvement since epoch  249 ; best_mse,best_ci: 0.29511398 0.8706095919814171 GCNNet davis
Training on 25046 samples...
Train epoch: 267 [0/25046 (0%)]	Loss: 0.177649
Train epoch: 267 [325820/25046 (41%)]	Loss: 0.230677
Train epoch: 267 [655560/25046 (82%)]	Loss: 0.189836
Make prediction for 5010 samples...
0.30087253 No improvement since epoch  249 ; best_mse,best_ci: 0.29511398 0.8706095919814171 GCNNet davis
Training on 25046 samples...
Train epoch: 268 [0/25046 (0%)]	Loss: 0.167558
Train epoch: 268 [330140/25046 (41%)]	Loss: 0.169548
Train epoch: 268 [655480/25046 (82%)]	Loss: 0.169368
Make prediction for 5010 samples...
0.30632243 No improvement since epoch  249 ; best_mse,best_ci: 0.29511398 0.8706095919814171 GCNNet davis
Training on 25046 samples...
Train epoch: 269 [0/25046 (0%)]	Loss: 0.116629
Train epoch: 269 [333320/25046 (41%)]	Loss: 0.165534
Train epoch: 269 [654360/25046 (82%)]	Loss: 0.169681
Make prediction for 5010 samples...
0.30169538 No improvement since epoch  249 ; best_mse,best_ci: 0.29511398 0.8706095919814171 GCNNet davis
Training on 25046 samples...
Train epoch: 270 [0/25046 (0%)]	Loss: 0.174062
Train epoch: 270 [326540/25046 (41%)]	Loss: 0.168309
Train epoch: 270 [656840/25046 (82%)]	Loss: 0.183868
Make prediction for 5010 samples...
0.32393727 No improvement since epoch  249 ; best_mse,best_ci: 0.29511398 0.8706095919814171 GCNNet davis
Training on 25046 samples...
Train epoch: 271 [0/25046 (0%)]	Loss: 0.145166
Train epoch: 271 [327800/25046 (41%)]	Loss: 0.232775
Train epoch: 271 [649880/25046 (82%)]	Loss: 0.165136
Make prediction for 5010 samples...
0.30422845 No improvement since epoch  249 ; best_mse,best_ci: 0.29511398 0.8706095919814171 GCNNet davis
Training on 25046 samples...
Train epoch: 272 [0/25046 (0%)]	Loss: 0.160618
Train epoch: 272 [333280/25046 (41%)]	Loss: 0.139513
Train epoch: 272 [653440/25046 (82%)]	Loss: 0.176929
Make prediction for 5010 samples...
0.31056938 No improvement since epoch  249 ; best_mse,best_ci: 0.29511398 0.8706095919814171 GCNNet davis
Training on 25046 samples...
Train epoch: 273 [0/25046 (0%)]	Loss: 0.177598
Train epoch: 273 [329780/25046 (41%)]	Loss: 0.148587
Train epoch: 273 [652200/25046 (82%)]	Loss: 0.182947
Make prediction for 5010 samples...
0.3012865 No improvement since epoch  249 ; best_mse,best_ci: 0.29511398 0.8706095919814171 GCNNet davis
Training on 25046 samples...
Train epoch: 274 [0/25046 (0%)]	Loss: 0.136050
Train epoch: 274 [333220/25046 (41%)]	Loss: 0.205512
Train epoch: 274 [657080/25046 (82%)]	Loss: 0.153337
Make prediction for 5010 samples...
0.3094153 No improvement since epoch  249 ; best_mse,best_ci: 0.29511398 0.8706095919814171 GCNNet davis
Training on 25046 samples...
Train epoch: 275 [0/25046 (0%)]	Loss: 0.154424
Train epoch: 275 [331380/25046 (41%)]	Loss: 0.147346
Train epoch: 275 [651640/25046 (82%)]	Loss: 0.143488
Make prediction for 5010 samples...
0.3142848 No improvement since epoch  249 ; best_mse,best_ci: 0.29511398 0.8706095919814171 GCNNet davis
Training on 25046 samples...
Train epoch: 276 [0/25046 (0%)]	Loss: 0.159445
Train epoch: 276 [326200/25046 (41%)]	Loss: 0.185720
Train epoch: 276 [659520/25046 (82%)]	Loss: 0.186695
Make prediction for 5010 samples...
0.295114 No improvement since epoch  249 ; best_mse,best_ci: 0.29511398 0.8706095919814171 GCNNet davis
Training on 25046 samples...
Train epoch: 277 [0/25046 (0%)]	Loss: 0.185144
Train epoch: 277 [334340/25046 (41%)]	Loss: 0.213312
Train epoch: 277 [658520/25046 (82%)]	Loss: 0.202528
Make prediction for 5010 samples...
rmse improved at epoch  277 ; best_mse,best_ci: 0.28814396 0.8669249688296059 GCNNet davis
Training on 25046 samples...
Train epoch: 278 [0/25046 (0%)]	Loss: 0.179310
Train epoch: 278 [328300/25046 (41%)]	Loss: 0.183757
Train epoch: 278 [651640/25046 (82%)]	Loss: 0.199108
Make prediction for 5010 samples...
0.37827218 No improvement since epoch  277 ; best_mse,best_ci: 0.28814396 0.8669249688296059 GCNNet davis
Training on 25046 samples...
Train epoch: 279 [0/25046 (0%)]	Loss: 0.212572
Train epoch: 279 [326200/25046 (41%)]	Loss: 0.217082
Train epoch: 279 [654520/25046 (82%)]	Loss: 0.169762
Make prediction for 5010 samples...
0.312567 No improvement since epoch  277 ; best_mse,best_ci: 0.28814396 0.8669249688296059 GCNNet davis
Training on 25046 samples...
Train epoch: 280 [0/25046 (0%)]	Loss: 0.158208
Train epoch: 280 [332720/25046 (41%)]	Loss: 0.153068
Train epoch: 280 [655880/25046 (82%)]	Loss: 0.172770
Make prediction for 5010 samples...
0.29596066 No improvement since epoch  277 ; best_mse,best_ci: 0.28814396 0.8669249688296059 GCNNet davis
Training on 25046 samples...
Train epoch: 281 [0/25046 (0%)]	Loss: 0.170138
Train epoch: 281 [328840/25046 (41%)]	Loss: 0.205087
Train epoch: 281 [658640/25046 (82%)]	Loss: 0.180736
Make prediction for 5010 samples...
0.37796298 No improvement since epoch  277 ; best_mse,best_ci: 0.28814396 0.8669249688296059 GCNNet davis
Training on 25046 samples...
Train epoch: 282 [0/25046 (0%)]	Loss: 0.208791
Train epoch: 282 [325380/25046 (41%)]	Loss: 0.147698
Train epoch: 282 [647360/25046 (82%)]	Loss: 0.187325
Make prediction for 5010 samples...
0.29845527 No improvement since epoch  277 ; best_mse,best_ci: 0.28814396 0.8669249688296059 GCNNet davis
Training on 25046 samples...
Train epoch: 283 [0/25046 (0%)]	Loss: 0.202833
Train epoch: 283 [325460/25046 (41%)]	Loss: 0.159253
Train epoch: 283 [656640/25046 (82%)]	Loss: 0.161634
Make prediction for 5010 samples...
0.3168047 No improvement since epoch  277 ; best_mse,best_ci: 0.28814396 0.8669249688296059 GCNNet davis
Training on 25046 samples...
Train epoch: 284 [0/25046 (0%)]	Loss: 0.157580
Train epoch: 284 [329060/25046 (41%)]	Loss: 0.185662
Train epoch: 284 [652800/25046 (82%)]	Loss: 0.174055
Make prediction for 5010 samples...
0.29820147 No improvement since epoch  277 ; best_mse,best_ci: 0.28814396 0.8669249688296059 GCNNet davis
Training on 25046 samples...
Train epoch: 285 [0/25046 (0%)]	Loss: 0.137242
Train epoch: 285 [325140/25046 (41%)]	Loss: 0.158350
Train epoch: 285 [651040/25046 (82%)]	Loss: 0.179092
Make prediction for 5010 samples...
0.29567158 No improvement since epoch  277 ; best_mse,best_ci: 0.28814396 0.8669249688296059 GCNNet davis
Training on 25046 samples...
Train epoch: 286 [0/25046 (0%)]	Loss: 0.145685
Train epoch: 286 [326640/25046 (41%)]	Loss: 0.159867
Train epoch: 286 [650680/25046 (82%)]	Loss: 0.179957
Make prediction for 5010 samples...
0.30770773 No improvement since epoch  277 ; best_mse,best_ci: 0.28814396 0.8669249688296059 GCNNet davis
Training on 25046 samples...
Train epoch: 287 [0/25046 (0%)]	Loss: 0.167609
Train epoch: 287 [323780/25046 (41%)]	Loss: 0.156164
Train epoch: 287 [658800/25046 (82%)]	Loss: 0.173244
Make prediction for 5010 samples...
0.31181636 No improvement since epoch  277 ; best_mse,best_ci: 0.28814396 0.8669249688296059 GCNNet davis
Training on 25046 samples...
Train epoch: 288 [0/25046 (0%)]	Loss: 0.188304
Train epoch: 288 [332820/25046 (41%)]	Loss: 0.194867
Train epoch: 288 [653080/25046 (82%)]	Loss: 0.159652
Make prediction for 5010 samples...
0.29792938 No improvement since epoch  277 ; best_mse,best_ci: 0.28814396 0.8669249688296059 GCNNet davis
Training on 25046 samples...
Train epoch: 289 [0/25046 (0%)]	Loss: 0.190525
Train epoch: 289 [328020/25046 (41%)]	Loss: 0.173529
Train epoch: 289 [650160/25046 (82%)]	Loss: 0.198801
Make prediction for 5010 samples...
0.29847053 No improvement since epoch  277 ; best_mse,best_ci: 0.28814396 0.8669249688296059 GCNNet davis
Training on 25046 samples...
Train epoch: 290 [0/25046 (0%)]	Loss: 0.175093
Train epoch: 290 [332340/25046 (41%)]	Loss: 0.209880
Train epoch: 290 [669840/25046 (82%)]	Loss: 0.225971
Make prediction for 5010 samples...
0.29190892 No improvement since epoch  277 ; best_mse,best_ci: 0.28814396 0.8669249688296059 GCNNet davis
Training on 25046 samples...
Train epoch: 291 [0/25046 (0%)]	Loss: 0.182075
Train epoch: 291 [328360/25046 (41%)]	Loss: 0.133476
Train epoch: 291 [655080/25046 (82%)]	Loss: 0.138232
Make prediction for 5010 samples...
0.3143332 No improvement since epoch  277 ; best_mse,best_ci: 0.28814396 0.8669249688296059 GCNNet davis
Training on 25046 samples...
Train epoch: 292 [0/25046 (0%)]	Loss: 0.203998
Train epoch: 292 [325080/25046 (41%)]	Loss: 0.160828
Train epoch: 292 [652080/25046 (82%)]	Loss: 0.132289
Make prediction for 5010 samples...
0.31722456 No improvement since epoch  277 ; best_mse,best_ci: 0.28814396 0.8669249688296059 GCNNet davis
Training on 25046 samples...
Train epoch: 293 [0/25046 (0%)]	Loss: 0.213301
Train epoch: 293 [329820/25046 (41%)]	Loss: 0.146754
Train epoch: 293 [648960/25046 (82%)]	Loss: 0.175593
Make prediction for 5010 samples...
0.3071744 No improvement since epoch  277 ; best_mse,best_ci: 0.28814396 0.8669249688296059 GCNNet davis
Training on 25046 samples...
Train epoch: 294 [0/25046 (0%)]	Loss: 0.152605
Train epoch: 294 [332380/25046 (41%)]	Loss: 0.250607
Train epoch: 294 [654480/25046 (82%)]	Loss: 0.164609
Make prediction for 5010 samples...
0.2994326 No improvement since epoch  277 ; best_mse,best_ci: 0.28814396 0.8669249688296059 GCNNet davis
Training on 25046 samples...
Train epoch: 295 [0/25046 (0%)]	Loss: 0.159296
Train epoch: 295 [328880/25046 (41%)]	Loss: 0.192900
Train epoch: 295 [655120/25046 (82%)]	Loss: 0.184914
Make prediction for 5010 samples...
0.29256558 No improvement since epoch  277 ; best_mse,best_ci: 0.28814396 0.8669249688296059 GCNNet davis
Training on 25046 samples...
Train epoch: 296 [0/25046 (0%)]	Loss: 0.167183
Train epoch: 296 [325560/25046 (41%)]	Loss: 0.219695
Train epoch: 296 [651960/25046 (82%)]	Loss: 0.194642
Make prediction for 5010 samples...
0.29765546 No improvement since epoch  277 ; best_mse,best_ci: 0.28814396 0.8669249688296059 GCNNet davis
Training on 25046 samples...
Train epoch: 297 [0/25046 (0%)]	Loss: 0.157026
Train epoch: 297 [326260/25046 (41%)]	Loss: 0.146601
Train epoch: 297 [658040/25046 (82%)]	Loss: 0.151128
Make prediction for 5010 samples...
0.30243102 No improvement since epoch  277 ; best_mse,best_ci: 0.28814396 0.8669249688296059 GCNNet davis
Training on 25046 samples...
Train epoch: 298 [0/25046 (0%)]	Loss: 0.183985
Train epoch: 298 [324540/25046 (41%)]	Loss: 0.181624
Train epoch: 298 [671960/25046 (82%)]	Loss: 0.199128
Make prediction for 5010 samples...
0.29662684 No improvement since epoch  277 ; best_mse,best_ci: 0.28814396 0.8669249688296059 GCNNet davis
Training on 25046 samples...
Train epoch: 299 [0/25046 (0%)]	Loss: 0.178029
Train epoch: 299 [328440/25046 (41%)]	Loss: 0.150446
Train epoch: 299 [663400/25046 (82%)]	Loss: 0.181812
Make prediction for 5010 samples...
0.3019173 No improvement since epoch  277 ; best_mse,best_ci: 0.28814396 0.8669249688296059 GCNNet davis
Training on 25046 samples...
Train epoch: 300 [0/25046 (0%)]	Loss: 0.156768
Train epoch: 300 [327560/25046 (41%)]	Loss: 0.170560
Train epoch: 300 [658040/25046 (82%)]	Loss: 0.214446
Make prediction for 5010 samples...
0.29488412 No improvement since epoch  277 ; best_mse,best_ci: 0.28814396 0.8669249688296059 GCNNet davis
Training on 25046 samples...
Train epoch: 301 [0/25046 (0%)]	Loss: 0.138103
Train epoch: 301 [325520/25046 (41%)]	Loss: 0.176632
Train epoch: 301 [656080/25046 (82%)]	Loss: 0.167875
Make prediction for 5010 samples...
0.29593304 No improvement since epoch  277 ; best_mse,best_ci: 0.28814396 0.8669249688296059 GCNNet davis
Training on 25046 samples...
Train epoch: 302 [0/25046 (0%)]	Loss: 0.184885
Train epoch: 302 [327840/25046 (41%)]	Loss: 0.170113
Train epoch: 302 [652680/25046 (82%)]	Loss: 0.174863
Make prediction for 5010 samples...
0.31001967 No improvement since epoch  277 ; best_mse,best_ci: 0.28814396 0.8669249688296059 GCNNet davis
Training on 25046 samples...
Train epoch: 303 [0/25046 (0%)]	Loss: 0.211773
Train epoch: 303 [332000/25046 (41%)]	Loss: 0.190142
Train epoch: 303 [649120/25046 (82%)]	Loss: 0.163564
Make prediction for 5010 samples...
0.34587267 No improvement since epoch  277 ; best_mse,best_ci: 0.28814396 0.8669249688296059 GCNNet davis
Training on 25046 samples...
Train epoch: 304 [0/25046 (0%)]	Loss: 0.208915
Train epoch: 304 [327300/25046 (41%)]	Loss: 0.166810
Train epoch: 304 [656320/25046 (82%)]	Loss: 0.172607
Make prediction for 5010 samples...
0.29252687 No improvement since epoch  277 ; best_mse,best_ci: 0.28814396 0.8669249688296059 GCNNet davis
Training on 25046 samples...
Train epoch: 305 [0/25046 (0%)]	Loss: 0.169834
Train epoch: 305 [329380/25046 (41%)]	Loss: 0.158572
Train epoch: 305 [658840/25046 (82%)]	Loss: 0.177677
Make prediction for 5010 samples...
0.3077197 No improvement since epoch  277 ; best_mse,best_ci: 0.28814396 0.8669249688296059 GCNNet davis
Training on 25046 samples...
Train epoch: 306 [0/25046 (0%)]	Loss: 0.191019
Train epoch: 306 [329000/25046 (41%)]	Loss: 0.146610
Train epoch: 306 [653960/25046 (82%)]	Loss: 0.143405
Make prediction for 5010 samples...
0.29751885 No improvement since epoch  277 ; best_mse,best_ci: 0.28814396 0.8669249688296059 GCNNet davis
Training on 25046 samples...
Train epoch: 307 [0/25046 (0%)]	Loss: 0.141002
Train epoch: 307 [330840/25046 (41%)]	Loss: 0.208297
Train epoch: 307 [653880/25046 (82%)]	Loss: 0.151260
Make prediction for 5010 samples...
0.3010482 No improvement since epoch  277 ; best_mse,best_ci: 0.28814396 0.8669249688296059 GCNNet davis
Training on 25046 samples...
Train epoch: 308 [0/25046 (0%)]	Loss: 0.171216
Train epoch: 308 [325180/25046 (41%)]	Loss: 0.169243
Train epoch: 308 [652000/25046 (82%)]	Loss: 0.166010
Make prediction for 5010 samples...
rmse improved at epoch  308 ; best_mse,best_ci: 0.2766302 0.87093144228603 GCNNet davis
Training on 25046 samples...
Train epoch: 309 [0/25046 (0%)]	Loss: 0.180584
Train epoch: 309 [328800/25046 (41%)]	Loss: 0.158308
Train epoch: 309 [665480/25046 (82%)]	Loss: 0.159771
Make prediction for 5010 samples...
0.29412046 No improvement since epoch  308 ; best_mse,best_ci: 0.2766302 0.87093144228603 GCNNet davis
Training on 25046 samples...
Train epoch: 310 [0/25046 (0%)]	Loss: 0.156440
Train epoch: 310 [324540/25046 (41%)]	Loss: 0.167688
Train epoch: 310 [652000/25046 (82%)]	Loss: 0.160084
Make prediction for 5010 samples...
0.2949862 No improvement since epoch  308 ; best_mse,best_ci: 0.2766302 0.87093144228603 GCNNet davis
Training on 25046 samples...
Train epoch: 311 [0/25046 (0%)]	Loss: 0.146952
Train epoch: 311 [327940/25046 (41%)]	Loss: 0.162602
Train epoch: 311 [661400/25046 (82%)]	Loss: 0.203907
Make prediction for 5010 samples...
0.30997193 No improvement since epoch  308 ; best_mse,best_ci: 0.2766302 0.87093144228603 GCNNet davis
Training on 25046 samples...
Train epoch: 312 [0/25046 (0%)]	Loss: 0.153239
Train epoch: 312 [330660/25046 (41%)]	Loss: 0.182392
Train epoch: 312 [653560/25046 (82%)]	Loss: 0.189946
Make prediction for 5010 samples...
0.3235301 No improvement since epoch  308 ; best_mse,best_ci: 0.2766302 0.87093144228603 GCNNet davis
Training on 25046 samples...
Train epoch: 313 [0/25046 (0%)]	Loss: 0.155149
Train epoch: 313 [323480/25046 (41%)]	Loss: 0.143192
Train epoch: 313 [658200/25046 (82%)]	Loss: 0.226094
Make prediction for 5010 samples...
0.30374753 No improvement since epoch  308 ; best_mse,best_ci: 0.2766302 0.87093144228603 GCNNet davis
Training on 25046 samples...
Train epoch: 314 [0/25046 (0%)]	Loss: 0.145852
Train epoch: 314 [326900/25046 (41%)]	Loss: 0.109441
Train epoch: 314 [668600/25046 (82%)]	Loss: 0.192617
Make prediction for 5010 samples...
0.3227751 No improvement since epoch  308 ; best_mse,best_ci: 0.2766302 0.87093144228603 GCNNet davis
Training on 25046 samples...
Train epoch: 315 [0/25046 (0%)]	Loss: 0.154068
Train epoch: 315 [325620/25046 (41%)]	Loss: 0.163817
Train epoch: 315 [659480/25046 (82%)]	Loss: 0.173316
Make prediction for 5010 samples...
0.30995294 No improvement since epoch  308 ; best_mse,best_ci: 0.2766302 0.87093144228603 GCNNet davis
Training on 25046 samples...
Train epoch: 316 [0/25046 (0%)]	Loss: 0.153413
Train epoch: 316 [330620/25046 (41%)]	Loss: 0.151551
Train epoch: 316 [660160/25046 (82%)]	Loss: 0.175405
Make prediction for 5010 samples...
0.2974987 No improvement since epoch  308 ; best_mse,best_ci: 0.2766302 0.87093144228603 GCNNet davis
Training on 25046 samples...
Train epoch: 317 [0/25046 (0%)]	Loss: 0.161772
Train epoch: 317 [327440/25046 (41%)]	Loss: 0.232140
Train epoch: 317 [657920/25046 (82%)]	Loss: 0.180081
Make prediction for 5010 samples...
0.300079 No improvement since epoch  308 ; best_mse,best_ci: 0.2766302 0.87093144228603 GCNNet davis
Training on 25046 samples...
Train epoch: 318 [0/25046 (0%)]	Loss: 0.119596
Train epoch: 318 [327620/25046 (41%)]	Loss: 0.197406
Train epoch: 318 [659720/25046 (82%)]	Loss: 0.155316
Make prediction for 5010 samples...
0.30166736 No improvement since epoch  308 ; best_mse,best_ci: 0.2766302 0.87093144228603 GCNNet davis
Training on 25046 samples...
Train epoch: 319 [0/25046 (0%)]	Loss: 0.134468
Train epoch: 319 [326100/25046 (41%)]	Loss: 0.217590
Train epoch: 319 [660920/25046 (82%)]	Loss: 0.156739
Make prediction for 5010 samples...
0.2901537 No improvement since epoch  308 ; best_mse,best_ci: 0.2766302 0.87093144228603 GCNNet davis
Training on 25046 samples...
Train epoch: 320 [0/25046 (0%)]	Loss: 0.154623
Train epoch: 320 [331900/25046 (41%)]	Loss: 0.157533
Train epoch: 320 [656840/25046 (82%)]	Loss: 0.156185
Make prediction for 5010 samples...
0.28771475 No improvement since epoch  308 ; best_mse,best_ci: 0.2766302 0.87093144228603 GCNNet davis
Training on 25046 samples...
Train epoch: 321 [0/25046 (0%)]	Loss: 0.137795
Train epoch: 321 [327960/25046 (41%)]	Loss: 0.169300
Train epoch: 321 [654200/25046 (82%)]	Loss: 0.157779
Make prediction for 5010 samples...
0.30545822 No improvement since epoch  308 ; best_mse,best_ci: 0.2766302 0.87093144228603 GCNNet davis
Training on 25046 samples...
Train epoch: 322 [0/25046 (0%)]	Loss: 0.144642
Train epoch: 322 [326320/25046 (41%)]	Loss: 0.156378
Train epoch: 322 [656280/25046 (82%)]	Loss: 0.190290
Make prediction for 5010 samples...
0.3006769 No improvement since epoch  308 ; best_mse,best_ci: 0.2766302 0.87093144228603 GCNNet davis
Training on 25046 samples...
Train epoch: 323 [0/25046 (0%)]	Loss: 0.132274
Train epoch: 323 [330480/25046 (41%)]	Loss: 0.145836
Train epoch: 323 [648600/25046 (82%)]	Loss: 0.182832
Make prediction for 5010 samples...
0.30937645 No improvement since epoch  308 ; best_mse,best_ci: 0.2766302 0.87093144228603 GCNNet davis
Training on 25046 samples...
Train epoch: 324 [0/25046 (0%)]	Loss: 0.145832
Train epoch: 324 [328820/25046 (41%)]	Loss: 0.148626
Train epoch: 324 [657120/25046 (82%)]	Loss: 0.151105
Make prediction for 5010 samples...
0.32425755 No improvement since epoch  308 ; best_mse,best_ci: 0.2766302 0.87093144228603 GCNNet davis
Training on 25046 samples...
Train epoch: 325 [0/25046 (0%)]	Loss: 0.132455
Train epoch: 325 [328980/25046 (41%)]	Loss: 0.214724
Train epoch: 325 [652240/25046 (82%)]	Loss: 0.166474
Make prediction for 5010 samples...
0.34921953 No improvement since epoch  308 ; best_mse,best_ci: 0.2766302 0.87093144228603 GCNNet davis
Training on 25046 samples...
Train epoch: 326 [0/25046 (0%)]	Loss: 0.166074
Train epoch: 326 [330120/25046 (41%)]	Loss: 0.167076
Train epoch: 326 [662240/25046 (82%)]	Loss: 0.178196
Make prediction for 5010 samples...
0.30081657 No improvement since epoch  308 ; best_mse,best_ci: 0.2766302 0.87093144228603 GCNNet davis
Training on 25046 samples...
Train epoch: 327 [0/25046 (0%)]	Loss: 0.150562
Train epoch: 327 [330960/25046 (41%)]	Loss: 0.212596
Train epoch: 327 [662560/25046 (82%)]	Loss: 0.190186
Make prediction for 5010 samples...
0.29476792 No improvement since epoch  308 ; best_mse,best_ci: 0.2766302 0.87093144228603 GCNNet davis
Training on 25046 samples...
Train epoch: 328 [0/25046 (0%)]	Loss: 0.170057
Train epoch: 328 [326380/25046 (41%)]	Loss: 0.217589
Train epoch: 328 [666480/25046 (82%)]	Loss: 0.152101
Make prediction for 5010 samples...
0.29051727 No improvement since epoch  308 ; best_mse,best_ci: 0.2766302 0.87093144228603 GCNNet davis
Training on 25046 samples...
Train epoch: 329 [0/25046 (0%)]	Loss: 0.150614
Train epoch: 329 [331880/25046 (41%)]	Loss: 0.186141
Train epoch: 329 [650600/25046 (82%)]	Loss: 0.195514
Make prediction for 5010 samples...
0.28657937 No improvement since epoch  308 ; best_mse,best_ci: 0.2766302 0.87093144228603 GCNNet davis
Training on 25046 samples...
Train epoch: 330 [0/25046 (0%)]	Loss: 0.150561
Train epoch: 330 [327700/25046 (41%)]	Loss: 0.143121
Train epoch: 330 [661800/25046 (82%)]	Loss: 0.195251
Make prediction for 5010 samples...
0.2928789 No improvement since epoch  308 ; best_mse,best_ci: 0.2766302 0.87093144228603 GCNNet davis
Training on 25046 samples...
Train epoch: 331 [0/25046 (0%)]	Loss: 0.161131
Train epoch: 331 [326260/25046 (41%)]	Loss: 0.155587
Train epoch: 331 [654720/25046 (82%)]	Loss: 0.145089
Make prediction for 5010 samples...
0.3474593 No improvement since epoch  308 ; best_mse,best_ci: 0.2766302 0.87093144228603 GCNNet davis
Training on 25046 samples...
Train epoch: 332 [0/25046 (0%)]	Loss: 0.177496
Train epoch: 332 [328200/25046 (41%)]	Loss: 0.185082
Train epoch: 332 [658800/25046 (82%)]	Loss: 0.131063
Make prediction for 5010 samples...
0.30332837 No improvement since epoch  308 ; best_mse,best_ci: 0.2766302 0.87093144228603 GCNNet davis
Training on 25046 samples...
Train epoch: 333 [0/25046 (0%)]	Loss: 0.122580
Train epoch: 333 [326280/25046 (41%)]	Loss: 0.143664
Train epoch: 333 [657520/25046 (82%)]	Loss: 0.165736
Make prediction for 5010 samples...
0.2995816 No improvement since epoch  308 ; best_mse,best_ci: 0.2766302 0.87093144228603 GCNNet davis
Training on 25046 samples...
Train epoch: 334 [0/25046 (0%)]	Loss: 0.160460
Train epoch: 334 [325640/25046 (41%)]	Loss: 0.152135
Train epoch: 334 [653680/25046 (82%)]	Loss: 0.173215
Make prediction for 5010 samples...
0.30489618 No improvement since epoch  308 ; best_mse,best_ci: 0.2766302 0.87093144228603 GCNNet davis
Training on 25046 samples...
Train epoch: 335 [0/25046 (0%)]	Loss: 0.161282
Train epoch: 335 [325000/25046 (41%)]	Loss: 0.141696
Train epoch: 335 [658480/25046 (82%)]	Loss: 0.139136
Make prediction for 5010 samples...
0.2799232 No improvement since epoch  308 ; best_mse,best_ci: 0.2766302 0.87093144228603 GCNNet davis
Training on 25046 samples...
Train epoch: 336 [0/25046 (0%)]	Loss: 0.163959
Train epoch: 336 [329340/25046 (41%)]	Loss: 0.145628
Train epoch: 336 [668160/25046 (82%)]	Loss: 0.138374
Make prediction for 5010 samples...
0.2991351 No improvement since epoch  308 ; best_mse,best_ci: 0.2766302 0.87093144228603 GCNNet davis
Training on 25046 samples...
Train epoch: 337 [0/25046 (0%)]	Loss: 0.112626
Train epoch: 337 [330180/25046 (41%)]	Loss: 0.169927
Train epoch: 337 [664080/25046 (82%)]	Loss: 0.189014
Make prediction for 5010 samples...
0.32133156 No improvement since epoch  308 ; best_mse,best_ci: 0.2766302 0.87093144228603 GCNNet davis
Training on 25046 samples...
Train epoch: 338 [0/25046 (0%)]	Loss: 0.162403
Train epoch: 338 [328520/25046 (41%)]	Loss: 0.145674
Train epoch: 338 [654480/25046 (82%)]	Loss: 0.193398
Make prediction for 5010 samples...
0.30558574 No improvement since epoch  308 ; best_mse,best_ci: 0.2766302 0.87093144228603 GCNNet davis
Training on 25046 samples...
Train epoch: 339 [0/25046 (0%)]	Loss: 0.174437
Train epoch: 339 [328820/25046 (41%)]	Loss: 0.166371
Train epoch: 339 [666280/25046 (82%)]	Loss: 0.184169
Make prediction for 5010 samples...
0.2971174 No improvement since epoch  308 ; best_mse,best_ci: 0.2766302 0.87093144228603 GCNNet davis
Training on 25046 samples...
Train epoch: 340 [0/25046 (0%)]	Loss: 0.152966
Train epoch: 340 [327360/25046 (41%)]	Loss: 0.203538
Train epoch: 340 [660240/25046 (82%)]	Loss: 0.183111
Make prediction for 5010 samples...
0.2997244 No improvement since epoch  308 ; best_mse,best_ci: 0.2766302 0.87093144228603 GCNNet davis
Training on 25046 samples...
Train epoch: 341 [0/25046 (0%)]	Loss: 0.162404
Train epoch: 341 [332920/25046 (41%)]	Loss: 0.181375
Train epoch: 341 [659720/25046 (82%)]	Loss: 0.153733
Make prediction for 5010 samples...
0.30724505 No improvement since epoch  308 ; best_mse,best_ci: 0.2766302 0.87093144228603 GCNNet davis
Training on 25046 samples...
Train epoch: 342 [0/25046 (0%)]	Loss: 0.162657
Train epoch: 342 [329400/25046 (41%)]	Loss: 0.174974
Train epoch: 342 [661720/25046 (82%)]	Loss: 0.193380
Make prediction for 5010 samples...
0.29734272 No improvement since epoch  308 ; best_mse,best_ci: 0.2766302 0.87093144228603 GCNNet davis
Training on 25046 samples...
Train epoch: 343 [0/25046 (0%)]	Loss: 0.147074
Train epoch: 343 [329140/25046 (41%)]	Loss: 0.181726
Train epoch: 343 [656520/25046 (82%)]	Loss: 0.187133
Make prediction for 5010 samples...
0.27667585 No improvement since epoch  308 ; best_mse,best_ci: 0.2766302 0.87093144228603 GCNNet davis
Training on 25046 samples...
Train epoch: 344 [0/25046 (0%)]	Loss: 0.162868
Train epoch: 344 [330820/25046 (41%)]	Loss: 0.217797
Train epoch: 344 [648480/25046 (82%)]	Loss: 0.149387
Make prediction for 5010 samples...
0.28932485 No improvement since epoch  308 ; best_mse,best_ci: 0.2766302 0.87093144228603 GCNNet davis
Training on 25046 samples...
Train epoch: 345 [0/25046 (0%)]	Loss: 0.151284
Train epoch: 345 [327240/25046 (41%)]	Loss: 0.170550
Train epoch: 345 [653640/25046 (82%)]	Loss: 0.139545
Make prediction for 5010 samples...
0.29229048 No improvement since epoch  308 ; best_mse,best_ci: 0.2766302 0.87093144228603 GCNNet davis
Training on 25046 samples...
Train epoch: 346 [0/25046 (0%)]	Loss: 0.139641
Train epoch: 346 [323080/25046 (41%)]	Loss: 0.143976
Train epoch: 346 [657080/25046 (82%)]	Loss: 0.183134
Make prediction for 5010 samples...
0.30922344 No improvement since epoch  308 ; best_mse,best_ci: 0.2766302 0.87093144228603 GCNNet davis
Training on 25046 samples...
Train epoch: 347 [0/25046 (0%)]	Loss: 0.160709
Train epoch: 347 [328680/25046 (41%)]	Loss: 0.144663
Train epoch: 347 [666440/25046 (82%)]	Loss: 0.144654
Make prediction for 5010 samples...
0.2999366 No improvement since epoch  308 ; best_mse,best_ci: 0.2766302 0.87093144228603 GCNNet davis
Training on 25046 samples...
Train epoch: 348 [0/25046 (0%)]	Loss: 0.175883
Train epoch: 348 [332460/25046 (41%)]	Loss: 0.154954
Train epoch: 348 [656320/25046 (82%)]	Loss: 0.152884
Make prediction for 5010 samples...
0.2924547 No improvement since epoch  308 ; best_mse,best_ci: 0.2766302 0.87093144228603 GCNNet davis
Training on 25046 samples...
Train epoch: 349 [0/25046 (0%)]	Loss: 0.204055
Train epoch: 349 [330500/25046 (41%)]	Loss: 0.176373
Train epoch: 349 [646160/25046 (82%)]	Loss: 0.153942
Make prediction for 5010 samples...
0.31073123 No improvement since epoch  308 ; best_mse,best_ci: 0.2766302 0.87093144228603 GCNNet davis
Training on 25046 samples...
Train epoch: 350 [0/25046 (0%)]	Loss: 0.147555
Train epoch: 350 [330600/25046 (41%)]	Loss: 0.178883
Train epoch: 350 [666080/25046 (82%)]	Loss: 0.168136
Make prediction for 5010 samples...
0.31153005 No improvement since epoch  308 ; best_mse,best_ci: 0.2766302 0.87093144228603 GCNNet davis
Training on 25046 samples...
Train epoch: 351 [0/25046 (0%)]	Loss: 0.164895
Train epoch: 351 [328100/25046 (41%)]	Loss: 0.149213
Train epoch: 351 [649360/25046 (82%)]	Loss: 0.160126
Make prediction for 5010 samples...
0.29496193 No improvement since epoch  308 ; best_mse,best_ci: 0.2766302 0.87093144228603 GCNNet davis
Training on 25046 samples...
Train epoch: 352 [0/25046 (0%)]	Loss: 0.189492
Train epoch: 352 [322220/25046 (41%)]	Loss: 0.196593
Train epoch: 352 [658960/25046 (82%)]	Loss: 0.181274
Make prediction for 5010 samples...
0.30439627 No improvement since epoch  308 ; best_mse,best_ci: 0.2766302 0.87093144228603 GCNNet davis
Training on 25046 samples...
Train epoch: 353 [0/25046 (0%)]	Loss: 0.122689
Train epoch: 353 [326820/25046 (41%)]	Loss: 0.130152
Train epoch: 353 [651080/25046 (82%)]	Loss: 0.135806
Make prediction for 5010 samples...
0.32188553 No improvement since epoch  308 ; best_mse,best_ci: 0.2766302 0.87093144228603 GCNNet davis
Training on 25046 samples...
Train epoch: 354 [0/25046 (0%)]	Loss: 0.187419
Train epoch: 354 [327800/25046 (41%)]	Loss: 0.240523
Train epoch: 354 [652920/25046 (82%)]	Loss: 0.181529
Make prediction for 5010 samples...
0.3196454 No improvement since epoch  308 ; best_mse,best_ci: 0.2766302 0.87093144228603 GCNNet davis
Training on 25046 samples...
Train epoch: 355 [0/25046 (0%)]	Loss: 0.149348
Train epoch: 355 [331300/25046 (41%)]	Loss: 0.114248
Train epoch: 355 [654840/25046 (82%)]	Loss: 0.110785
Make prediction for 5010 samples...
0.29762936 No improvement since epoch  308 ; best_mse,best_ci: 0.2766302 0.87093144228603 GCNNet davis
Training on 25046 samples...
Train epoch: 356 [0/25046 (0%)]	Loss: 0.137741
Train epoch: 356 [327140/25046 (41%)]	Loss: 0.147122
Train epoch: 356 [656440/25046 (82%)]	Loss: 0.151104
Make prediction for 5010 samples...
0.29865396 No improvement since epoch  308 ; best_mse,best_ci: 0.2766302 0.87093144228603 GCNNet davis
Training on 25046 samples...
Train epoch: 357 [0/25046 (0%)]	Loss: 0.128673
Train epoch: 357 [328960/25046 (41%)]	Loss: 0.280045
Train epoch: 357 [651320/25046 (82%)]	Loss: 0.143661
Make prediction for 5010 samples...
0.29044902 No improvement since epoch  308 ; best_mse,best_ci: 0.2766302 0.87093144228603 GCNNet davis
Training on 25046 samples...
Train epoch: 358 [0/25046 (0%)]	Loss: 0.150077
Train epoch: 358 [326940/25046 (41%)]	Loss: 0.115015
Train epoch: 358 [652360/25046 (82%)]	Loss: 0.165656
Make prediction for 5010 samples...
0.3364869 No improvement since epoch  308 ; best_mse,best_ci: 0.2766302 0.87093144228603 GCNNet davis
Training on 25046 samples...
Train epoch: 359 [0/25046 (0%)]	Loss: 0.193740
Train epoch: 359 [320280/25046 (41%)]	Loss: 0.158256
Train epoch: 359 [658400/25046 (82%)]	Loss: 0.160192
Make prediction for 5010 samples...
0.3144501 No improvement since epoch  308 ; best_mse,best_ci: 0.2766302 0.87093144228603 GCNNet davis
Training on 25046 samples...
Train epoch: 360 [0/25046 (0%)]	Loss: 0.200998
Train epoch: 360 [325400/25046 (41%)]	Loss: 0.151729
Train epoch: 360 [654720/25046 (82%)]	Loss: 0.127802
Make prediction for 5010 samples...
0.3077572 No improvement since epoch  308 ; best_mse,best_ci: 0.2766302 0.87093144228603 GCNNet davis
Training on 25046 samples...
Train epoch: 361 [0/25046 (0%)]	Loss: 0.167620
Train epoch: 361 [328740/25046 (41%)]	Loss: 0.161853
Train epoch: 361 [657080/25046 (82%)]	Loss: 0.201311
Make prediction for 5010 samples...
0.3215118 No improvement since epoch  308 ; best_mse,best_ci: 0.2766302 0.87093144228603 GCNNet davis
Training on 25046 samples...
Train epoch: 362 [0/25046 (0%)]	Loss: 0.166337
Train epoch: 362 [327280/25046 (41%)]	Loss: 0.173642
Train epoch: 362 [659960/25046 (82%)]	Loss: 0.139952
Make prediction for 5010 samples...
0.29607296 No improvement since epoch  308 ; best_mse,best_ci: 0.2766302 0.87093144228603 GCNNet davis
Training on 25046 samples...
Train epoch: 363 [0/25046 (0%)]	Loss: 0.134367
Train epoch: 363 [328320/25046 (41%)]	Loss: 0.147793
Train epoch: 363 [659560/25046 (82%)]	Loss: 0.187267
Make prediction for 5010 samples...
0.29568398 No improvement since epoch  308 ; best_mse,best_ci: 0.2766302 0.87093144228603 GCNNet davis
Training on 25046 samples...
Train epoch: 364 [0/25046 (0%)]	Loss: 0.150731
Train epoch: 364 [326240/25046 (41%)]	Loss: 0.199998
Train epoch: 364 [666560/25046 (82%)]	Loss: 0.181055
Make prediction for 5010 samples...
0.2930609 No improvement since epoch  308 ; best_mse,best_ci: 0.2766302 0.87093144228603 GCNNet davis
Training on 25046 samples...
Train epoch: 365 [0/25046 (0%)]	Loss: 0.131241
Train epoch: 365 [329840/25046 (41%)]	Loss: 0.124464
Train epoch: 365 [651360/25046 (82%)]	Loss: 0.174564
Make prediction for 5010 samples...
0.28413948 No improvement since epoch  308 ; best_mse,best_ci: 0.2766302 0.87093144228603 GCNNet davis
Training on 25046 samples...
Train epoch: 366 [0/25046 (0%)]	Loss: 0.132728
Train epoch: 366 [329660/25046 (41%)]	Loss: 0.227296
Train epoch: 366 [653400/25046 (82%)]	Loss: 0.134211
Make prediction for 5010 samples...
0.32380533 No improvement since epoch  308 ; best_mse,best_ci: 0.2766302 0.87093144228603 GCNNet davis
Training on 25046 samples...
Train epoch: 367 [0/25046 (0%)]	Loss: 0.149047
Train epoch: 367 [330260/25046 (41%)]	Loss: 0.210651
Train epoch: 367 [653360/25046 (82%)]	Loss: 0.146437
Make prediction for 5010 samples...
0.29617473 No improvement since epoch  308 ; best_mse,best_ci: 0.2766302 0.87093144228603 GCNNet davis
Training on 25046 samples...
Train epoch: 368 [0/25046 (0%)]	Loss: 0.156662
Train epoch: 368 [329140/25046 (41%)]	Loss: 0.158551
Train epoch: 368 [661600/25046 (82%)]	Loss: 0.133896
Make prediction for 5010 samples...
0.31451637 No improvement since epoch  308 ; best_mse,best_ci: 0.2766302 0.87093144228603 GCNNet davis
Training on 25046 samples...
Train epoch: 369 [0/25046 (0%)]	Loss: 0.150135
Train epoch: 369 [330560/25046 (41%)]	Loss: 0.146348
Train epoch: 369 [648080/25046 (82%)]	Loss: 0.150157
Make prediction for 5010 samples...
0.29333872 No improvement since epoch  308 ; best_mse,best_ci: 0.2766302 0.87093144228603 GCNNet davis
Training on 25046 samples...
Train epoch: 370 [0/25046 (0%)]	Loss: 0.137495
Train epoch: 370 [328860/25046 (41%)]	Loss: 0.112437
Train epoch: 370 [661840/25046 (82%)]	Loss: 0.145406
Make prediction for 5010 samples...
0.304986 No improvement since epoch  308 ; best_mse,best_ci: 0.2766302 0.87093144228603 GCNNet davis
Training on 25046 samples...
Train epoch: 371 [0/25046 (0%)]	Loss: 0.164120
Train epoch: 371 [328080/25046 (41%)]	Loss: 0.166627
Train epoch: 371 [655640/25046 (82%)]	Loss: 0.166187
Make prediction for 5010 samples...
0.303206 No improvement since epoch  308 ; best_mse,best_ci: 0.2766302 0.87093144228603 GCNNet davis
Training on 25046 samples...
Train epoch: 372 [0/25046 (0%)]	Loss: 0.147142
Train epoch: 372 [328700/25046 (41%)]	Loss: 0.159378
Train epoch: 372 [663280/25046 (82%)]	Loss: 0.186026
Make prediction for 5010 samples...
0.29733717 No improvement since epoch  308 ; best_mse,best_ci: 0.2766302 0.87093144228603 GCNNet davis
Training on 25046 samples...
Train epoch: 373 [0/25046 (0%)]	Loss: 0.174862
Train epoch: 373 [325900/25046 (41%)]	Loss: 0.182791
Train epoch: 373 [654760/25046 (82%)]	Loss: 0.153475
Make prediction for 5010 samples...
0.28066987 No improvement since epoch  308 ; best_mse,best_ci: 0.2766302 0.87093144228603 GCNNet davis
Training on 25046 samples...
Train epoch: 374 [0/25046 (0%)]	Loss: 0.165581
Train epoch: 374 [326340/25046 (41%)]	Loss: 0.113815
Train epoch: 374 [648920/25046 (82%)]	Loss: 0.178681
Make prediction for 5010 samples...
0.2920971 No improvement since epoch  308 ; best_mse,best_ci: 0.2766302 0.87093144228603 GCNNet davis
Training on 25046 samples...
Train epoch: 375 [0/25046 (0%)]	Loss: 0.157264
Train epoch: 375 [325080/25046 (41%)]	Loss: 0.189769
Train epoch: 375 [657960/25046 (82%)]	Loss: 0.148918
Make prediction for 5010 samples...
0.33078942 No improvement since epoch  308 ; best_mse,best_ci: 0.2766302 0.87093144228603 GCNNet davis
Training on 25046 samples...
Train epoch: 376 [0/25046 (0%)]	Loss: 0.166193
Train epoch: 376 [326820/25046 (41%)]	Loss: 0.136588
Train epoch: 376 [647800/25046 (82%)]	Loss: 0.145558
Make prediction for 5010 samples...
0.33163974 No improvement since epoch  308 ; best_mse,best_ci: 0.2766302 0.87093144228603 GCNNet davis
Training on 25046 samples...
Train epoch: 377 [0/25046 (0%)]	Loss: 0.143916
Train epoch: 377 [330120/25046 (41%)]	Loss: 0.129439
Train epoch: 377 [661600/25046 (82%)]	Loss: 0.153939
Make prediction for 5010 samples...
0.30081832 No improvement since epoch  308 ; best_mse,best_ci: 0.2766302 0.87093144228603 GCNNet davis
Training on 25046 samples...
Train epoch: 378 [0/25046 (0%)]	Loss: 0.137036
Train epoch: 378 [323380/25046 (41%)]	Loss: 0.145807
Train epoch: 378 [663400/25046 (82%)]	Loss: 0.163279
Make prediction for 5010 samples...
0.29230422 No improvement since epoch  308 ; best_mse,best_ci: 0.2766302 0.87093144228603 GCNNet davis
Training on 25046 samples...
Train epoch: 379 [0/25046 (0%)]	Loss: 0.134248
Train epoch: 379 [325500/25046 (41%)]	Loss: 0.138180
Train epoch: 379 [650120/25046 (82%)]	Loss: 0.163041
Make prediction for 5010 samples...
0.31340533 No improvement since epoch  308 ; best_mse,best_ci: 0.2766302 0.87093144228603 GCNNet davis
Training on 25046 samples...
Train epoch: 380 [0/25046 (0%)]	Loss: 0.129379
Train epoch: 380 [327560/25046 (41%)]	Loss: 0.178214
Train epoch: 380 [653320/25046 (82%)]	Loss: 0.141545
Make prediction for 5010 samples...
0.28836727 No improvement since epoch  308 ; best_mse,best_ci: 0.2766302 0.87093144228603 GCNNet davis
Training on 25046 samples...
Train epoch: 381 [0/25046 (0%)]	Loss: 0.158848
Train epoch: 381 [326120/25046 (41%)]	Loss: 0.150948
Train epoch: 381 [665240/25046 (82%)]	Loss: 0.153768
Make prediction for 5010 samples...
0.3064941 No improvement since epoch  308 ; best_mse,best_ci: 0.2766302 0.87093144228603 GCNNet davis
Training on 25046 samples...
Train epoch: 382 [0/25046 (0%)]	Loss: 0.154357
Train epoch: 382 [331540/25046 (41%)]	Loss: 0.143496
Train epoch: 382 [658400/25046 (82%)]	Loss: 0.146102
Make prediction for 5010 samples...
0.29844928 No improvement since epoch  308 ; best_mse,best_ci: 0.2766302 0.87093144228603 GCNNet davis
Training on 25046 samples...
Train epoch: 383 [0/25046 (0%)]	Loss: 0.144078
Train epoch: 383 [328040/25046 (41%)]	Loss: 0.115843
Train epoch: 383 [655880/25046 (82%)]	Loss: 0.151084
Make prediction for 5010 samples...
0.35283545 No improvement since epoch  308 ; best_mse,best_ci: 0.2766302 0.87093144228603 GCNNet davis
Training on 25046 samples...
Train epoch: 384 [0/25046 (0%)]	Loss: 0.159855
Train epoch: 384 [325640/25046 (41%)]	Loss: 0.184938
Train epoch: 384 [651680/25046 (82%)]	Loss: 0.163800
Make prediction for 5010 samples...
0.2934194 No improvement since epoch  308 ; best_mse,best_ci: 0.2766302 0.87093144228603 GCNNet davis
Training on 25046 samples...
Train epoch: 385 [0/25046 (0%)]	Loss: 0.151208
Train epoch: 385 [329920/25046 (41%)]	Loss: 0.144365
Train epoch: 385 [653760/25046 (82%)]	Loss: 0.140953
Make prediction for 5010 samples...
0.27945584 No improvement since epoch  308 ; best_mse,best_ci: 0.2766302 0.87093144228603 GCNNet davis
Training on 25046 samples...
Train epoch: 386 [0/25046 (0%)]	Loss: 0.144115
Train epoch: 386 [326580/25046 (41%)]	Loss: 0.158064
Train epoch: 386 [660640/25046 (82%)]	Loss: 0.152028
Make prediction for 5010 samples...
rmse improved at epoch  386 ; best_mse,best_ci: 0.2759762 0.8627985002679406 GCNNet davis
Training on 25046 samples...
Train epoch: 387 [0/25046 (0%)]	Loss: 0.131201
Train epoch: 387 [327260/25046 (41%)]	Loss: 0.174852
Train epoch: 387 [647200/25046 (82%)]	Loss: 0.140429
Make prediction for 5010 samples...
0.28152698 No improvement since epoch  386 ; best_mse,best_ci: 0.2759762 0.8627985002679406 GCNNet davis
Training on 25046 samples...
Train epoch: 388 [0/25046 (0%)]	Loss: 0.142686
Train epoch: 388 [325500/25046 (41%)]	Loss: 0.127979
Train epoch: 388 [667280/25046 (82%)]	Loss: 0.195803
Make prediction for 5010 samples...
0.29370907 No improvement since epoch  386 ; best_mse,best_ci: 0.2759762 0.8627985002679406 GCNNet davis
Training on 25046 samples...
Train epoch: 389 [0/25046 (0%)]	Loss: 0.182209
Train epoch: 389 [324980/25046 (41%)]	Loss: 0.154012
Train epoch: 389 [651000/25046 (82%)]	Loss: 0.140190
Make prediction for 5010 samples...
0.28548494 No improvement since epoch  386 ; best_mse,best_ci: 0.2759762 0.8627985002679406 GCNNet davis
Training on 25046 samples...
Train epoch: 390 [0/25046 (0%)]	Loss: 0.113313
Train epoch: 390 [325440/25046 (41%)]	Loss: 0.291243
Train epoch: 390 [666280/25046 (82%)]	Loss: 0.144521
Make prediction for 5010 samples...
0.2864246 No improvement since epoch  386 ; best_mse,best_ci: 0.2759762 0.8627985002679406 GCNNet davis
Training on 25046 samples...
Train epoch: 391 [0/25046 (0%)]	Loss: 0.145021
Train epoch: 391 [335960/25046 (41%)]	Loss: 0.208071
Train epoch: 391 [643400/25046 (82%)]	Loss: 0.152710
Make prediction for 5010 samples...
0.29786593 No improvement since epoch  386 ; best_mse,best_ci: 0.2759762 0.8627985002679406 GCNNet davis
Training on 25046 samples...
Train epoch: 392 [0/25046 (0%)]	Loss: 0.130408
Train epoch: 392 [326040/25046 (41%)]	Loss: 0.135581
Train epoch: 392 [656280/25046 (82%)]	Loss: 0.156509
Make prediction for 5010 samples...
0.285103 No improvement since epoch  386 ; best_mse,best_ci: 0.2759762 0.8627985002679406 GCNNet davis
Training on 25046 samples...
Train epoch: 393 [0/25046 (0%)]	Loss: 0.158256
Train epoch: 393 [326640/25046 (41%)]	Loss: 0.153060
Train epoch: 393 [655360/25046 (82%)]	Loss: 0.170375
Make prediction for 5010 samples...
0.29179913 No improvement since epoch  386 ; best_mse,best_ci: 0.2759762 0.8627985002679406 GCNNet davis
Training on 25046 samples...
Train epoch: 394 [0/25046 (0%)]	Loss: 0.117730
Train epoch: 394 [330480/25046 (41%)]	Loss: 0.194192
Train epoch: 394 [665000/25046 (82%)]	Loss: 0.164797
Make prediction for 5010 samples...
0.29872823 No improvement since epoch  386 ; best_mse,best_ci: 0.2759762 0.8627985002679406 GCNNet davis
Training on 25046 samples...
Train epoch: 395 [0/25046 (0%)]	Loss: 0.114892
Train epoch: 395 [327080/25046 (41%)]	Loss: 0.149766
Train epoch: 395 [643360/25046 (82%)]	Loss: 0.163809
Make prediction for 5010 samples...
0.29610282 No improvement since epoch  386 ; best_mse,best_ci: 0.2759762 0.8627985002679406 GCNNet davis
Training on 25046 samples...
Train epoch: 396 [0/25046 (0%)]	Loss: 0.162308
Train epoch: 396 [330680/25046 (41%)]	Loss: 0.115768
Train epoch: 396 [658120/25046 (82%)]	Loss: 0.166949
Make prediction for 5010 samples...
0.31541836 No improvement since epoch  386 ; best_mse,best_ci: 0.2759762 0.8627985002679406 GCNNet davis
Training on 25046 samples...
Train epoch: 397 [0/25046 (0%)]	Loss: 0.158740
Train epoch: 397 [331980/25046 (41%)]	Loss: 0.164860
Train epoch: 397 [651320/25046 (82%)]	Loss: 0.188803
Make prediction for 5010 samples...
0.28825203 No improvement since epoch  386 ; best_mse,best_ci: 0.2759762 0.8627985002679406 GCNNet davis
Training on 25046 samples...
Train epoch: 398 [0/25046 (0%)]	Loss: 0.141148
Train epoch: 398 [327720/25046 (41%)]	Loss: 0.120660
Train epoch: 398 [659560/25046 (82%)]	Loss: 0.167380
Make prediction for 5010 samples...
0.28595883 No improvement since epoch  386 ; best_mse,best_ci: 0.2759762 0.8627985002679406 GCNNet davis
Training on 25046 samples...
Train epoch: 399 [0/25046 (0%)]	Loss: 0.118210
Train epoch: 399 [328340/25046 (41%)]	Loss: 0.166314
Train epoch: 399 [649720/25046 (82%)]	Loss: 0.131187
Make prediction for 5010 samples...
0.30484134 No improvement since epoch  386 ; best_mse,best_ci: 0.2759762 0.8627985002679406 GCNNet davis
Training on 25046 samples...
Train epoch: 400 [0/25046 (0%)]	Loss: 0.116150
Train epoch: 400 [328440/25046 (41%)]	Loss: 0.170915
Train epoch: 400 [649400/25046 (82%)]	Loss: 0.183548
Make prediction for 5010 samples...
0.29845598 No improvement since epoch  386 ; best_mse,best_ci: 0.2759762 0.8627985002679406 GCNNet davis
Training on 25046 samples...
Train epoch: 401 [0/25046 (0%)]	Loss: 0.175180
Train epoch: 401 [333960/25046 (41%)]	Loss: 0.142470
Train epoch: 401 [659920/25046 (82%)]	Loss: 0.130232
Make prediction for 5010 samples...
0.31205434 No improvement since epoch  386 ; best_mse,best_ci: 0.2759762 0.8627985002679406 GCNNet davis
Training on 25046 samples...
Train epoch: 402 [0/25046 (0%)]	Loss: 0.140199
Train epoch: 402 [323740/25046 (41%)]	Loss: 0.169654
Train epoch: 402 [661120/25046 (82%)]	Loss: 0.130537
Make prediction for 5010 samples...
0.2842863 No improvement since epoch  386 ; best_mse,best_ci: 0.2759762 0.8627985002679406 GCNNet davis
Training on 25046 samples...
Train epoch: 403 [0/25046 (0%)]	Loss: 0.135786
Train epoch: 403 [329020/25046 (41%)]	Loss: 0.131504
Train epoch: 403 [661360/25046 (82%)]	Loss: 0.172336
Make prediction for 5010 samples...
0.2981369 No improvement since epoch  386 ; best_mse,best_ci: 0.2759762 0.8627985002679406 GCNNet davis
Training on 25046 samples...
Train epoch: 404 [0/25046 (0%)]	Loss: 0.183591
Train epoch: 404 [330840/25046 (41%)]	Loss: 0.142068
Train epoch: 404 [650080/25046 (82%)]	Loss: 0.157308
Make prediction for 5010 samples...
0.29224437 No improvement since epoch  386 ; best_mse,best_ci: 0.2759762 0.8627985002679406 GCNNet davis
Training on 25046 samples...
Train epoch: 405 [0/25046 (0%)]	Loss: 0.203753
Train epoch: 405 [326460/25046 (41%)]	Loss: 0.138927
Train epoch: 405 [661680/25046 (82%)]	Loss: 0.146655
Make prediction for 5010 samples...
0.31451166 No improvement since epoch  386 ; best_mse,best_ci: 0.2759762 0.8627985002679406 GCNNet davis
Training on 25046 samples...
Train epoch: 406 [0/25046 (0%)]	Loss: 0.156077
Train epoch: 406 [326520/25046 (41%)]	Loss: 0.126364
Train epoch: 406 [654280/25046 (82%)]	Loss: 0.122161
Make prediction for 5010 samples...
0.2902146 No improvement since epoch  386 ; best_mse,best_ci: 0.2759762 0.8627985002679406 GCNNet davis
Training on 25046 samples...
Train epoch: 407 [0/25046 (0%)]	Loss: 0.118341
Train epoch: 407 [328400/25046 (41%)]	Loss: 0.129989
Train epoch: 407 [650440/25046 (82%)]	Loss: 0.186879
Make prediction for 5010 samples...
0.30743864 No improvement since epoch  386 ; best_mse,best_ci: 0.2759762 0.8627985002679406 GCNNet davis
Training on 25046 samples...
Train epoch: 408 [0/25046 (0%)]	Loss: 0.143254
Train epoch: 408 [330540/25046 (41%)]	Loss: 0.148486
Train epoch: 408 [660120/25046 (82%)]	Loss: 0.145248
Make prediction for 5010 samples...
0.2988821 No improvement since epoch  386 ; best_mse,best_ci: 0.2759762 0.8627985002679406 GCNNet davis
Training on 25046 samples...
Train epoch: 409 [0/25046 (0%)]	Loss: 0.131963
Train epoch: 409 [332500/25046 (41%)]	Loss: 0.177974
Train epoch: 409 [654840/25046 (82%)]	Loss: 0.150745
Make prediction for 5010 samples...
0.29056984 No improvement since epoch  386 ; best_mse,best_ci: 0.2759762 0.8627985002679406 GCNNet davis
Training on 25046 samples...
Train epoch: 410 [0/25046 (0%)]	Loss: 0.132615
Train epoch: 410 [328680/25046 (41%)]	Loss: 0.142253
Train epoch: 410 [651560/25046 (82%)]	Loss: 0.157362
Make prediction for 5010 samples...
0.2820052 No improvement since epoch  386 ; best_mse,best_ci: 0.2759762 0.8627985002679406 GCNNet davis
Training on 25046 samples...
Train epoch: 411 [0/25046 (0%)]	Loss: 0.160410
Train epoch: 411 [329080/25046 (41%)]	Loss: 0.118296
Train epoch: 411 [661360/25046 (82%)]	Loss: 0.224344
Make prediction for 5010 samples...
0.29517314 No improvement since epoch  386 ; best_mse,best_ci: 0.2759762 0.8627985002679406 GCNNet davis
Training on 25046 samples...
Train epoch: 412 [0/25046 (0%)]	Loss: 0.153891
Train epoch: 412 [329520/25046 (41%)]	Loss: 0.119583
Train epoch: 412 [650720/25046 (82%)]	Loss: 0.160827
Make prediction for 5010 samples...
0.30461538 No improvement since epoch  386 ; best_mse,best_ci: 0.2759762 0.8627985002679406 GCNNet davis
Training on 25046 samples...
Train epoch: 413 [0/25046 (0%)]	Loss: 0.130025
Train epoch: 413 [332280/25046 (41%)]	Loss: 0.165207
Train epoch: 413 [656560/25046 (82%)]	Loss: 0.174776
Make prediction for 5010 samples...
0.2999286 No improvement since epoch  386 ; best_mse,best_ci: 0.2759762 0.8627985002679406 GCNNet davis
Training on 25046 samples...
Train epoch: 414 [0/25046 (0%)]	Loss: 0.119673
Train epoch: 414 [328740/25046 (41%)]	Loss: 0.151960
Train epoch: 414 [656160/25046 (82%)]	Loss: 0.164450
Make prediction for 5010 samples...
0.28477278 No improvement since epoch  386 ; best_mse,best_ci: 0.2759762 0.8627985002679406 GCNNet davis
Training on 25046 samples...
Train epoch: 415 [0/25046 (0%)]	Loss: 0.131021
Train epoch: 415 [325180/25046 (41%)]	Loss: 0.165128
Train epoch: 415 [651240/25046 (82%)]	Loss: 0.160893
Make prediction for 5010 samples...
0.27658853 No improvement since epoch  386 ; best_mse,best_ci: 0.2759762 0.8627985002679406 GCNNet davis
Training on 25046 samples...
Train epoch: 416 [0/25046 (0%)]	Loss: 0.148888
Train epoch: 416 [329140/25046 (41%)]	Loss: 0.120645
Train epoch: 416 [662360/25046 (82%)]	Loss: 0.175981
Make prediction for 5010 samples...
0.35017002 No improvement since epoch  386 ; best_mse,best_ci: 0.2759762 0.8627985002679406 GCNNet davis
Training on 25046 samples...
Train epoch: 417 [0/25046 (0%)]	Loss: 0.155025
Train epoch: 417 [329160/25046 (41%)]	Loss: 0.148112
Train epoch: 417 [659360/25046 (82%)]	Loss: 0.125901
Make prediction for 5010 samples...
0.32652143 No improvement since epoch  386 ; best_mse,best_ci: 0.2759762 0.8627985002679406 GCNNet davis
Training on 25046 samples...
Train epoch: 418 [0/25046 (0%)]	Loss: 0.149604
Train epoch: 418 [326740/25046 (41%)]	Loss: 0.147735
Train epoch: 418 [655640/25046 (82%)]	Loss: 0.146818
Make prediction for 5010 samples...
0.2854906 No improvement since epoch  386 ; best_mse,best_ci: 0.2759762 0.8627985002679406 GCNNet davis
Training on 25046 samples...
Train epoch: 419 [0/25046 (0%)]	Loss: 0.187115
Train epoch: 419 [325400/25046 (41%)]	Loss: 0.160833
Train epoch: 419 [648320/25046 (82%)]	Loss: 0.172087
Make prediction for 5010 samples...
0.3027838 No improvement since epoch  386 ; best_mse,best_ci: 0.2759762 0.8627985002679406 GCNNet davis
Training on 25046 samples...
Train epoch: 420 [0/25046 (0%)]	Loss: 0.151691
Train epoch: 420 [326460/25046 (41%)]	Loss: 0.158413
Train epoch: 420 [652400/25046 (82%)]	Loss: 0.176384
Make prediction for 5010 samples...
0.2990716 No improvement since epoch  386 ; best_mse,best_ci: 0.2759762 0.8627985002679406 GCNNet davis
Training on 25046 samples...
Train epoch: 421 [0/25046 (0%)]	Loss: 0.148781
Train epoch: 421 [326480/25046 (41%)]	Loss: 0.135628
Train epoch: 421 [651160/25046 (82%)]	Loss: 0.139119
Make prediction for 5010 samples...
0.28835723 No improvement since epoch  386 ; best_mse,best_ci: 0.2759762 0.8627985002679406 GCNNet davis
Training on 25046 samples...
Train epoch: 422 [0/25046 (0%)]	Loss: 0.151377
Train epoch: 422 [332460/25046 (41%)]	Loss: 0.156523
Train epoch: 422 [653760/25046 (82%)]	Loss: 0.118976
Make prediction for 5010 samples...
0.30914927 No improvement since epoch  386 ; best_mse,best_ci: 0.2759762 0.8627985002679406 GCNNet davis
Training on 25046 samples...
Train epoch: 423 [0/25046 (0%)]	Loss: 0.138551
Train epoch: 423 [331480/25046 (41%)]	Loss: 0.168562
Train epoch: 423 [653920/25046 (82%)]	Loss: 0.151114
Make prediction for 5010 samples...
0.2990595 No improvement since epoch  386 ; best_mse,best_ci: 0.2759762 0.8627985002679406 GCNNet davis
Training on 25046 samples...
Train epoch: 424 [0/25046 (0%)]	Loss: 0.130445
Train epoch: 424 [327260/25046 (41%)]	Loss: 0.122630
Train epoch: 424 [665920/25046 (82%)]	Loss: 0.161355
Make prediction for 5010 samples...
0.28963605 No improvement since epoch  386 ; best_mse,best_ci: 0.2759762 0.8627985002679406 GCNNet davis
Training on 25046 samples...
Train epoch: 425 [0/25046 (0%)]	Loss: 0.161194
Train epoch: 425 [327120/25046 (41%)]	Loss: 0.143326
Train epoch: 425 [655560/25046 (82%)]	Loss: 0.137634
Make prediction for 5010 samples...
0.3142752 No improvement since epoch  386 ; best_mse,best_ci: 0.2759762 0.8627985002679406 GCNNet davis
Training on 25046 samples...
Train epoch: 426 [0/25046 (0%)]	Loss: 0.157542
Train epoch: 426 [326880/25046 (41%)]	Loss: 0.136104
Train epoch: 426 [656320/25046 (82%)]	Loss: 0.159147
Make prediction for 5010 samples...
0.2955733 No improvement since epoch  386 ; best_mse,best_ci: 0.2759762 0.8627985002679406 GCNNet davis
Training on 25046 samples...
Train epoch: 427 [0/25046 (0%)]	Loss: 0.129793
Train epoch: 427 [328340/25046 (41%)]	Loss: 0.171801
Train epoch: 427 [660440/25046 (82%)]	Loss: 0.135660
Make prediction for 5010 samples...
0.2816156 No improvement since epoch  386 ; best_mse,best_ci: 0.2759762 0.8627985002679406 GCNNet davis
Training on 25046 samples...
Train epoch: 428 [0/25046 (0%)]	Loss: 0.122881
Train epoch: 428 [329120/25046 (41%)]	Loss: 0.157303
Train epoch: 428 [665760/25046 (82%)]	Loss: 0.145363
Make prediction for 5010 samples...
0.3241674 No improvement since epoch  386 ; best_mse,best_ci: 0.2759762 0.8627985002679406 GCNNet davis
Training on 25046 samples...
Train epoch: 429 [0/25046 (0%)]	Loss: 0.141749
Train epoch: 429 [323640/25046 (41%)]	Loss: 0.130303
Train epoch: 429 [645840/25046 (82%)]	Loss: 0.150249
Make prediction for 5010 samples...
0.3044855 No improvement since epoch  386 ; best_mse,best_ci: 0.2759762 0.8627985002679406 GCNNet davis
Training on 25046 samples...
Train epoch: 430 [0/25046 (0%)]	Loss: 0.144669
Train epoch: 430 [330520/25046 (41%)]	Loss: 0.157966
Train epoch: 430 [664440/25046 (82%)]	Loss: 0.153937
Make prediction for 5010 samples...
0.29615244 No improvement since epoch  386 ; best_mse,best_ci: 0.2759762 0.8627985002679406 GCNNet davis
Training on 25046 samples...
Train epoch: 431 [0/25046 (0%)]	Loss: 0.160560
Train epoch: 431 [324040/25046 (41%)]	Loss: 0.156937
Train epoch: 431 [660560/25046 (82%)]	Loss: 0.172144
Make prediction for 5010 samples...
0.2772506 No improvement since epoch  386 ; best_mse,best_ci: 0.2759762 0.8627985002679406 GCNNet davis
Training on 25046 samples...
Train epoch: 432 [0/25046 (0%)]	Loss: 0.148699
Train epoch: 432 [325040/25046 (41%)]	Loss: 0.142471
Train epoch: 432 [653440/25046 (82%)]	Loss: 0.162864
Make prediction for 5010 samples...
0.28348058 No improvement since epoch  386 ; best_mse,best_ci: 0.2759762 0.8627985002679406 GCNNet davis
Training on 25046 samples...
Train epoch: 433 [0/25046 (0%)]	Loss: 0.187516
Train epoch: 433 [330620/25046 (41%)]	Loss: 0.142095
Train epoch: 433 [656800/25046 (82%)]	Loss: 0.186076
Make prediction for 5010 samples...
0.27630788 No improvement since epoch  386 ; best_mse,best_ci: 0.2759762 0.8627985002679406 GCNNet davis
Training on 25046 samples...
Train epoch: 434 [0/25046 (0%)]	Loss: 0.141342
Train epoch: 434 [324960/25046 (41%)]	Loss: 0.150905
Train epoch: 434 [669280/25046 (82%)]	Loss: 0.196283
Make prediction for 5010 samples...
0.28970462 No improvement since epoch  386 ; best_mse,best_ci: 0.2759762 0.8627985002679406 GCNNet davis
Training on 25046 samples...
Train epoch: 435 [0/25046 (0%)]	Loss: 0.133305
Train epoch: 435 [328640/25046 (41%)]	Loss: 0.160445
Train epoch: 435 [659480/25046 (82%)]	Loss: 0.181546
Make prediction for 5010 samples...
0.28317052 No improvement since epoch  386 ; best_mse,best_ci: 0.2759762 0.8627985002679406 GCNNet davis
Training on 25046 samples...
Train epoch: 436 [0/25046 (0%)]	Loss: 0.150738
Train epoch: 436 [331500/25046 (41%)]	Loss: 0.145857
Train epoch: 436 [663480/25046 (82%)]	Loss: 0.108761
Make prediction for 5010 samples...
0.2848474 No improvement since epoch  386 ; best_mse,best_ci: 0.2759762 0.8627985002679406 GCNNet davis
Training on 25046 samples...
Train epoch: 437 [0/25046 (0%)]	Loss: 0.140680
Train epoch: 437 [326940/25046 (41%)]	Loss: 0.138542
Train epoch: 437 [649840/25046 (82%)]	Loss: 0.141664
Make prediction for 5010 samples...
0.29909036 No improvement since epoch  386 ; best_mse,best_ci: 0.2759762 0.8627985002679406 GCNNet davis
Training on 25046 samples...
Train epoch: 438 [0/25046 (0%)]	Loss: 0.143331
Train epoch: 438 [325400/25046 (41%)]	Loss: 0.114474
Train epoch: 438 [654600/25046 (82%)]	Loss: 0.198637
Make prediction for 5010 samples...
0.29210418 No improvement since epoch  386 ; best_mse,best_ci: 0.2759762 0.8627985002679406 GCNNet davis
Training on 25046 samples...
Train epoch: 439 [0/25046 (0%)]	Loss: 0.131328
Train epoch: 439 [330260/25046 (41%)]	Loss: 0.144626
Train epoch: 439 [646120/25046 (82%)]	Loss: 0.147919
Make prediction for 5010 samples...
0.2847602 No improvement since epoch  386 ; best_mse,best_ci: 0.2759762 0.8627985002679406 GCNNet davis
Training on 25046 samples...
Train epoch: 440 [0/25046 (0%)]	Loss: 0.181482
Train epoch: 440 [324660/25046 (41%)]	Loss: 0.197259
Train epoch: 440 [660920/25046 (82%)]	Loss: 0.127856
Make prediction for 5010 samples...
0.27909893 No improvement since epoch  386 ; best_mse,best_ci: 0.2759762 0.8627985002679406 GCNNet davis
Training on 25046 samples...
Train epoch: 441 [0/25046 (0%)]	Loss: 0.149032
Train epoch: 441 [327740/25046 (41%)]	Loss: 0.120800
Train epoch: 441 [663080/25046 (82%)]	Loss: 0.204490
Make prediction for 5010 samples...
0.2836879 No improvement since epoch  386 ; best_mse,best_ci: 0.2759762 0.8627985002679406 GCNNet davis
Training on 25046 samples...
Train epoch: 442 [0/25046 (0%)]	Loss: 0.143923
Train epoch: 442 [327420/25046 (41%)]	Loss: 0.139016
Train epoch: 442 [660360/25046 (82%)]	Loss: 0.123339
Make prediction for 5010 samples...
0.3127022 No improvement since epoch  386 ; best_mse,best_ci: 0.2759762 0.8627985002679406 GCNNet davis
Training on 25046 samples...
Train epoch: 443 [0/25046 (0%)]	Loss: 0.123905
Train epoch: 443 [328240/25046 (41%)]	Loss: 0.164803
Train epoch: 443 [652800/25046 (82%)]	Loss: 0.129703
Make prediction for 5010 samples...
rmse improved at epoch  443 ; best_mse,best_ci: 0.27554536 0.8734788303976777 GCNNet davis
Training on 25046 samples...
Train epoch: 444 [0/25046 (0%)]	Loss: 0.144984
Train epoch: 444 [328620/25046 (41%)]	Loss: 0.144393
Train epoch: 444 [652560/25046 (82%)]	Loss: 0.227190
Make prediction for 5010 samples...
0.38664562 No improvement since epoch  443 ; best_mse,best_ci: 0.27554536 0.8734788303976777 GCNNet davis
Training on 25046 samples...
Train epoch: 445 [0/25046 (0%)]	Loss: 0.214311
Train epoch: 445 [330320/25046 (41%)]	Loss: 0.150754
Train epoch: 445 [657960/25046 (82%)]	Loss: 0.183993
Make prediction for 5010 samples...
0.30791068 No improvement since epoch  443 ; best_mse,best_ci: 0.27554536 0.8734788303976777 GCNNet davis
Training on 25046 samples...
Train epoch: 446 [0/25046 (0%)]	Loss: 0.138306
Train epoch: 446 [321880/25046 (41%)]	Loss: 0.107028
Train epoch: 446 [663360/25046 (82%)]	Loss: 0.144758
Make prediction for 5010 samples...
0.28999853 No improvement since epoch  443 ; best_mse,best_ci: 0.27554536 0.8734788303976777 GCNNet davis
Training on 25046 samples...
Train epoch: 447 [0/25046 (0%)]	Loss: 0.103442
Train epoch: 447 [332300/25046 (41%)]	Loss: 0.118014
Train epoch: 447 [663640/25046 (82%)]	Loss: 0.107306
Make prediction for 5010 samples...
0.28025573 No improvement since epoch  443 ; best_mse,best_ci: 0.27554536 0.8734788303976777 GCNNet davis
Training on 25046 samples...
Train epoch: 448 [0/25046 (0%)]	Loss: 0.151557
Train epoch: 448 [324260/25046 (41%)]	Loss: 0.135439
Train epoch: 448 [649880/25046 (82%)]	Loss: 0.154624
Make prediction for 5010 samples...
0.29255328 No improvement since epoch  443 ; best_mse,best_ci: 0.27554536 0.8734788303976777 GCNNet davis
Training on 25046 samples...
Train epoch: 449 [0/25046 (0%)]	Loss: 0.107541
Train epoch: 449 [327700/25046 (41%)]	Loss: 0.134440
Train epoch: 449 [653600/25046 (82%)]	Loss: 0.102399
Make prediction for 5010 samples...
0.28911337 No improvement since epoch  443 ; best_mse,best_ci: 0.27554536 0.8734788303976777 GCNNet davis
Training on 25046 samples...
Train epoch: 450 [0/25046 (0%)]	Loss: 0.140810
Train epoch: 450 [332780/25046 (41%)]	Loss: 0.153112
Train epoch: 450 [643040/25046 (82%)]	Loss: 0.124547
Make prediction for 5010 samples...
0.29204834 No improvement since epoch  443 ; best_mse,best_ci: 0.27554536 0.8734788303976777 GCNNet davis
Training on 25046 samples...
Train epoch: 451 [0/25046 (0%)]	Loss: 0.119733
Train epoch: 451 [323140/25046 (41%)]	Loss: 0.127534
Train epoch: 451 [645960/25046 (82%)]	Loss: 0.156950
Make prediction for 5010 samples...
0.28997412 No improvement since epoch  443 ; best_mse,best_ci: 0.27554536 0.8734788303976777 GCNNet davis
Training on 25046 samples...
Train epoch: 452 [0/25046 (0%)]	Loss: 0.114317
Train epoch: 452 [326660/25046 (41%)]	Loss: 0.168855
Train epoch: 452 [656120/25046 (82%)]	Loss: 0.163097
Make prediction for 5010 samples...
0.27764684 No improvement since epoch  443 ; best_mse,best_ci: 0.27554536 0.8734788303976777 GCNNet davis
Training on 25046 samples...
Train epoch: 453 [0/25046 (0%)]	Loss: 0.128128
Train epoch: 453 [326360/25046 (41%)]	Loss: 0.156002
Train epoch: 453 [660440/25046 (82%)]	Loss: 0.142167
Make prediction for 5010 samples...
0.30119404 No improvement since epoch  443 ; best_mse,best_ci: 0.27554536 0.8734788303976777 GCNNet davis
Training on 25046 samples...
Train epoch: 454 [0/25046 (0%)]	Loss: 0.160215
Train epoch: 454 [329260/25046 (41%)]	Loss: 0.144967
Train epoch: 454 [650520/25046 (82%)]	Loss: 0.132956
Make prediction for 5010 samples...
0.2840856 No improvement since epoch  443 ; best_mse,best_ci: 0.27554536 0.8734788303976777 GCNNet davis
Training on 25046 samples...
Train epoch: 455 [0/25046 (0%)]	Loss: 0.119097
Train epoch: 455 [334940/25046 (41%)]	Loss: 0.174750
Train epoch: 455 [649200/25046 (82%)]	Loss: 0.138214
Make prediction for 5010 samples...
0.27751854 No improvement since epoch  443 ; best_mse,best_ci: 0.27554536 0.8734788303976777 GCNNet davis
Training on 25046 samples...
Train epoch: 456 [0/25046 (0%)]	Loss: 0.130445
Train epoch: 456 [329720/25046 (41%)]	Loss: 0.136923
Train epoch: 456 [651040/25046 (82%)]	Loss: 0.148401
Make prediction for 5010 samples...
0.32991484 No improvement since epoch  443 ; best_mse,best_ci: 0.27554536 0.8734788303976777 GCNNet davis
Training on 25046 samples...
Train epoch: 457 [0/25046 (0%)]	Loss: 0.165303
Train epoch: 457 [324180/25046 (41%)]	Loss: 0.155156
Train epoch: 457 [648040/25046 (82%)]	Loss: 0.130659
Make prediction for 5010 samples...
0.27953747 No improvement since epoch  443 ; best_mse,best_ci: 0.27554536 0.8734788303976777 GCNNet davis
Training on 25046 samples...
Train epoch: 458 [0/25046 (0%)]	Loss: 0.123737
Train epoch: 458 [327720/25046 (41%)]	Loss: 0.166396
Train epoch: 458 [654000/25046 (82%)]	Loss: 0.140581
Make prediction for 5010 samples...
0.27870643 No improvement since epoch  443 ; best_mse,best_ci: 0.27554536 0.8734788303976777 GCNNet davis
Training on 25046 samples...
Train epoch: 459 [0/25046 (0%)]	Loss: 0.146117
Train epoch: 459 [328460/25046 (41%)]	Loss: 0.142602
Train epoch: 459 [655480/25046 (82%)]	Loss: 0.131967
Make prediction for 5010 samples...
0.28621534 No improvement since epoch  443 ; best_mse,best_ci: 0.27554536 0.8734788303976777 GCNNet davis
Training on 25046 samples...
Train epoch: 460 [0/25046 (0%)]	Loss: 0.166208
Train epoch: 460 [333800/25046 (41%)]	Loss: 0.136282
Train epoch: 460 [665800/25046 (82%)]	Loss: 0.099314
Make prediction for 5010 samples...
0.29356566 No improvement since epoch  443 ; best_mse,best_ci: 0.27554536 0.8734788303976777 GCNNet davis
Training on 25046 samples...
Train epoch: 461 [0/25046 (0%)]	Loss: 0.154440
Train epoch: 461 [330560/25046 (41%)]	Loss: 0.127332
Train epoch: 461 [666280/25046 (82%)]	Loss: 0.196069
Make prediction for 5010 samples...
0.29223862 No improvement since epoch  443 ; best_mse,best_ci: 0.27554536 0.8734788303976777 GCNNet davis
Training on 25046 samples...
Train epoch: 462 [0/25046 (0%)]	Loss: 0.128468
Train epoch: 462 [327480/25046 (41%)]	Loss: 0.117596
Train epoch: 462 [656560/25046 (82%)]	Loss: 0.119505
Make prediction for 5010 samples...
0.2759186 No improvement since epoch  443 ; best_mse,best_ci: 0.27554536 0.8734788303976777 GCNNet davis
Training on 25046 samples...
Train epoch: 463 [0/25046 (0%)]	Loss: 0.140777
Train epoch: 463 [329300/25046 (41%)]	Loss: 0.184109
Train epoch: 463 [653200/25046 (82%)]	Loss: 0.149700
Make prediction for 5010 samples...
0.3294008 No improvement since epoch  443 ; best_mse,best_ci: 0.27554536 0.8734788303976777 GCNNet davis
Training on 25046 samples...
Train epoch: 464 [0/25046 (0%)]	Loss: 0.151891
Train epoch: 464 [328040/25046 (41%)]	Loss: 0.145140
Train epoch: 464 [660840/25046 (82%)]	Loss: 0.106310
Make prediction for 5010 samples...
0.30036014 No improvement since epoch  443 ; best_mse,best_ci: 0.27554536 0.8734788303976777 GCNNet davis
Training on 25046 samples...
Train epoch: 465 [0/25046 (0%)]	Loss: 0.153059
Train epoch: 465 [327040/25046 (41%)]	Loss: 0.108071
Train epoch: 465 [653720/25046 (82%)]	Loss: 0.135278
Make prediction for 5010 samples...
rmse improved at epoch  465 ; best_mse,best_ci: 0.27353287 0.873954445967973 GCNNet davis
Training on 25046 samples...
Train epoch: 466 [0/25046 (0%)]	Loss: 0.114892
Train epoch: 466 [328820/25046 (41%)]	Loss: 0.149286
Train epoch: 466 [658200/25046 (82%)]	Loss: 0.118313
Make prediction for 5010 samples...
0.30737627 No improvement since epoch  465 ; best_mse,best_ci: 0.27353287 0.873954445967973 GCNNet davis
Training on 25046 samples...
Train epoch: 467 [0/25046 (0%)]	Loss: 0.146652
Train epoch: 467 [326520/25046 (41%)]	Loss: 0.135498
Train epoch: 467 [654400/25046 (82%)]	Loss: 0.179412
Make prediction for 5010 samples...
0.29784307 No improvement since epoch  465 ; best_mse,best_ci: 0.27353287 0.873954445967973 GCNNet davis
Training on 25046 samples...
Train epoch: 468 [0/25046 (0%)]	Loss: 0.133979
Train epoch: 468 [330700/25046 (41%)]	Loss: 0.136855
Train epoch: 468 [664080/25046 (82%)]	Loss: 0.124743
Make prediction for 5010 samples...
0.30044216 No improvement since epoch  465 ; best_mse,best_ci: 0.27353287 0.873954445967973 GCNNet davis
Training on 25046 samples...
Train epoch: 469 [0/25046 (0%)]	Loss: 0.118327
Train epoch: 469 [328900/25046 (41%)]	Loss: 0.147847
Train epoch: 469 [654440/25046 (82%)]	Loss: 0.130871
Make prediction for 5010 samples...
0.28391045 No improvement since epoch  465 ; best_mse,best_ci: 0.27353287 0.873954445967973 GCNNet davis
Training on 25046 samples...
Train epoch: 470 [0/25046 (0%)]	Loss: 0.130241
Train epoch: 470 [324460/25046 (41%)]	Loss: 0.140041
Train epoch: 470 [655440/25046 (82%)]	Loss: 0.176509
Make prediction for 5010 samples...
0.2868633 No improvement since epoch  465 ; best_mse,best_ci: 0.27353287 0.873954445967973 GCNNet davis
Training on 25046 samples...
Train epoch: 471 [0/25046 (0%)]	Loss: 0.110850
Train epoch: 471 [333840/25046 (41%)]	Loss: 0.119411
Train epoch: 471 [659040/25046 (82%)]	Loss: 0.148608
Make prediction for 5010 samples...
0.2849367 No improvement since epoch  465 ; best_mse,best_ci: 0.27353287 0.873954445967973 GCNNet davis
Training on 25046 samples...
Train epoch: 472 [0/25046 (0%)]	Loss: 0.109401
Train epoch: 472 [326900/25046 (41%)]	Loss: 0.132952
Train epoch: 472 [660560/25046 (82%)]	Loss: 0.166402
Make prediction for 5010 samples...
0.29503497 No improvement since epoch  465 ; best_mse,best_ci: 0.27353287 0.873954445967973 GCNNet davis
Training on 25046 samples...
Train epoch: 473 [0/25046 (0%)]	Loss: 0.141301
Train epoch: 473 [325080/25046 (41%)]	Loss: 0.134435
Train epoch: 473 [664320/25046 (82%)]	Loss: 0.146598
Make prediction for 5010 samples...
0.28502795 No improvement since epoch  465 ; best_mse,best_ci: 0.27353287 0.873954445967973 GCNNet davis
Training on 25046 samples...
Train epoch: 474 [0/25046 (0%)]	Loss: 0.134486
Train epoch: 474 [328240/25046 (41%)]	Loss: 0.172709
Train epoch: 474 [651480/25046 (82%)]	Loss: 0.142969
Make prediction for 5010 samples...
0.28436273 No improvement since epoch  465 ; best_mse,best_ci: 0.27353287 0.873954445967973 GCNNet davis
Training on 25046 samples...
Train epoch: 475 [0/25046 (0%)]	Loss: 0.152436
Train epoch: 475 [326040/25046 (41%)]	Loss: 0.142255
Train epoch: 475 [658160/25046 (82%)]	Loss: 0.130898
Make prediction for 5010 samples...
0.28578755 No improvement since epoch  465 ; best_mse,best_ci: 0.27353287 0.873954445967973 GCNNet davis
Training on 25046 samples...
Train epoch: 476 [0/25046 (0%)]	Loss: 0.096266
Train epoch: 476 [331700/25046 (41%)]	Loss: 0.135550
Train epoch: 476 [657680/25046 (82%)]	Loss: 0.139342
Make prediction for 5010 samples...
0.29999787 No improvement since epoch  465 ; best_mse,best_ci: 0.27353287 0.873954445967973 GCNNet davis
Training on 25046 samples...
Train epoch: 477 [0/25046 (0%)]	Loss: 0.142778
Train epoch: 477 [325920/25046 (41%)]	Loss: 0.119104
Train epoch: 477 [659680/25046 (82%)]	Loss: 0.142386
Make prediction for 5010 samples...
0.29343593 No improvement since epoch  465 ; best_mse,best_ci: 0.27353287 0.873954445967973 GCNNet davis
Training on 25046 samples...
Train epoch: 478 [0/25046 (0%)]	Loss: 0.140246
Train epoch: 478 [326220/25046 (41%)]	Loss: 0.138365
Train epoch: 478 [655280/25046 (82%)]	Loss: 0.125233
Make prediction for 5010 samples...
0.35539424 No improvement since epoch  465 ; best_mse,best_ci: 0.27353287 0.873954445967973 GCNNet davis
Training on 25046 samples...
Train epoch: 479 [0/25046 (0%)]	Loss: 0.181946
Train epoch: 479 [327400/25046 (41%)]	Loss: 0.128045
Train epoch: 479 [649960/25046 (82%)]	Loss: 0.102007
Make prediction for 5010 samples...
0.31013024 No improvement since epoch  465 ; best_mse,best_ci: 0.27353287 0.873954445967973 GCNNet davis
Training on 25046 samples...
Train epoch: 480 [0/25046 (0%)]	Loss: 0.140499
Train epoch: 480 [325500/25046 (41%)]	Loss: 0.111328
Train epoch: 480 [660720/25046 (82%)]	Loss: 0.150198
Make prediction for 5010 samples...
0.28862104 No improvement since epoch  465 ; best_mse,best_ci: 0.27353287 0.873954445967973 GCNNet davis
Training on 25046 samples...
Train epoch: 481 [0/25046 (0%)]	Loss: 0.120715
Train epoch: 481 [331220/25046 (41%)]	Loss: 0.141740
Train epoch: 481 [651880/25046 (82%)]	Loss: 0.137060
Make prediction for 5010 samples...
0.28173482 No improvement since epoch  465 ; best_mse,best_ci: 0.27353287 0.873954445967973 GCNNet davis
Training on 25046 samples...
Train epoch: 482 [0/25046 (0%)]	Loss: 0.143879
Train epoch: 482 [328040/25046 (41%)]	Loss: 0.150814
Train epoch: 482 [670040/25046 (82%)]	Loss: 0.148169
Make prediction for 5010 samples...
0.27883896 No improvement since epoch  465 ; best_mse,best_ci: 0.27353287 0.873954445967973 GCNNet davis
Training on 25046 samples...
Train epoch: 483 [0/25046 (0%)]	Loss: 0.118200
Train epoch: 483 [325620/25046 (41%)]	Loss: 0.109738
Train epoch: 483 [654000/25046 (82%)]	Loss: 0.179239
Make prediction for 5010 samples...
0.28791857 No improvement since epoch  465 ; best_mse,best_ci: 0.27353287 0.873954445967973 GCNNet davis
Training on 25046 samples...
Train epoch: 484 [0/25046 (0%)]	Loss: 0.162855
Train epoch: 484 [331560/25046 (41%)]	Loss: 0.190449
Train epoch: 484 [666800/25046 (82%)]	Loss: 0.158348
Make prediction for 5010 samples...
0.30465227 No improvement since epoch  465 ; best_mse,best_ci: 0.27353287 0.873954445967973 GCNNet davis
Training on 25046 samples...
Train epoch: 485 [0/25046 (0%)]	Loss: 0.102408
Train epoch: 485 [329280/25046 (41%)]	Loss: 0.153294
Train epoch: 485 [661200/25046 (82%)]	Loss: 0.130734
Make prediction for 5010 samples...
0.2815745 No improvement since epoch  465 ; best_mse,best_ci: 0.27353287 0.873954445967973 GCNNet davis
Training on 25046 samples...
Train epoch: 486 [0/25046 (0%)]	Loss: 0.122039
Train epoch: 486 [328460/25046 (41%)]	Loss: 0.150223
Train epoch: 486 [655520/25046 (82%)]	Loss: 0.134796
Make prediction for 5010 samples...
0.27583638 No improvement since epoch  465 ; best_mse,best_ci: 0.27353287 0.873954445967973 GCNNet davis
Training on 25046 samples...
Train epoch: 487 [0/25046 (0%)]	Loss: 0.138136
Train epoch: 487 [330380/25046 (41%)]	Loss: 0.154050
Train epoch: 487 [656960/25046 (82%)]	Loss: 0.136985
Make prediction for 5010 samples...
0.27368453 No improvement since epoch  465 ; best_mse,best_ci: 0.27353287 0.873954445967973 GCNNet davis
Training on 25046 samples...
Train epoch: 488 [0/25046 (0%)]	Loss: 0.127280
Train epoch: 488 [327580/25046 (41%)]	Loss: 0.136005
Train epoch: 488 [650600/25046 (82%)]	Loss: 0.116303
Make prediction for 5010 samples...
rmse improved at epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 489 [0/25046 (0%)]	Loss: 0.139159
Train epoch: 489 [323940/25046 (41%)]	Loss: 0.108828
Train epoch: 489 [652920/25046 (82%)]	Loss: 0.115971
Make prediction for 5010 samples...
0.27328116 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 490 [0/25046 (0%)]	Loss: 0.145261
Train epoch: 490 [329260/25046 (41%)]	Loss: 0.195384
Train epoch: 490 [644800/25046 (82%)]	Loss: 0.119791
Make prediction for 5010 samples...
0.29256588 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 491 [0/25046 (0%)]	Loss: 0.128831
Train epoch: 491 [327420/25046 (41%)]	Loss: 0.154272
Train epoch: 491 [660200/25046 (82%)]	Loss: 0.130627
Make prediction for 5010 samples...
0.29951388 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 492 [0/25046 (0%)]	Loss: 0.111777
Train epoch: 492 [324380/25046 (41%)]	Loss: 0.136880
Train epoch: 492 [656720/25046 (82%)]	Loss: 0.105770
Make prediction for 5010 samples...
0.3002424 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 493 [0/25046 (0%)]	Loss: 0.127068
Train epoch: 493 [327120/25046 (41%)]	Loss: 0.116805
Train epoch: 493 [659960/25046 (82%)]	Loss: 0.125463
Make prediction for 5010 samples...
0.30188373 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 494 [0/25046 (0%)]	Loss: 0.122118
Train epoch: 494 [332220/25046 (41%)]	Loss: 0.123076
Train epoch: 494 [666240/25046 (82%)]	Loss: 0.122880
Make prediction for 5010 samples...
0.27271304 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 495 [0/25046 (0%)]	Loss: 0.125831
Train epoch: 495 [332180/25046 (41%)]	Loss: 0.134322
Train epoch: 495 [658040/25046 (82%)]	Loss: 0.136219
Make prediction for 5010 samples...
0.29487184 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 496 [0/25046 (0%)]	Loss: 0.158399
Train epoch: 496 [329360/25046 (41%)]	Loss: 0.121477
Train epoch: 496 [653720/25046 (82%)]	Loss: 0.136491
Make prediction for 5010 samples...
0.29127747 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 497 [0/25046 (0%)]	Loss: 0.136643
Train epoch: 497 [331320/25046 (41%)]	Loss: 0.114378
Train epoch: 497 [657760/25046 (82%)]	Loss: 0.121696
Make prediction for 5010 samples...
0.28331164 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 498 [0/25046 (0%)]	Loss: 0.200183
Train epoch: 498 [328680/25046 (41%)]	Loss: 0.153207
Train epoch: 498 [661360/25046 (82%)]	Loss: 0.151753
Make prediction for 5010 samples...
0.2832142 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 499 [0/25046 (0%)]	Loss: 0.120521
Train epoch: 499 [326520/25046 (41%)]	Loss: 0.143328
Train epoch: 499 [660920/25046 (82%)]	Loss: 0.142422
Make prediction for 5010 samples...
0.28506976 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 500 [0/25046 (0%)]	Loss: 0.131597
Train epoch: 500 [330920/25046 (41%)]	Loss: 0.143728
Train epoch: 500 [657160/25046 (82%)]	Loss: 0.153090
Make prediction for 5010 samples...
0.27980995 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 501 [0/25046 (0%)]	Loss: 0.117343
Train epoch: 501 [330260/25046 (41%)]	Loss: 0.111023
Train epoch: 501 [662120/25046 (82%)]	Loss: 0.119004
Make prediction for 5010 samples...
0.2757972 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 502 [0/25046 (0%)]	Loss: 0.127916
Train epoch: 502 [328180/25046 (41%)]	Loss: 0.171644
Train epoch: 502 [661160/25046 (82%)]	Loss: 0.125029
Make prediction for 5010 samples...
0.28015167 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 503 [0/25046 (0%)]	Loss: 0.103993
Train epoch: 503 [328800/25046 (41%)]	Loss: 0.115459
Train epoch: 503 [657480/25046 (82%)]	Loss: 0.141000
Make prediction for 5010 samples...
0.27316925 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 504 [0/25046 (0%)]	Loss: 0.150017
Train epoch: 504 [329960/25046 (41%)]	Loss: 0.123276
Train epoch: 504 [653280/25046 (82%)]	Loss: 0.124449
Make prediction for 5010 samples...
0.2834659 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 505 [0/25046 (0%)]	Loss: 0.114315
Train epoch: 505 [327640/25046 (41%)]	Loss: 0.106043
Train epoch: 505 [653520/25046 (82%)]	Loss: 0.148709
Make prediction for 5010 samples...
0.28316748 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 506 [0/25046 (0%)]	Loss: 0.168266
Train epoch: 506 [325920/25046 (41%)]	Loss: 0.109770
Train epoch: 506 [661600/25046 (82%)]	Loss: 0.156147
Make prediction for 5010 samples...
0.2815456 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 507 [0/25046 (0%)]	Loss: 0.156290
Train epoch: 507 [327760/25046 (41%)]	Loss: 0.136361
Train epoch: 507 [661080/25046 (82%)]	Loss: 0.142235
Make prediction for 5010 samples...
0.31376314 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 508 [0/25046 (0%)]	Loss: 0.150052
Train epoch: 508 [326580/25046 (41%)]	Loss: 0.166176
Train epoch: 508 [665320/25046 (82%)]	Loss: 0.143647
Make prediction for 5010 samples...
0.29607475 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 509 [0/25046 (0%)]	Loss: 0.128517
Train epoch: 509 [330660/25046 (41%)]	Loss: 0.114988
Train epoch: 509 [654200/25046 (82%)]	Loss: 0.121988
Make prediction for 5010 samples...
0.29559734 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 510 [0/25046 (0%)]	Loss: 0.143792
Train epoch: 510 [328820/25046 (41%)]	Loss: 0.160462
Train epoch: 510 [649160/25046 (82%)]	Loss: 0.109217
Make prediction for 5010 samples...
0.29418167 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 511 [0/25046 (0%)]	Loss: 0.168940
Train epoch: 511 [329600/25046 (41%)]	Loss: 0.126830
Train epoch: 511 [664400/25046 (82%)]	Loss: 0.115251
Make prediction for 5010 samples...
0.28272712 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 512 [0/25046 (0%)]	Loss: 0.131279
Train epoch: 512 [324340/25046 (41%)]	Loss: 0.125523
Train epoch: 512 [661320/25046 (82%)]	Loss: 0.171600
Make prediction for 5010 samples...
0.2881065 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 513 [0/25046 (0%)]	Loss: 0.114812
Train epoch: 513 [323760/25046 (41%)]	Loss: 0.163655
Train epoch: 513 [652000/25046 (82%)]	Loss: 0.120863
Make prediction for 5010 samples...
0.28438777 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 514 [0/25046 (0%)]	Loss: 0.095233
Train epoch: 514 [325460/25046 (41%)]	Loss: 0.115330
Train epoch: 514 [651680/25046 (82%)]	Loss: 0.106273
Make prediction for 5010 samples...
0.28355002 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 515 [0/25046 (0%)]	Loss: 0.156558
Train epoch: 515 [324440/25046 (41%)]	Loss: 0.155042
Train epoch: 515 [648240/25046 (82%)]	Loss: 0.107470
Make prediction for 5010 samples...
0.27486277 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 516 [0/25046 (0%)]	Loss: 0.127667
Train epoch: 516 [330580/25046 (41%)]	Loss: 0.138001
Train epoch: 516 [655920/25046 (82%)]	Loss: 0.139016
Make prediction for 5010 samples...
0.31402504 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 517 [0/25046 (0%)]	Loss: 0.140423
Train epoch: 517 [331060/25046 (41%)]	Loss: 0.118054
Train epoch: 517 [650920/25046 (82%)]	Loss: 0.154604
Make prediction for 5010 samples...
0.30167392 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 518 [0/25046 (0%)]	Loss: 0.164029
Train epoch: 518 [329240/25046 (41%)]	Loss: 0.162910
Train epoch: 518 [645280/25046 (82%)]	Loss: 0.148418
Make prediction for 5010 samples...
0.29770884 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 519 [0/25046 (0%)]	Loss: 0.180177
Train epoch: 519 [333640/25046 (41%)]	Loss: 0.123086
Train epoch: 519 [659640/25046 (82%)]	Loss: 0.120113
Make prediction for 5010 samples...
0.2921802 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 520 [0/25046 (0%)]	Loss: 0.144804
Train epoch: 520 [329300/25046 (41%)]	Loss: 0.156447
Train epoch: 520 [660000/25046 (82%)]	Loss: 0.121715
Make prediction for 5010 samples...
0.2902226 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 521 [0/25046 (0%)]	Loss: 0.139153
Train epoch: 521 [327220/25046 (41%)]	Loss: 0.159758
Train epoch: 521 [648040/25046 (82%)]	Loss: 0.133508
Make prediction for 5010 samples...
0.281843 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 522 [0/25046 (0%)]	Loss: 0.096951
Train epoch: 522 [326900/25046 (41%)]	Loss: 0.167653
Train epoch: 522 [658280/25046 (82%)]	Loss: 0.136320
Make prediction for 5010 samples...
0.27868629 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 523 [0/25046 (0%)]	Loss: 0.126318
Train epoch: 523 [327780/25046 (41%)]	Loss: 0.131861
Train epoch: 523 [652800/25046 (82%)]	Loss: 0.136802
Make prediction for 5010 samples...
0.2834573 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 524 [0/25046 (0%)]	Loss: 0.112284
Train epoch: 524 [329960/25046 (41%)]	Loss: 0.127707
Train epoch: 524 [659280/25046 (82%)]	Loss: 0.144789
Make prediction for 5010 samples...
0.28029153 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 525 [0/25046 (0%)]	Loss: 0.141360
Train epoch: 525 [328920/25046 (41%)]	Loss: 0.124212
Train epoch: 525 [670480/25046 (82%)]	Loss: 0.132697
Make prediction for 5010 samples...
0.2719906 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 526 [0/25046 (0%)]	Loss: 0.144296
Train epoch: 526 [330700/25046 (41%)]	Loss: 0.133513
Train epoch: 526 [660560/25046 (82%)]	Loss: 0.148931
Make prediction for 5010 samples...
0.29483467 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 527 [0/25046 (0%)]	Loss: 0.105869
Train epoch: 527 [328540/25046 (41%)]	Loss: 0.109990
Train epoch: 527 [651880/25046 (82%)]	Loss: 0.183940
Make prediction for 5010 samples...
0.299386 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 528 [0/25046 (0%)]	Loss: 0.152718
Train epoch: 528 [327800/25046 (41%)]	Loss: 0.107984
Train epoch: 528 [657640/25046 (82%)]	Loss: 0.136052
Make prediction for 5010 samples...
0.30000588 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 529 [0/25046 (0%)]	Loss: 0.127786
Train epoch: 529 [332280/25046 (41%)]	Loss: 0.147011
Train epoch: 529 [659960/25046 (82%)]	Loss: 0.141879
Make prediction for 5010 samples...
0.31833345 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 530 [0/25046 (0%)]	Loss: 0.133713
Train epoch: 530 [328220/25046 (41%)]	Loss: 0.115926
Train epoch: 530 [652880/25046 (82%)]	Loss: 0.149515
Make prediction for 5010 samples...
0.28402254 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 531 [0/25046 (0%)]	Loss: 0.121217
Train epoch: 531 [329060/25046 (41%)]	Loss: 0.107313
Train epoch: 531 [663040/25046 (82%)]	Loss: 0.135901
Make prediction for 5010 samples...
0.3118522 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 532 [0/25046 (0%)]	Loss: 0.143516
Train epoch: 532 [329220/25046 (41%)]	Loss: 0.113945
Train epoch: 532 [651640/25046 (82%)]	Loss: 0.123195
Make prediction for 5010 samples...
0.27650014 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 533 [0/25046 (0%)]	Loss: 0.106422
Train epoch: 533 [327160/25046 (41%)]	Loss: 0.181378
Train epoch: 533 [660080/25046 (82%)]	Loss: 0.148639
Make prediction for 5010 samples...
0.27698344 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 534 [0/25046 (0%)]	Loss: 0.130553
Train epoch: 534 [326180/25046 (41%)]	Loss: 0.162131
Train epoch: 534 [660560/25046 (82%)]	Loss: 0.180157
Make prediction for 5010 samples...
0.3068429 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 535 [0/25046 (0%)]	Loss: 0.128626
Train epoch: 535 [327100/25046 (41%)]	Loss: 0.104797
Train epoch: 535 [657960/25046 (82%)]	Loss: 0.118257
Make prediction for 5010 samples...
0.27354428 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 536 [0/25046 (0%)]	Loss: 0.108506
Train epoch: 536 [330280/25046 (41%)]	Loss: 0.118291
Train epoch: 536 [651680/25046 (82%)]	Loss: 0.115745
Make prediction for 5010 samples...
0.27377278 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 537 [0/25046 (0%)]	Loss: 0.105849
Train epoch: 537 [327540/25046 (41%)]	Loss: 0.141006
Train epoch: 537 [650120/25046 (82%)]	Loss: 0.102092
Make prediction for 5010 samples...
0.2743456 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 538 [0/25046 (0%)]	Loss: 0.138795
Train epoch: 538 [330460/25046 (41%)]	Loss: 0.094224
Train epoch: 538 [658040/25046 (82%)]	Loss: 0.121552
Make prediction for 5010 samples...
0.27163535 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 539 [0/25046 (0%)]	Loss: 0.133631
Train epoch: 539 [328120/25046 (41%)]	Loss: 0.131367
Train epoch: 539 [660720/25046 (82%)]	Loss: 0.160020
Make prediction for 5010 samples...
0.30023718 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 540 [0/25046 (0%)]	Loss: 0.188077
Train epoch: 540 [332620/25046 (41%)]	Loss: 0.130802
Train epoch: 540 [659600/25046 (82%)]	Loss: 0.168440
Make prediction for 5010 samples...
0.27874312 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 541 [0/25046 (0%)]	Loss: 0.127755
Train epoch: 541 [324960/25046 (41%)]	Loss: 0.121512
Train epoch: 541 [662200/25046 (82%)]	Loss: 0.158388
Make prediction for 5010 samples...
0.27515712 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 542 [0/25046 (0%)]	Loss: 0.140900
Train epoch: 542 [328560/25046 (41%)]	Loss: 0.131270
Train epoch: 542 [660320/25046 (82%)]	Loss: 0.116538
Make prediction for 5010 samples...
0.28502977 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 543 [0/25046 (0%)]	Loss: 0.127731
Train epoch: 543 [332260/25046 (41%)]	Loss: 0.138500
Train epoch: 543 [666280/25046 (82%)]	Loss: 0.131148
Make prediction for 5010 samples...
0.31371695 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 544 [0/25046 (0%)]	Loss: 0.094871
Train epoch: 544 [333500/25046 (41%)]	Loss: 0.114816
Train epoch: 544 [650280/25046 (82%)]	Loss: 0.127242
Make prediction for 5010 samples...
0.3026862 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 545 [0/25046 (0%)]	Loss: 0.116370
Train epoch: 545 [327960/25046 (41%)]	Loss: 0.140058
Train epoch: 545 [655560/25046 (82%)]	Loss: 0.105620
Make prediction for 5010 samples...
0.28394693 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 546 [0/25046 (0%)]	Loss: 0.132881
Train epoch: 546 [326540/25046 (41%)]	Loss: 0.110691
Train epoch: 546 [657880/25046 (82%)]	Loss: 0.128165
Make prediction for 5010 samples...
0.27641138 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 547 [0/25046 (0%)]	Loss: 0.097433
Train epoch: 547 [332540/25046 (41%)]	Loss: 0.120717
Train epoch: 547 [648200/25046 (82%)]	Loss: 0.140198
Make prediction for 5010 samples...
0.2902388 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 548 [0/25046 (0%)]	Loss: 0.118727
Train epoch: 548 [330280/25046 (41%)]	Loss: 0.137612
Train epoch: 548 [657640/25046 (82%)]	Loss: 0.144886
Make prediction for 5010 samples...
0.3059742 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 549 [0/25046 (0%)]	Loss: 0.146937
Train epoch: 549 [327020/25046 (41%)]	Loss: 0.172098
Train epoch: 549 [661040/25046 (82%)]	Loss: 0.118072
Make prediction for 5010 samples...
0.28541005 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 550 [0/25046 (0%)]	Loss: 0.118863
Train epoch: 550 [330500/25046 (41%)]	Loss: 0.117355
Train epoch: 550 [653240/25046 (82%)]	Loss: 0.138095
Make prediction for 5010 samples...
0.29271185 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 551 [0/25046 (0%)]	Loss: 0.170799
Train epoch: 551 [329100/25046 (41%)]	Loss: 0.123766
Train epoch: 551 [657680/25046 (82%)]	Loss: 0.118078
Make prediction for 5010 samples...
0.27212203 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 552 [0/25046 (0%)]	Loss: 0.148032
Train epoch: 552 [323700/25046 (41%)]	Loss: 0.118557
Train epoch: 552 [657880/25046 (82%)]	Loss: 0.104676
Make prediction for 5010 samples...
0.28460836 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 553 [0/25046 (0%)]	Loss: 0.112779
Train epoch: 553 [326380/25046 (41%)]	Loss: 0.171794
Train epoch: 553 [654880/25046 (82%)]	Loss: 0.122976
Make prediction for 5010 samples...
0.28952312 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 554 [0/25046 (0%)]	Loss: 0.109852
Train epoch: 554 [331040/25046 (41%)]	Loss: 0.162134
Train epoch: 554 [658160/25046 (82%)]	Loss: 0.193774
Make prediction for 5010 samples...
0.28671348 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 555 [0/25046 (0%)]	Loss: 0.137460
Train epoch: 555 [326280/25046 (41%)]	Loss: 0.136810
Train epoch: 555 [655720/25046 (82%)]	Loss: 0.125742
Make prediction for 5010 samples...
0.28356004 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 556 [0/25046 (0%)]	Loss: 0.116321
Train epoch: 556 [329680/25046 (41%)]	Loss: 0.130876
Train epoch: 556 [660920/25046 (82%)]	Loss: 0.121302
Make prediction for 5010 samples...
0.28013372 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 557 [0/25046 (0%)]	Loss: 0.102302
Train epoch: 557 [329180/25046 (41%)]	Loss: 0.126426
Train epoch: 557 [646640/25046 (82%)]	Loss: 0.158258
Make prediction for 5010 samples...
0.3045572 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 558 [0/25046 (0%)]	Loss: 0.135048
Train epoch: 558 [330000/25046 (41%)]	Loss: 0.123237
Train epoch: 558 [658040/25046 (82%)]	Loss: 0.146332
Make prediction for 5010 samples...
0.28186804 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 559 [0/25046 (0%)]	Loss: 0.127935
Train epoch: 559 [330080/25046 (41%)]	Loss: 0.131058
Train epoch: 559 [649760/25046 (82%)]	Loss: 0.114180
Make prediction for 5010 samples...
0.28803504 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 560 [0/25046 (0%)]	Loss: 0.111438
Train epoch: 560 [326960/25046 (41%)]	Loss: 0.116466
Train epoch: 560 [659000/25046 (82%)]	Loss: 0.166856
Make prediction for 5010 samples...
0.27704585 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 561 [0/25046 (0%)]	Loss: 0.159826
Train epoch: 561 [330080/25046 (41%)]	Loss: 0.119278
Train epoch: 561 [655600/25046 (82%)]	Loss: 0.114606
Make prediction for 5010 samples...
0.28380394 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 562 [0/25046 (0%)]	Loss: 0.153872
Train epoch: 562 [326320/25046 (41%)]	Loss: 0.143871
Train epoch: 562 [653800/25046 (82%)]	Loss: 0.119799
Make prediction for 5010 samples...
0.30383584 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 563 [0/25046 (0%)]	Loss: 0.150526
Train epoch: 563 [324360/25046 (41%)]	Loss: 0.244942
Train epoch: 563 [665120/25046 (82%)]	Loss: 0.118513
Make prediction for 5010 samples...
0.28754202 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 564 [0/25046 (0%)]	Loss: 0.137840
Train epoch: 564 [327380/25046 (41%)]	Loss: 0.126226
Train epoch: 564 [650760/25046 (82%)]	Loss: 0.160105
Make prediction for 5010 samples...
0.33519956 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 565 [0/25046 (0%)]	Loss: 0.138215
Train epoch: 565 [328380/25046 (41%)]	Loss: 0.127025
Train epoch: 565 [650120/25046 (82%)]	Loss: 0.129997
Make prediction for 5010 samples...
0.30668837 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 566 [0/25046 (0%)]	Loss: 0.116209
Train epoch: 566 [321560/25046 (41%)]	Loss: 0.095459
Train epoch: 566 [653640/25046 (82%)]	Loss: 0.168652
Make prediction for 5010 samples...
0.2772092 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 567 [0/25046 (0%)]	Loss: 0.128173
Train epoch: 567 [329000/25046 (41%)]	Loss: 0.106550
Train epoch: 567 [661400/25046 (82%)]	Loss: 0.126734
Make prediction for 5010 samples...
0.30042884 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 568 [0/25046 (0%)]	Loss: 0.139889
Train epoch: 568 [326600/25046 (41%)]	Loss: 0.139624
Train epoch: 568 [649960/25046 (82%)]	Loss: 0.122436
Make prediction for 5010 samples...
0.3058861 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 569 [0/25046 (0%)]	Loss: 0.146354
Train epoch: 569 [335040/25046 (41%)]	Loss: 0.123775
Train epoch: 569 [651000/25046 (82%)]	Loss: 0.137366
Make prediction for 5010 samples...
0.2700321 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 570 [0/25046 (0%)]	Loss: 0.143494
Train epoch: 570 [326640/25046 (41%)]	Loss: 0.106509
Train epoch: 570 [659560/25046 (82%)]	Loss: 0.104589
Make prediction for 5010 samples...
0.27476075 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 571 [0/25046 (0%)]	Loss: 0.113142
Train epoch: 571 [329320/25046 (41%)]	Loss: 0.147938
Train epoch: 571 [664240/25046 (82%)]	Loss: 0.118523
Make prediction for 5010 samples...
0.29437804 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 572 [0/25046 (0%)]	Loss: 0.115825
Train epoch: 572 [333780/25046 (41%)]	Loss: 0.104427
Train epoch: 572 [654760/25046 (82%)]	Loss: 0.109090
Make prediction for 5010 samples...
0.27205583 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 573 [0/25046 (0%)]	Loss: 0.113532
Train epoch: 573 [331340/25046 (41%)]	Loss: 0.132699
Train epoch: 573 [657200/25046 (82%)]	Loss: 0.145051
Make prediction for 5010 samples...
0.27204505 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 574 [0/25046 (0%)]	Loss: 0.155534
Train epoch: 574 [333120/25046 (41%)]	Loss: 0.143780
Train epoch: 574 [653320/25046 (82%)]	Loss: 0.147141
Make prediction for 5010 samples...
0.27615464 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 575 [0/25046 (0%)]	Loss: 0.125179
Train epoch: 575 [328580/25046 (41%)]	Loss: 0.123461
Train epoch: 575 [663320/25046 (82%)]	Loss: 0.137518
Make prediction for 5010 samples...
0.3001547 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 576 [0/25046 (0%)]	Loss: 0.116588
Train epoch: 576 [334980/25046 (41%)]	Loss: 0.205852
Train epoch: 576 [658920/25046 (82%)]	Loss: 0.152143
Make prediction for 5010 samples...
0.275693 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 577 [0/25046 (0%)]	Loss: 0.106476
Train epoch: 577 [329080/25046 (41%)]	Loss: 0.117819
Train epoch: 577 [652360/25046 (82%)]	Loss: 0.153372
Make prediction for 5010 samples...
0.28558898 No improvement since epoch  488 ; best_mse,best_ci: 0.26973137 0.8735304428424336 GCNNet davis
Training on 25046 samples...
Train epoch: 578 [0/25046 (0%)]	Loss: 0.137441
Train epoch: 578 [329520/25046 (41%)]	Loss: 0.155475
Train epoch: 578 [651560/25046 (82%)]	Loss: 0.130375
Make prediction for 5010 samples...
rmse improved at epoch  578 ; best_mse,best_ci: 0.26826766 0.8752242346310928 GCNNet davis
Training on 25046 samples...
Train epoch: 579 [0/25046 (0%)]	Loss: 0.098890
Train epoch: 579 [325200/25046 (41%)]	Loss: 0.120010
Train epoch: 579 [647680/25046 (82%)]	Loss: 0.164637
Make prediction for 5010 samples...
0.30634645 No improvement since epoch  578 ; best_mse,best_ci: 0.26826766 0.8752242346310928 GCNNet davis
Training on 25046 samples...
Train epoch: 580 [0/25046 (0%)]	Loss: 0.152030
Train epoch: 580 [328600/25046 (41%)]	Loss: 0.131871
Train epoch: 580 [665640/25046 (82%)]	Loss: 0.124415
Make prediction for 5010 samples...
0.31757522 No improvement since epoch  578 ; best_mse,best_ci: 0.26826766 0.8752242346310928 GCNNet davis
Training on 25046 samples...
Train epoch: 581 [0/25046 (0%)]	Loss: 0.139232
Train epoch: 581 [327940/25046 (41%)]	Loss: 0.134740
Train epoch: 581 [658200/25046 (82%)]	Loss: 0.118189
Make prediction for 5010 samples...
0.2704727 No improvement since epoch  578 ; best_mse,best_ci: 0.26826766 0.8752242346310928 GCNNet davis
Training on 25046 samples...
Train epoch: 582 [0/25046 (0%)]	Loss: 0.106661
Train epoch: 582 [322460/25046 (41%)]	Loss: 0.098145
Train epoch: 582 [656320/25046 (82%)]	Loss: 0.101312
Make prediction for 5010 samples...
0.28867486 No improvement since epoch  578 ; best_mse,best_ci: 0.26826766 0.8752242346310928 GCNNet davis
Training on 25046 samples...
Train epoch: 583 [0/25046 (0%)]	Loss: 0.114748
Train epoch: 583 [327780/25046 (41%)]	Loss: 0.172355
Train epoch: 583 [659160/25046 (82%)]	Loss: 0.103947
Make prediction for 5010 samples...
0.27762228 No improvement since epoch  578 ; best_mse,best_ci: 0.26826766 0.8752242346310928 GCNNet davis
Training on 25046 samples...
Train epoch: 584 [0/25046 (0%)]	Loss: 0.138463
Train epoch: 584 [327040/25046 (41%)]	Loss: 0.124719
Train epoch: 584 [650800/25046 (82%)]	Loss: 0.140678
Make prediction for 5010 samples...
0.28656736 No improvement since epoch  578 ; best_mse,best_ci: 0.26826766 0.8752242346310928 GCNNet davis
Training on 25046 samples...
Train epoch: 585 [0/25046 (0%)]	Loss: 0.108915
Train epoch: 585 [328960/25046 (41%)]	Loss: 0.124279
Train epoch: 585 [652840/25046 (82%)]	Loss: 0.124262
Make prediction for 5010 samples...
0.29110107 No improvement since epoch  578 ; best_mse,best_ci: 0.26826766 0.8752242346310928 GCNNet davis
Training on 25046 samples...
Train epoch: 586 [0/25046 (0%)]	Loss: 0.113876
Train epoch: 586 [326500/25046 (41%)]	Loss: 0.135909
Train epoch: 586 [652160/25046 (82%)]	Loss: 0.131149
Make prediction for 5010 samples...
0.28737307 No improvement since epoch  578 ; best_mse,best_ci: 0.26826766 0.8752242346310928 GCNNet davis
Training on 25046 samples...
Train epoch: 587 [0/25046 (0%)]	Loss: 0.084335
Train epoch: 587 [328020/25046 (41%)]	Loss: 0.127561
Train epoch: 587 [654680/25046 (82%)]	Loss: 0.124226
Make prediction for 5010 samples...
0.27224037 No improvement since epoch  578 ; best_mse,best_ci: 0.26826766 0.8752242346310928 GCNNet davis
Training on 25046 samples...
Train epoch: 588 [0/25046 (0%)]	Loss: 0.104817
Train epoch: 588 [329620/25046 (41%)]	Loss: 0.193021
Train epoch: 588 [656880/25046 (82%)]	Loss: 0.123714
Make prediction for 5010 samples...
0.27621248 No improvement since epoch  578 ; best_mse,best_ci: 0.26826766 0.8752242346310928 GCNNet davis
Training on 25046 samples...
Train epoch: 589 [0/25046 (0%)]	Loss: 0.134092
Train epoch: 589 [328340/25046 (41%)]	Loss: 0.110989
Train epoch: 589 [655360/25046 (82%)]	Loss: 0.113217
Make prediction for 5010 samples...
0.3072194 No improvement since epoch  578 ; best_mse,best_ci: 0.26826766 0.8752242346310928 GCNNet davis
Training on 25046 samples...
Train epoch: 590 [0/25046 (0%)]	Loss: 0.129145
Train epoch: 590 [330600/25046 (41%)]	Loss: 0.144980
Train epoch: 590 [653520/25046 (82%)]	Loss: 0.160159
Make prediction for 5010 samples...
0.30133307 No improvement since epoch  578 ; best_mse,best_ci: 0.26826766 0.8752242346310928 GCNNet davis
Training on 25046 samples...
Train epoch: 591 [0/25046 (0%)]	Loss: 0.090961
Train epoch: 591 [327160/25046 (41%)]	Loss: 0.119730
Train epoch: 591 [656320/25046 (82%)]	Loss: 0.172042
Make prediction for 5010 samples...
0.28650397 No improvement since epoch  578 ; best_mse,best_ci: 0.26826766 0.8752242346310928 GCNNet davis
Training on 25046 samples...
Train epoch: 592 [0/25046 (0%)]	Loss: 0.144179
Train epoch: 592 [323160/25046 (41%)]	Loss: 0.122910
Train epoch: 592 [661440/25046 (82%)]	Loss: 0.132379
Make prediction for 5010 samples...
0.31748518 No improvement since epoch  578 ; best_mse,best_ci: 0.26826766 0.8752242346310928 GCNNet davis
Training on 25046 samples...
Train epoch: 593 [0/25046 (0%)]	Loss: 0.127974
Train epoch: 593 [328480/25046 (41%)]	Loss: 0.153180
Train epoch: 593 [652160/25046 (82%)]	Loss: 0.145316
Make prediction for 5010 samples...
0.29769513 No improvement since epoch  578 ; best_mse,best_ci: 0.26826766 0.8752242346310928 GCNNet davis
Training on 25046 samples...
Train epoch: 594 [0/25046 (0%)]	Loss: 0.100351
Train epoch: 594 [332200/25046 (41%)]	Loss: 0.117394
Train epoch: 594 [654720/25046 (82%)]	Loss: 0.128240
Make prediction for 5010 samples...
0.3050575 No improvement since epoch  578 ; best_mse,best_ci: 0.26826766 0.8752242346310928 GCNNet davis
Training on 25046 samples...
Train epoch: 595 [0/25046 (0%)]	Loss: 0.101192
Train epoch: 595 [324820/25046 (41%)]	Loss: 0.133650
Train epoch: 595 [648920/25046 (82%)]	Loss: 0.155297
Make prediction for 5010 samples...
0.28179535 No improvement since epoch  578 ; best_mse,best_ci: 0.26826766 0.8752242346310928 GCNNet davis
Training on 25046 samples...
Train epoch: 596 [0/25046 (0%)]	Loss: 0.103307
Train epoch: 596 [330420/25046 (41%)]	Loss: 0.123007
Train epoch: 596 [659520/25046 (82%)]	Loss: 0.163716
Make prediction for 5010 samples...
0.28785482 No improvement since epoch  578 ; best_mse,best_ci: 0.26826766 0.8752242346310928 GCNNet davis
Training on 25046 samples...
Train epoch: 597 [0/25046 (0%)]	Loss: 0.103322
Train epoch: 597 [330480/25046 (41%)]	Loss: 0.112174
Train epoch: 597 [662080/25046 (82%)]	Loss: 0.116695
Make prediction for 5010 samples...
0.30238074 No improvement since epoch  578 ; best_mse,best_ci: 0.26826766 0.8752242346310928 GCNNet davis
Training on 25046 samples...
Train epoch: 598 [0/25046 (0%)]	Loss: 0.152555
Train epoch: 598 [334040/25046 (41%)]	Loss: 0.139697
Train epoch: 598 [656160/25046 (82%)]	Loss: 0.100805
Make prediction for 5010 samples...
0.279545 No improvement since epoch  578 ; best_mse,best_ci: 0.26826766 0.8752242346310928 GCNNet davis
Training on 25046 samples...
Train epoch: 599 [0/25046 (0%)]	Loss: 0.118695
Train epoch: 599 [331760/25046 (41%)]	Loss: 0.116508
Train epoch: 599 [652760/25046 (82%)]	Loss: 0.145203
Make prediction for 5010 samples...
0.2747044 No improvement since epoch  578 ; best_mse,best_ci: 0.26826766 0.8752242346310928 GCNNet davis
Training on 25046 samples...
Train epoch: 600 [0/25046 (0%)]	Loss: 0.123192
Train epoch: 600 [322980/25046 (41%)]	Loss: 0.121194
Train epoch: 600 [653880/25046 (82%)]	Loss: 0.163377
Make prediction for 5010 samples...
0.28754923 No improvement since epoch  578 ; best_mse,best_ci: 0.26826766 0.8752242346310928 GCNNet davis
Training on 25046 samples...
Train epoch: 601 [0/25046 (0%)]	Loss: 0.139585
Train epoch: 601 [330340/25046 (41%)]	Loss: 0.142877
Train epoch: 601 [656320/25046 (82%)]	Loss: 0.113912
Make prediction for 5010 samples...
0.27047166 No improvement since epoch  578 ; best_mse,best_ci: 0.26826766 0.8752242346310928 GCNNet davis
Training on 25046 samples...
Train epoch: 602 [0/25046 (0%)]	Loss: 0.122924
Train epoch: 602 [325940/25046 (41%)]	Loss: 0.135068
Train epoch: 602 [650280/25046 (82%)]	Loss: 0.130960
Make prediction for 5010 samples...
0.2749338 No improvement since epoch  578 ; best_mse,best_ci: 0.26826766 0.8752242346310928 GCNNet davis
Training on 25046 samples...
Train epoch: 603 [0/25046 (0%)]	Loss: 0.096684
Train epoch: 603 [327740/25046 (41%)]	Loss: 0.149036
Train epoch: 603 [661880/25046 (82%)]	Loss: 0.138676
Make prediction for 5010 samples...
0.29194608 No improvement since epoch  578 ; best_mse,best_ci: 0.26826766 0.8752242346310928 GCNNet davis
Training on 25046 samples...
Train epoch: 604 [0/25046 (0%)]	Loss: 0.107719
Train epoch: 604 [330240/25046 (41%)]	Loss: 0.107225
Train epoch: 604 [659880/25046 (82%)]	Loss: 0.114925
Make prediction for 5010 samples...
0.3140826 No improvement since epoch  578 ; best_mse,best_ci: 0.26826766 0.8752242346310928 GCNNet davis
Training on 25046 samples...
Train epoch: 605 [0/25046 (0%)]	Loss: 0.090213
Train epoch: 605 [328000/25046 (41%)]	Loss: 0.111611
Train epoch: 605 [658960/25046 (82%)]	Loss: 0.130550
Make prediction for 5010 samples...
0.2922012 No improvement since epoch  578 ; best_mse,best_ci: 0.26826766 0.8752242346310928 GCNNet davis
Training on 25046 samples...
Train epoch: 606 [0/25046 (0%)]	Loss: 0.110214
Train epoch: 606 [329380/25046 (41%)]	Loss: 0.101955
Train epoch: 606 [653760/25046 (82%)]	Loss: 0.134881
Make prediction for 5010 samples...
0.28268126 No improvement since epoch  578 ; best_mse,best_ci: 0.26826766 0.8752242346310928 GCNNet davis
Training on 25046 samples...
Train epoch: 607 [0/25046 (0%)]	Loss: 0.166505
Train epoch: 607 [326060/25046 (41%)]	Loss: 0.131023
Train epoch: 607 [649760/25046 (82%)]	Loss: 0.109430
Make prediction for 5010 samples...
0.27253178 No improvement since epoch  578 ; best_mse,best_ci: 0.26826766 0.8752242346310928 GCNNet davis
Training on 25046 samples...
Train epoch: 608 [0/25046 (0%)]	Loss: 0.095697
Train epoch: 608 [329560/25046 (41%)]	Loss: 0.150177
Train epoch: 608 [659600/25046 (82%)]	Loss: 0.138391
Make prediction for 5010 samples...
0.28115004 No improvement since epoch  578 ; best_mse,best_ci: 0.26826766 0.8752242346310928 GCNNet davis
Training on 25046 samples...
Train epoch: 609 [0/25046 (0%)]	Loss: 0.157436
Train epoch: 609 [331820/25046 (41%)]	Loss: 0.129947
Train epoch: 609 [655720/25046 (82%)]	Loss: 0.114056
Make prediction for 5010 samples...
rmse improved at epoch  609 ; best_mse,best_ci: 0.26704255 0.8762852762253629 GCNNet davis
Training on 25046 samples...
Train epoch: 610 [0/25046 (0%)]	Loss: 0.097010
Train epoch: 610 [328400/25046 (41%)]	Loss: 0.111906
Train epoch: 610 [656640/25046 (82%)]	Loss: 0.115682
Make prediction for 5010 samples...
0.30537003 No improvement since epoch  609 ; best_mse,best_ci: 0.26704255 0.8762852762253629 GCNNet davis
Training on 25046 samples...
Train epoch: 611 [0/25046 (0%)]	Loss: 0.116845
Train epoch: 611 [329500/25046 (41%)]	Loss: 0.116925
Train epoch: 611 [659320/25046 (82%)]	Loss: 0.122745
Make prediction for 5010 samples...
0.29198036 No improvement since epoch  609 ; best_mse,best_ci: 0.26704255 0.8762852762253629 GCNNet davis
Training on 25046 samples...
Train epoch: 612 [0/25046 (0%)]	Loss: 0.101310
Train epoch: 612 [331480/25046 (41%)]	Loss: 0.125497
Train epoch: 612 [655120/25046 (82%)]	Loss: 0.102922
Make prediction for 5010 samples...
0.27435577 No improvement since epoch  609 ; best_mse,best_ci: 0.26704255 0.8762852762253629 GCNNet davis
Training on 25046 samples...
Train epoch: 613 [0/25046 (0%)]	Loss: 0.113897
Train epoch: 613 [328580/25046 (41%)]	Loss: 0.107477
Train epoch: 613 [656120/25046 (82%)]	Loss: 0.117018
Make prediction for 5010 samples...
0.28271624 No improvement since epoch  609 ; best_mse,best_ci: 0.26704255 0.8762852762253629 GCNNet davis
Training on 25046 samples...
Train epoch: 614 [0/25046 (0%)]	Loss: 0.105349
Train epoch: 614 [329580/25046 (41%)]	Loss: 0.103629
Train epoch: 614 [658960/25046 (82%)]	Loss: 0.116779
Make prediction for 5010 samples...
0.28555804 No improvement since epoch  609 ; best_mse,best_ci: 0.26704255 0.8762852762253629 GCNNet davis
Training on 25046 samples...
Train epoch: 615 [0/25046 (0%)]	Loss: 0.108717
Train epoch: 615 [329340/25046 (41%)]	Loss: 0.144850
Train epoch: 615 [655880/25046 (82%)]	Loss: 0.140700
Make prediction for 5010 samples...
0.28029698 No improvement since epoch  609 ; best_mse,best_ci: 0.26704255 0.8762852762253629 GCNNet davis
Training on 25046 samples...
Train epoch: 616 [0/25046 (0%)]	Loss: 0.088319
Train epoch: 616 [329260/25046 (41%)]	Loss: 0.117104
Train epoch: 616 [645680/25046 (82%)]	Loss: 0.094281
Make prediction for 5010 samples...
0.26957905 No improvement since epoch  609 ; best_mse,best_ci: 0.26704255 0.8762852762253629 GCNNet davis
Training on 25046 samples...
Train epoch: 617 [0/25046 (0%)]	Loss: 0.116533
Train epoch: 617 [326660/25046 (41%)]	Loss: 0.124541
Train epoch: 617 [662400/25046 (82%)]	Loss: 0.134857
Make prediction for 5010 samples...
0.29788682 No improvement since epoch  609 ; best_mse,best_ci: 0.26704255 0.8762852762253629 GCNNet davis
Training on 25046 samples...
Train epoch: 618 [0/25046 (0%)]	Loss: 0.116025
Train epoch: 618 [331860/25046 (41%)]	Loss: 0.118484
Train epoch: 618 [660840/25046 (82%)]	Loss: 0.143082
Make prediction for 5010 samples...
0.29020002 No improvement since epoch  609 ; best_mse,best_ci: 0.26704255 0.8762852762253629 GCNNet davis
Training on 25046 samples...
Train epoch: 619 [0/25046 (0%)]	Loss: 0.164612
Train epoch: 619 [326840/25046 (41%)]	Loss: 0.107084
Train epoch: 619 [651120/25046 (82%)]	Loss: 0.146381
Make prediction for 5010 samples...
0.2745317 No improvement since epoch  609 ; best_mse,best_ci: 0.26704255 0.8762852762253629 GCNNet davis
Training on 25046 samples...
Train epoch: 620 [0/25046 (0%)]	Loss: 0.143609
Train epoch: 620 [329120/25046 (41%)]	Loss: 0.105984
Train epoch: 620 [648560/25046 (82%)]	Loss: 0.158290
Make prediction for 5010 samples...
0.27768824 No improvement since epoch  609 ; best_mse,best_ci: 0.26704255 0.8762852762253629 GCNNet davis
Training on 25046 samples...
Train epoch: 621 [0/25046 (0%)]	Loss: 0.116132
Train epoch: 621 [330020/25046 (41%)]	Loss: 0.120295
Train epoch: 621 [664760/25046 (82%)]	Loss: 0.117567
Make prediction for 5010 samples...
0.27401763 No improvement since epoch  609 ; best_mse,best_ci: 0.26704255 0.8762852762253629 GCNNet davis
Training on 25046 samples...
Train epoch: 622 [0/25046 (0%)]	Loss: 0.128372
Train epoch: 622 [332380/25046 (41%)]	Loss: 0.103671
Train epoch: 622 [653240/25046 (82%)]	Loss: 0.109149
Make prediction for 5010 samples...
0.26809266 No improvement since epoch  609 ; best_mse,best_ci: 0.26704255 0.8762852762253629 GCNNet davis
Training on 25046 samples...
Train epoch: 623 [0/25046 (0%)]	Loss: 0.105934
Train epoch: 623 [326600/25046 (41%)]	Loss: 0.128527
Train epoch: 623 [654000/25046 (82%)]	Loss: 0.095887
Make prediction for 5010 samples...
0.26937288 No improvement since epoch  609 ; best_mse,best_ci: 0.26704255 0.8762852762253629 GCNNet davis
Training on 25046 samples...
Train epoch: 624 [0/25046 (0%)]	Loss: 0.092746
Train epoch: 624 [326760/25046 (41%)]	Loss: 0.108214
Train epoch: 624 [643320/25046 (82%)]	Loss: 0.162944
Make prediction for 5010 samples...
0.27587184 No improvement since epoch  609 ; best_mse,best_ci: 0.26704255 0.8762852762253629 GCNNet davis
Training on 25046 samples...
Train epoch: 625 [0/25046 (0%)]	Loss: 0.102172
Train epoch: 625 [328340/25046 (41%)]	Loss: 0.128733
Train epoch: 625 [655040/25046 (82%)]	Loss: 0.117373
Make prediction for 5010 samples...
0.2706186 No improvement since epoch  609 ; best_mse,best_ci: 0.26704255 0.8762852762253629 GCNNet davis
Training on 25046 samples...
Train epoch: 626 [0/25046 (0%)]	Loss: 0.092232
Train epoch: 626 [325660/25046 (41%)]	Loss: 0.121030
Train epoch: 626 [651200/25046 (82%)]	Loss: 0.129482
Make prediction for 5010 samples...
0.2946344 No improvement since epoch  609 ; best_mse,best_ci: 0.26704255 0.8762852762253629 GCNNet davis
Training on 25046 samples...
Train epoch: 627 [0/25046 (0%)]	Loss: 0.139662
Train epoch: 627 [324760/25046 (41%)]	Loss: 0.122162
Train epoch: 627 [654240/25046 (82%)]	Loss: 0.153361
Make prediction for 5010 samples...
0.2777639 No improvement since epoch  609 ; best_mse,best_ci: 0.26704255 0.8762852762253629 GCNNet davis
Training on 25046 samples...
Train epoch: 628 [0/25046 (0%)]	Loss: 0.122815
Train epoch: 628 [327200/25046 (41%)]	Loss: 0.146370
Train epoch: 628 [662960/25046 (82%)]	Loss: 0.102236
Make prediction for 5010 samples...
0.26895264 No improvement since epoch  609 ; best_mse,best_ci: 0.26704255 0.8762852762253629 GCNNet davis
Training on 25046 samples...
Train epoch: 629 [0/25046 (0%)]	Loss: 0.136492
Train epoch: 629 [326140/25046 (41%)]	Loss: 0.110333
Train epoch: 629 [648800/25046 (82%)]	Loss: 0.103616
Make prediction for 5010 samples...
0.2761704 No improvement since epoch  609 ; best_mse,best_ci: 0.26704255 0.8762852762253629 GCNNet davis
Training on 25046 samples...
Train epoch: 630 [0/25046 (0%)]	Loss: 0.108641
Train epoch: 630 [329260/25046 (41%)]	Loss: 0.124020
Train epoch: 630 [648240/25046 (82%)]	Loss: 0.128109
Make prediction for 5010 samples...
0.2829119 No improvement since epoch  609 ; best_mse,best_ci: 0.26704255 0.8762852762253629 GCNNet davis
Training on 25046 samples...
Train epoch: 631 [0/25046 (0%)]	Loss: 0.096220
Train epoch: 631 [324500/25046 (41%)]	Loss: 0.152654
Train epoch: 631 [651640/25046 (82%)]	Loss: 0.126724
Make prediction for 5010 samples...
0.27348614 No improvement since epoch  609 ; best_mse,best_ci: 0.26704255 0.8762852762253629 GCNNet davis
Training on 25046 samples...
Train epoch: 632 [0/25046 (0%)]	Loss: 0.110794
Train epoch: 632 [325180/25046 (41%)]	Loss: 0.109472
Train epoch: 632 [655360/25046 (82%)]	Loss: 0.138014
Make prediction for 5010 samples...
0.30592015 No improvement since epoch  609 ; best_mse,best_ci: 0.26704255 0.8762852762253629 GCNNet davis
Training on 25046 samples...
Train epoch: 633 [0/25046 (0%)]	Loss: 0.116335
Train epoch: 633 [327520/25046 (41%)]	Loss: 0.144608
Train epoch: 633 [659640/25046 (82%)]	Loss: 0.125748
Make prediction for 5010 samples...
0.30880967 No improvement since epoch  609 ; best_mse,best_ci: 0.26704255 0.8762852762253629 GCNNet davis
Training on 25046 samples...
Train epoch: 634 [0/25046 (0%)]	Loss: 0.185787
Train epoch: 634 [325460/25046 (41%)]	Loss: 0.158451
Train epoch: 634 [653040/25046 (82%)]	Loss: 0.167014
Make prediction for 5010 samples...
0.28088096 No improvement since epoch  609 ; best_mse,best_ci: 0.26704255 0.8762852762253629 GCNNet davis
Training on 25046 samples...
Train epoch: 635 [0/25046 (0%)]	Loss: 0.121354
Train epoch: 635 [323560/25046 (41%)]	Loss: 0.140688
Train epoch: 635 [662240/25046 (82%)]	Loss: 0.129373
Make prediction for 5010 samples...
0.28059655 No improvement since epoch  609 ; best_mse,best_ci: 0.26704255 0.8762852762253629 GCNNet davis
Training on 25046 samples...
Train epoch: 636 [0/25046 (0%)]	Loss: 0.136389
Train epoch: 636 [325520/25046 (41%)]	Loss: 0.088735
Train epoch: 636 [653160/25046 (82%)]	Loss: 0.115395
Make prediction for 5010 samples...
0.30513602 No improvement since epoch  609 ; best_mse,best_ci: 0.26704255 0.8762852762253629 GCNNet davis
Training on 25046 samples...
Train epoch: 637 [0/25046 (0%)]	Loss: 0.121212
Train epoch: 637 [331140/25046 (41%)]	Loss: 0.143638
Train epoch: 637 [660840/25046 (82%)]	Loss: 0.126142
Make prediction for 5010 samples...
0.2870438 No improvement since epoch  609 ; best_mse,best_ci: 0.26704255 0.8762852762253629 GCNNet davis
Training on 25046 samples...
Train epoch: 638 [0/25046 (0%)]	Loss: 0.096631
Train epoch: 638 [330280/25046 (41%)]	Loss: 0.096941
Train epoch: 638 [647160/25046 (82%)]	Loss: 0.116502
Make prediction for 5010 samples...
0.29665568 No improvement since epoch  609 ; best_mse,best_ci: 0.26704255 0.8762852762253629 GCNNet davis
Training on 25046 samples...
Train epoch: 639 [0/25046 (0%)]	Loss: 0.116148
Train epoch: 639 [325740/25046 (41%)]	Loss: 0.100624
Train epoch: 639 [653320/25046 (82%)]	Loss: 0.143337
Make prediction for 5010 samples...
0.27219683 No improvement since epoch  609 ; best_mse,best_ci: 0.26704255 0.8762852762253629 GCNNet davis
Training on 25046 samples...
Train epoch: 640 [0/25046 (0%)]	Loss: 0.113606
Train epoch: 640 [322300/25046 (41%)]	Loss: 0.122653
Train epoch: 640 [654840/25046 (82%)]	Loss: 0.093766
Make prediction for 5010 samples...
0.2717243 No improvement since epoch  609 ; best_mse,best_ci: 0.26704255 0.8762852762253629 GCNNet davis
Training on 25046 samples...
Train epoch: 641 [0/25046 (0%)]	Loss: 0.128961
Train epoch: 641 [328820/25046 (41%)]	Loss: 0.118490
Train epoch: 641 [655440/25046 (82%)]	Loss: 0.124183
Make prediction for 5010 samples...
0.27085754 No improvement since epoch  609 ; best_mse,best_ci: 0.26704255 0.8762852762253629 GCNNet davis
Training on 25046 samples...
Train epoch: 642 [0/25046 (0%)]	Loss: 0.123043
Train epoch: 642 [330540/25046 (41%)]	Loss: 0.090874
Train epoch: 642 [657600/25046 (82%)]	Loss: 0.100804
Make prediction for 5010 samples...
0.2758807 No improvement since epoch  609 ; best_mse,best_ci: 0.26704255 0.8762852762253629 GCNNet davis
Training on 25046 samples...
Train epoch: 643 [0/25046 (0%)]	Loss: 0.108028
Train epoch: 643 [328600/25046 (41%)]	Loss: 0.137481
Train epoch: 643 [665000/25046 (82%)]	Loss: 0.121267
Make prediction for 5010 samples...
0.34148735 No improvement since epoch  609 ; best_mse,best_ci: 0.26704255 0.8762852762253629 GCNNet davis
Training on 25046 samples...
Train epoch: 644 [0/25046 (0%)]	Loss: 0.144916
Train epoch: 644 [326600/25046 (41%)]	Loss: 0.105056
Train epoch: 644 [649920/25046 (82%)]	Loss: 0.172939
Make prediction for 5010 samples...
0.2751204 No improvement since epoch  609 ; best_mse,best_ci: 0.26704255 0.8762852762253629 GCNNet davis
Training on 25046 samples...
Train epoch: 645 [0/25046 (0%)]	Loss: 0.123554
Train epoch: 645 [322440/25046 (41%)]	Loss: 0.097985
Train epoch: 645 [656080/25046 (82%)]	Loss: 0.107196
Make prediction for 5010 samples...
0.28295562 No improvement since epoch  609 ; best_mse,best_ci: 0.26704255 0.8762852762253629 GCNNet davis
Training on 25046 samples...
Train epoch: 646 [0/25046 (0%)]	Loss: 0.126225
Train epoch: 646 [322480/25046 (41%)]	Loss: 0.118581
Train epoch: 646 [656760/25046 (82%)]	Loss: 0.148323
Make prediction for 5010 samples...
0.2948921 No improvement since epoch  609 ; best_mse,best_ci: 0.26704255 0.8762852762253629 GCNNet davis
Training on 25046 samples...
Train epoch: 647 [0/25046 (0%)]	Loss: 0.125799
Train epoch: 647 [325200/25046 (41%)]	Loss: 0.106207
Train epoch: 647 [661200/25046 (82%)]	Loss: 0.109472
Make prediction for 5010 samples...
0.3008784 No improvement since epoch  609 ; best_mse,best_ci: 0.26704255 0.8762852762253629 GCNNet davis
Training on 25046 samples...
Train epoch: 648 [0/25046 (0%)]	Loss: 0.117855
Train epoch: 648 [324100/25046 (41%)]	Loss: 0.114636
Train epoch: 648 [666120/25046 (82%)]	Loss: 0.099367
Make prediction for 5010 samples...
0.29111186 No improvement since epoch  609 ; best_mse,best_ci: 0.26704255 0.8762852762253629 GCNNet davis
Training on 25046 samples...
Train epoch: 649 [0/25046 (0%)]	Loss: 0.118553
Train epoch: 649 [326060/25046 (41%)]	Loss: 0.105986
Train epoch: 649 [660200/25046 (82%)]	Loss: 0.114384
Make prediction for 5010 samples...
0.30210617 No improvement since epoch  609 ; best_mse,best_ci: 0.26704255 0.8762852762253629 GCNNet davis
Training on 25046 samples...
Train epoch: 650 [0/25046 (0%)]	Loss: 0.121755
Train epoch: 650 [329340/25046 (41%)]	Loss: 0.166844
Train epoch: 650 [663200/25046 (82%)]	Loss: 0.143339
Make prediction for 5010 samples...
0.27709836 No improvement since epoch  609 ; best_mse,best_ci: 0.26704255 0.8762852762253629 GCNNet davis
Training on 25046 samples...
Train epoch: 651 [0/25046 (0%)]	Loss: 0.118033
Train epoch: 651 [323000/25046 (41%)]	Loss: 0.123564
Train epoch: 651 [653120/25046 (82%)]	Loss: 0.103811
Make prediction for 5010 samples...
0.27820078 No improvement since epoch  609 ; best_mse,best_ci: 0.26704255 0.8762852762253629 GCNNet davis
Training on 25046 samples...
Train epoch: 652 [0/25046 (0%)]	Loss: 0.157577
Train epoch: 652 [322320/25046 (41%)]	Loss: 0.104523
Train epoch: 652 [655480/25046 (82%)]	Loss: 0.117833
Make prediction for 5010 samples...
0.2858396 No improvement since epoch  609 ; best_mse,best_ci: 0.26704255 0.8762852762253629 GCNNet davis
Training on 25046 samples...
Train epoch: 653 [0/25046 (0%)]	Loss: 0.089537
Train epoch: 653 [324800/25046 (41%)]	Loss: 0.118222
Train epoch: 653 [651560/25046 (82%)]	Loss: 0.091964
Make prediction for 5010 samples...
0.27546313 No improvement since epoch  609 ; best_mse,best_ci: 0.26704255 0.8762852762253629 GCNNet davis
Training on 25046 samples...
Train epoch: 654 [0/25046 (0%)]	Loss: 0.100678
Train epoch: 654 [329460/25046 (41%)]	Loss: 0.120241
Train epoch: 654 [666800/25046 (82%)]	Loss: 0.096207
Make prediction for 5010 samples...
0.28890926 No improvement since epoch  609 ; best_mse,best_ci: 0.26704255 0.8762852762253629 GCNNet davis
Training on 25046 samples...
Train epoch: 655 [0/25046 (0%)]	Loss: 0.113167
Train epoch: 655 [327540/25046 (41%)]	Loss: 0.110469
Train epoch: 655 [657160/25046 (82%)]	Loss: 0.163065
Make prediction for 5010 samples...
0.27385825 No improvement since epoch  609 ; best_mse,best_ci: 0.26704255 0.8762852762253629 GCNNet davis
Training on 25046 samples...
Train epoch: 656 [0/25046 (0%)]	Loss: 0.120251
Train epoch: 656 [329480/25046 (41%)]	Loss: 0.120096
Train epoch: 656 [657280/25046 (82%)]	Loss: 0.104861
Make prediction for 5010 samples...
0.27172723 No improvement since epoch  609 ; best_mse,best_ci: 0.26704255 0.8762852762253629 GCNNet davis
Training on 25046 samples...
Train epoch: 657 [0/25046 (0%)]	Loss: 0.121556
Train epoch: 657 [330580/25046 (41%)]	Loss: 0.151295
Train epoch: 657 [660120/25046 (82%)]	Loss: 0.104465
Make prediction for 5010 samples...
0.272591 No improvement since epoch  609 ; best_mse,best_ci: 0.26704255 0.8762852762253629 GCNNet davis
Training on 25046 samples...
Train epoch: 658 [0/25046 (0%)]	Loss: 0.101518
Train epoch: 658 [323680/25046 (41%)]	Loss: 0.097999
Train epoch: 658 [658360/25046 (82%)]	Loss: 0.155144
Make prediction for 5010 samples...
0.2802906 No improvement since epoch  609 ; best_mse,best_ci: 0.26704255 0.8762852762253629 GCNNet davis
Training on 25046 samples...
Train epoch: 659 [0/25046 (0%)]	Loss: 0.117594
Train epoch: 659 [326980/25046 (41%)]	Loss: 0.106801
Train epoch: 659 [657360/25046 (82%)]	Loss: 0.135851
Make prediction for 5010 samples...
0.27898243 No improvement since epoch  609 ; best_mse,best_ci: 0.26704255 0.8762852762253629 GCNNet davis
Training on 25046 samples...
Train epoch: 660 [0/25046 (0%)]	Loss: 0.102813
Train epoch: 660 [326560/25046 (41%)]	Loss: 0.145002
Train epoch: 660 [654800/25046 (82%)]	Loss: 0.101777
Make prediction for 5010 samples...
0.304845 No improvement since epoch  609 ; best_mse,best_ci: 0.26704255 0.8762852762253629 GCNNet davis
Training on 25046 samples...
Train epoch: 661 [0/25046 (0%)]	Loss: 0.114931
Train epoch: 661 [325380/25046 (41%)]	Loss: 0.108930
Train epoch: 661 [661320/25046 (82%)]	Loss: 0.100458
Make prediction for 5010 samples...
0.27852318 No improvement since epoch  609 ; best_mse,best_ci: 0.26704255 0.8762852762253629 GCNNet davis
Training on 25046 samples...
Train epoch: 662 [0/25046 (0%)]	Loss: 0.143295
Train epoch: 662 [328760/25046 (41%)]	Loss: 0.106779
Train epoch: 662 [663640/25046 (82%)]	Loss: 0.137596
Make prediction for 5010 samples...
0.28061205 No improvement since epoch  609 ; best_mse,best_ci: 0.26704255 0.8762852762253629 GCNNet davis
Training on 25046 samples...
Train epoch: 663 [0/25046 (0%)]	Loss: 0.122619
Train epoch: 663 [326620/25046 (41%)]	Loss: 0.122012
Train epoch: 663 [647800/25046 (82%)]	Loss: 0.145809
Make prediction for 5010 samples...
0.27870288 No improvement since epoch  609 ; best_mse,best_ci: 0.26704255 0.8762852762253629 GCNNet davis
Training on 25046 samples...
Train epoch: 664 [0/25046 (0%)]	Loss: 0.162405
Train epoch: 664 [327060/25046 (41%)]	Loss: 0.120558
Train epoch: 664 [656920/25046 (82%)]	Loss: 0.119387
Make prediction for 5010 samples...
0.280382 No improvement since epoch  609 ; best_mse,best_ci: 0.26704255 0.8762852762253629 GCNNet davis
Training on 25046 samples...
Train epoch: 665 [0/25046 (0%)]	Loss: 0.108177
Train epoch: 665 [328780/25046 (41%)]	Loss: 0.176015
Train epoch: 665 [657040/25046 (82%)]	Loss: 0.130927
Make prediction for 5010 samples...
0.2724271 No improvement since epoch  609 ; best_mse,best_ci: 0.26704255 0.8762852762253629 GCNNet davis
Training on 25046 samples...
Train epoch: 666 [0/25046 (0%)]	Loss: 0.124708
Train epoch: 666 [331960/25046 (41%)]	Loss: 0.096913
Train epoch: 666 [660000/25046 (82%)]	Loss: 0.133247
Make prediction for 5010 samples...
0.27494565 No improvement since epoch  609 ; best_mse,best_ci: 0.26704255 0.8762852762253629 GCNNet davis
Training on 25046 samples...
Train epoch: 667 [0/25046 (0%)]	Loss: 0.101459
Train epoch: 667 [328000/25046 (41%)]	Loss: 0.132793
Train epoch: 667 [658400/25046 (82%)]	Loss: 0.161779
Make prediction for 5010 samples...
0.28449494 No improvement since epoch  609 ; best_mse,best_ci: 0.26704255 0.8762852762253629 GCNNet davis
Training on 25046 samples...
Train epoch: 668 [0/25046 (0%)]	Loss: 0.122325
Train epoch: 668 [326460/25046 (41%)]	Loss: 0.129731
Train epoch: 668 [652280/25046 (82%)]	Loss: 0.099472
Make prediction for 5010 samples...
0.28769615 No improvement since epoch  609 ; best_mse,best_ci: 0.26704255 0.8762852762253629 GCNNet davis
Training on 25046 samples...
Train epoch: 669 [0/25046 (0%)]	Loss: 0.101595
Train epoch: 669 [330000/25046 (41%)]	Loss: 0.116621
Train epoch: 669 [649520/25046 (82%)]	Loss: 0.153193
Make prediction for 5010 samples...
0.27207908 No improvement since epoch  609 ; best_mse,best_ci: 0.26704255 0.8762852762253629 GCNNet davis
Training on 25046 samples...
Train epoch: 670 [0/25046 (0%)]	Loss: 0.127775
Train epoch: 670 [331780/25046 (41%)]	Loss: 0.111455
Train epoch: 670 [652960/25046 (82%)]	Loss: 0.114952
Make prediction for 5010 samples...
0.2702424 No improvement since epoch  609 ; best_mse,best_ci: 0.26704255 0.8762852762253629 GCNNet davis
Training on 25046 samples...
Train epoch: 671 [0/25046 (0%)]	Loss: 0.087579
Train epoch: 671 [324780/25046 (41%)]	Loss: 0.098963
Train epoch: 671 [654440/25046 (82%)]	Loss: 0.110394
Make prediction for 5010 samples...
0.27180213 No improvement since epoch  609 ; best_mse,best_ci: 0.26704255 0.8762852762253629 GCNNet davis
Training on 25046 samples...
Train epoch: 672 [0/25046 (0%)]	Loss: 0.089775
Train epoch: 672 [328320/25046 (41%)]	Loss: 0.151767
Train epoch: 672 [655040/25046 (82%)]	Loss: 0.121774
Make prediction for 5010 samples...
rmse improved at epoch  672 ; best_mse,best_ci: 0.26673812 0.8658695173072455 GCNNet davis
Training on 25046 samples...
Train epoch: 673 [0/25046 (0%)]	Loss: 0.089570
Train epoch: 673 [328300/25046 (41%)]	Loss: 0.115637
Train epoch: 673 [660120/25046 (82%)]	Loss: 0.163122
Make prediction for 5010 samples...
0.27072823 No improvement since epoch  672 ; best_mse,best_ci: 0.26673812 0.8658695173072455 GCNNet davis
Training on 25046 samples...
Train epoch: 674 [0/25046 (0%)]	Loss: 0.126670
Train epoch: 674 [325200/25046 (41%)]	Loss: 0.114852
Train epoch: 674 [649880/25046 (82%)]	Loss: 0.115497
Make prediction for 5010 samples...
0.28589982 No improvement since epoch  672 ; best_mse,best_ci: 0.26673812 0.8658695173072455 GCNNet davis
Training on 25046 samples...
Train epoch: 675 [0/25046 (0%)]	Loss: 0.117762
Train epoch: 675 [329360/25046 (41%)]	Loss: 0.193093
Train epoch: 675 [660600/25046 (82%)]	Loss: 0.165517
Make prediction for 5010 samples...
0.27744505 No improvement since epoch  672 ; best_mse,best_ci: 0.26673812 0.8658695173072455 GCNNet davis
Training on 25046 samples...
Train epoch: 676 [0/25046 (0%)]	Loss: 0.125685
Train epoch: 676 [328720/25046 (41%)]	Loss: 0.113698
Train epoch: 676 [647960/25046 (82%)]	Loss: 0.136519
Make prediction for 5010 samples...
0.29195574 No improvement since epoch  672 ; best_mse,best_ci: 0.26673812 0.8658695173072455 GCNNet davis
Training on 25046 samples...
Train epoch: 677 [0/25046 (0%)]	Loss: 0.114675
Train epoch: 677 [330000/25046 (41%)]	Loss: 0.139649
Train epoch: 677 [653240/25046 (82%)]	Loss: 0.107641
Make prediction for 5010 samples...
0.27973446 No improvement since epoch  672 ; best_mse,best_ci: 0.26673812 0.8658695173072455 GCNNet davis
Training on 25046 samples...
Train epoch: 678 [0/25046 (0%)]	Loss: 0.107922
Train epoch: 678 [328780/25046 (41%)]	Loss: 0.111729
Train epoch: 678 [659560/25046 (82%)]	Loss: 0.115268
Make prediction for 5010 samples...
0.27245235 No improvement since epoch  672 ; best_mse,best_ci: 0.26673812 0.8658695173072455 GCNNet davis
Training on 25046 samples...
Train epoch: 679 [0/25046 (0%)]	Loss: 0.124789
Train epoch: 679 [328080/25046 (41%)]	Loss: 0.120919
Train epoch: 679 [664040/25046 (82%)]	Loss: 0.102985
Make prediction for 5010 samples...
0.3032017 No improvement since epoch  672 ; best_mse,best_ci: 0.26673812 0.8658695173072455 GCNNet davis
Training on 25046 samples...
Train epoch: 680 [0/25046 (0%)]	Loss: 0.102469
Train epoch: 680 [327060/25046 (41%)]	Loss: 0.114036
Train epoch: 680 [650480/25046 (82%)]	Loss: 0.132275
Make prediction for 5010 samples...
0.3126424 No improvement since epoch  672 ; best_mse,best_ci: 0.26673812 0.8658695173072455 GCNNet davis
Training on 25046 samples...
Train epoch: 681 [0/25046 (0%)]	Loss: 0.106634
Train epoch: 681 [329660/25046 (41%)]	Loss: 0.087390
Train epoch: 681 [656560/25046 (82%)]	Loss: 0.102864
Make prediction for 5010 samples...
0.2727117 No improvement since epoch  672 ; best_mse,best_ci: 0.26673812 0.8658695173072455 GCNNet davis
Training on 25046 samples...
Train epoch: 682 [0/25046 (0%)]	Loss: 0.088570
Train epoch: 682 [328320/25046 (41%)]	Loss: 0.121224
Train epoch: 682 [654080/25046 (82%)]	Loss: 0.148766
Make prediction for 5010 samples...
0.2798129 No improvement since epoch  672 ; best_mse,best_ci: 0.26673812 0.8658695173072455 GCNNet davis
Training on 25046 samples...
Train epoch: 683 [0/25046 (0%)]	Loss: 0.133315
Train epoch: 683 [328980/25046 (41%)]	Loss: 0.122725
Train epoch: 683 [652520/25046 (82%)]	Loss: 0.111508
Make prediction for 5010 samples...
rmse improved at epoch  683 ; best_mse,best_ci: 0.26580483 0.8734655826930149 GCNNet davis
Training on 25046 samples...
Train epoch: 684 [0/25046 (0%)]	Loss: 0.138362
Train epoch: 684 [332160/25046 (41%)]	Loss: 0.128326
Train epoch: 684 [657000/25046 (82%)]	Loss: 0.087776
Make prediction for 5010 samples...
0.27939177 No improvement since epoch  683 ; best_mse,best_ci: 0.26580483 0.8734655826930149 GCNNet davis
Training on 25046 samples...
Train epoch: 685 [0/25046 (0%)]	Loss: 0.173085
Train epoch: 685 [330060/25046 (41%)]	Loss: 0.140691
Train epoch: 685 [656040/25046 (82%)]	Loss: 0.102756
Make prediction for 5010 samples...
0.27267355 No improvement since epoch  683 ; best_mse,best_ci: 0.26580483 0.8734655826930149 GCNNet davis
Training on 25046 samples...
Train epoch: 686 [0/25046 (0%)]	Loss: 0.100265
Train epoch: 686 [324160/25046 (41%)]	Loss: 0.114938
Train epoch: 686 [660320/25046 (82%)]	Loss: 0.110831
Make prediction for 5010 samples...
0.2896091 No improvement since epoch  683 ; best_mse,best_ci: 0.26580483 0.8734655826930149 GCNNet davis
Training on 25046 samples...
Train epoch: 687 [0/25046 (0%)]	Loss: 0.087895
Train epoch: 687 [328580/25046 (41%)]	Loss: 0.126447
Train epoch: 687 [657080/25046 (82%)]	Loss: 0.112603
Make prediction for 5010 samples...
0.3064627 No improvement since epoch  683 ; best_mse,best_ci: 0.26580483 0.8734655826930149 GCNNet davis
Training on 25046 samples...
Train epoch: 688 [0/25046 (0%)]	Loss: 0.146255
Train epoch: 688 [325680/25046 (41%)]	Loss: 0.159640
Train epoch: 688 [669440/25046 (82%)]	Loss: 0.114548
Make prediction for 5010 samples...
0.2740921 No improvement since epoch  683 ; best_mse,best_ci: 0.26580483 0.8734655826930149 GCNNet davis
Training on 25046 samples...
Train epoch: 689 [0/25046 (0%)]	Loss: 0.112826
Train epoch: 689 [333460/25046 (41%)]	Loss: 0.136407
Train epoch: 689 [653400/25046 (82%)]	Loss: 0.133716
Make prediction for 5010 samples...
0.2754472 No improvement since epoch  683 ; best_mse,best_ci: 0.26580483 0.8734655826930149 GCNNet davis
Training on 25046 samples...
Train epoch: 690 [0/25046 (0%)]	Loss: 0.120156
Train epoch: 690 [328520/25046 (41%)]	Loss: 0.081667
Train epoch: 690 [651040/25046 (82%)]	Loss: 0.121214
Make prediction for 5010 samples...
0.28058666 No improvement since epoch  683 ; best_mse,best_ci: 0.26580483 0.8734655826930149 GCNNet davis
Training on 25046 samples...
Train epoch: 691 [0/25046 (0%)]	Loss: 0.130796
Train epoch: 691 [330220/25046 (41%)]	Loss: 0.100841
Train epoch: 691 [655120/25046 (82%)]	Loss: 0.095136
Make prediction for 5010 samples...
0.34217754 No improvement since epoch  683 ; best_mse,best_ci: 0.26580483 0.8734655826930149 GCNNet davis
Training on 25046 samples...
Train epoch: 692 [0/25046 (0%)]	Loss: 0.132804
Train epoch: 692 [325980/25046 (41%)]	Loss: 0.135798
Train epoch: 692 [648560/25046 (82%)]	Loss: 0.092069
Make prediction for 5010 samples...
0.27391082 No improvement since epoch  683 ; best_mse,best_ci: 0.26580483 0.8734655826930149 GCNNet davis
Training on 25046 samples...
Train epoch: 693 [0/25046 (0%)]	Loss: 0.094754
Train epoch: 693 [329100/25046 (41%)]	Loss: 0.117204
Train epoch: 693 [664440/25046 (82%)]	Loss: 0.181477
Make prediction for 5010 samples...
0.29286602 No improvement since epoch  683 ; best_mse,best_ci: 0.26580483 0.8734655826930149 GCNNet davis
Training on 25046 samples...
Train epoch: 694 [0/25046 (0%)]	Loss: 0.107161
Train epoch: 694 [330520/25046 (41%)]	Loss: 0.090865
Train epoch: 694 [660200/25046 (82%)]	Loss: 0.082491
Make prediction for 5010 samples...
0.2731823 No improvement since epoch  683 ; best_mse,best_ci: 0.26580483 0.8734655826930149 GCNNet davis
Training on 25046 samples...
Train epoch: 695 [0/25046 (0%)]	Loss: 0.120797
Train epoch: 695 [329060/25046 (41%)]	Loss: 0.099453
Train epoch: 695 [662560/25046 (82%)]	Loss: 0.124669
Make prediction for 5010 samples...
0.26826152 No improvement since epoch  683 ; best_mse,best_ci: 0.26580483 0.8734655826930149 GCNNet davis
Training on 25046 samples...
Train epoch: 696 [0/25046 (0%)]	Loss: 0.118512
Train epoch: 696 [326860/25046 (41%)]	Loss: 0.123550
Train epoch: 696 [659520/25046 (82%)]	Loss: 0.117579
Make prediction for 5010 samples...
0.269326 No improvement since epoch  683 ; best_mse,best_ci: 0.26580483 0.8734655826930149 GCNNet davis
Training on 25046 samples...
Train epoch: 697 [0/25046 (0%)]	Loss: 0.128846
Train epoch: 697 [327920/25046 (41%)]	Loss: 0.136933
Train epoch: 697 [655640/25046 (82%)]	Loss: 0.100058
Make prediction for 5010 samples...
rmse improved at epoch  697 ; best_mse,best_ci: 0.26544225 0.877861676503917 GCNNet davis
Training on 25046 samples...
Train epoch: 698 [0/25046 (0%)]	Loss: 0.095754
Train epoch: 698 [326020/25046 (41%)]	Loss: 0.137645
Train epoch: 698 [666480/25046 (82%)]	Loss: 0.104253
Make prediction for 5010 samples...
0.28864494 No improvement since epoch  697 ; best_mse,best_ci: 0.26544225 0.877861676503917 GCNNet davis
Training on 25046 samples...
Train epoch: 699 [0/25046 (0%)]	Loss: 0.090990
Train epoch: 699 [329280/25046 (41%)]	Loss: 0.092399
Train epoch: 699 [645680/25046 (82%)]	Loss: 0.113248
Make prediction for 5010 samples...
0.2872585 No improvement since epoch  697 ; best_mse,best_ci: 0.26544225 0.877861676503917 GCNNet davis
Training on 25046 samples...
Train epoch: 700 [0/25046 (0%)]	Loss: 0.099941
Train epoch: 700 [332220/25046 (41%)]	Loss: 0.093604
Train epoch: 700 [661400/25046 (82%)]	Loss: 0.122301
Make prediction for 5010 samples...
0.2730604 No improvement since epoch  697 ; best_mse,best_ci: 0.26544225 0.877861676503917 GCNNet davis
Training on 25046 samples...
Train epoch: 701 [0/25046 (0%)]	Loss: 0.121803
Train epoch: 701 [323200/25046 (41%)]	Loss: 0.159884
Train epoch: 701 [654760/25046 (82%)]	Loss: 0.103155
Make prediction for 5010 samples...
0.27953908 No improvement since epoch  697 ; best_mse,best_ci: 0.26544225 0.877861676503917 GCNNet davis
Training on 25046 samples...
Train epoch: 702 [0/25046 (0%)]	Loss: 0.102814
Train epoch: 702 [331600/25046 (41%)]	Loss: 0.108095
Train epoch: 702 [659160/25046 (82%)]	Loss: 0.105047
Make prediction for 5010 samples...
0.28149158 No improvement since epoch  697 ; best_mse,best_ci: 0.26544225 0.877861676503917 GCNNet davis
Training on 25046 samples...
Train epoch: 703 [0/25046 (0%)]	Loss: 0.100665
Train epoch: 703 [330540/25046 (41%)]	Loss: 0.089116
Train epoch: 703 [652560/25046 (82%)]	Loss: 0.115617
Make prediction for 5010 samples...
0.33759874 No improvement since epoch  697 ; best_mse,best_ci: 0.26544225 0.877861676503917 GCNNet davis
Training on 25046 samples...
Train epoch: 704 [0/25046 (0%)]	Loss: 0.140244
Train epoch: 704 [328660/25046 (41%)]	Loss: 0.090582
Train epoch: 704 [661320/25046 (82%)]	Loss: 0.114567
Make prediction for 5010 samples...
0.2781409 No improvement since epoch  697 ; best_mse,best_ci: 0.26544225 0.877861676503917 GCNNet davis
Training on 25046 samples...
Train epoch: 705 [0/25046 (0%)]	Loss: 0.132626
Train epoch: 705 [329740/25046 (41%)]	Loss: 0.103462
Train epoch: 705 [660600/25046 (82%)]	Loss: 0.101694
Make prediction for 5010 samples...
0.27208188 No improvement since epoch  697 ; best_mse,best_ci: 0.26544225 0.877861676503917 GCNNet davis
Training on 25046 samples...
Train epoch: 706 [0/25046 (0%)]	Loss: 0.125967
Train epoch: 706 [330520/25046 (41%)]	Loss: 0.110924
Train epoch: 706 [657520/25046 (82%)]	Loss: 0.126182
Make prediction for 5010 samples...
0.28903145 No improvement since epoch  697 ; best_mse,best_ci: 0.26544225 0.877861676503917 GCNNet davis
Training on 25046 samples...
Train epoch: 707 [0/25046 (0%)]	Loss: 0.112400
Train epoch: 707 [336920/25046 (41%)]	Loss: 0.118920
Train epoch: 707 [661360/25046 (82%)]	Loss: 0.110951
Make prediction for 5010 samples...
0.26949358 No improvement since epoch  697 ; best_mse,best_ci: 0.26544225 0.877861676503917 GCNNet davis
Training on 25046 samples...
Train epoch: 708 [0/25046 (0%)]	Loss: 0.116528
Train epoch: 708 [327820/25046 (41%)]	Loss: 0.120892
Train epoch: 708 [659120/25046 (82%)]	Loss: 0.143920
Make prediction for 5010 samples...
0.28603497 No improvement since epoch  697 ; best_mse,best_ci: 0.26544225 0.877861676503917 GCNNet davis
Training on 25046 samples...
Train epoch: 709 [0/25046 (0%)]	Loss: 0.093085
Train epoch: 709 [330900/25046 (41%)]	Loss: 0.094271
Train epoch: 709 [664520/25046 (82%)]	Loss: 0.105672
Make prediction for 5010 samples...
0.27100292 No improvement since epoch  697 ; best_mse,best_ci: 0.26544225 0.877861676503917 GCNNet davis
Training on 25046 samples...
Train epoch: 710 [0/25046 (0%)]	Loss: 0.108505
Train epoch: 710 [334040/25046 (41%)]	Loss: 0.127306
Train epoch: 710 [664400/25046 (82%)]	Loss: 0.098103
Make prediction for 5010 samples...
0.28800616 No improvement since epoch  697 ; best_mse,best_ci: 0.26544225 0.877861676503917 GCNNet davis
Training on 25046 samples...
Train epoch: 711 [0/25046 (0%)]	Loss: 0.111522
Train epoch: 711 [329980/25046 (41%)]	Loss: 0.108761
Train epoch: 711 [650480/25046 (82%)]	Loss: 0.105932
Make prediction for 5010 samples...
0.2729223 No improvement since epoch  697 ; best_mse,best_ci: 0.26544225 0.877861676503917 GCNNet davis
Training on 25046 samples...
Train epoch: 712 [0/25046 (0%)]	Loss: 0.084655
Train epoch: 712 [330480/25046 (41%)]	Loss: 0.108984
Train epoch: 712 [653280/25046 (82%)]	Loss: 0.120510
Make prediction for 5010 samples...
0.27434173 No improvement since epoch  697 ; best_mse,best_ci: 0.26544225 0.877861676503917 GCNNet davis
Training on 25046 samples...
Train epoch: 713 [0/25046 (0%)]	Loss: 0.099711
Train epoch: 713 [325180/25046 (41%)]	Loss: 0.142923
Train epoch: 713 [654000/25046 (82%)]	Loss: 0.077921
Make prediction for 5010 samples...
0.2662197 No improvement since epoch  697 ; best_mse,best_ci: 0.26544225 0.877861676503917 GCNNet davis
Training on 25046 samples...
Train epoch: 714 [0/25046 (0%)]	Loss: 0.130289
Train epoch: 714 [323440/25046 (41%)]	Loss: 0.078185
Train epoch: 714 [654480/25046 (82%)]	Loss: 0.107057
Make prediction for 5010 samples...
0.32646647 No improvement since epoch  697 ; best_mse,best_ci: 0.26544225 0.877861676503917 GCNNet davis
Training on 25046 samples...
Train epoch: 715 [0/25046 (0%)]	Loss: 0.117058
Train epoch: 715 [328340/25046 (41%)]	Loss: 0.114269
Train epoch: 715 [657480/25046 (82%)]	Loss: 0.138666
Make prediction for 5010 samples...
0.299735 No improvement since epoch  697 ; best_mse,best_ci: 0.26544225 0.877861676503917 GCNNet davis
Training on 25046 samples...
Train epoch: 716 [0/25046 (0%)]	Loss: 0.094076
Train epoch: 716 [325160/25046 (41%)]	Loss: 0.115112
Train epoch: 716 [643880/25046 (82%)]	Loss: 0.108283
Make prediction for 5010 samples...
0.27016872 No improvement since epoch  697 ; best_mse,best_ci: 0.26544225 0.877861676503917 GCNNet davis
Training on 25046 samples...
Train epoch: 717 [0/25046 (0%)]	Loss: 0.103239
Train epoch: 717 [332420/25046 (41%)]	Loss: 0.149235
Train epoch: 717 [661080/25046 (82%)]	Loss: 0.156769
Make prediction for 5010 samples...
0.2785439 No improvement since epoch  697 ; best_mse,best_ci: 0.26544225 0.877861676503917 GCNNet davis
Training on 25046 samples...
Train epoch: 718 [0/25046 (0%)]	Loss: 0.093594
Train epoch: 718 [329220/25046 (41%)]	Loss: 0.107868
Train epoch: 718 [657880/25046 (82%)]	Loss: 0.104317
Make prediction for 5010 samples...
0.2719956 No improvement since epoch  697 ; best_mse,best_ci: 0.26544225 0.877861676503917 GCNNet davis
Training on 25046 samples...
Train epoch: 719 [0/25046 (0%)]	Loss: 0.131512
Train epoch: 719 [329680/25046 (41%)]	Loss: 0.093367
Train epoch: 719 [651120/25046 (82%)]	Loss: 0.098277
Make prediction for 5010 samples...
0.2831333 No improvement since epoch  697 ; best_mse,best_ci: 0.26544225 0.877861676503917 GCNNet davis
Training on 25046 samples...
Train epoch: 720 [0/25046 (0%)]	Loss: 0.090561
Train epoch: 720 [326740/25046 (41%)]	Loss: 0.100751
Train epoch: 720 [656840/25046 (82%)]	Loss: 0.136769
Make prediction for 5010 samples...
0.28557768 No improvement since epoch  697 ; best_mse,best_ci: 0.26544225 0.877861676503917 GCNNet davis
Training on 25046 samples...
Train epoch: 721 [0/25046 (0%)]	Loss: 0.146662
Train epoch: 721 [325480/25046 (41%)]	Loss: 0.109282
Train epoch: 721 [653000/25046 (82%)]	Loss: 0.098062
Make prediction for 5010 samples...
0.27156365 No improvement since epoch  697 ; best_mse,best_ci: 0.26544225 0.877861676503917 GCNNet davis
Training on 25046 samples...
Train epoch: 722 [0/25046 (0%)]	Loss: 0.108021
Train epoch: 722 [327460/25046 (41%)]	Loss: 0.105618
Train epoch: 722 [654280/25046 (82%)]	Loss: 0.095538
Make prediction for 5010 samples...
0.27269295 No improvement since epoch  697 ; best_mse,best_ci: 0.26544225 0.877861676503917 GCNNet davis
Training on 25046 samples...
Train epoch: 723 [0/25046 (0%)]	Loss: 0.127161
Train epoch: 723 [329060/25046 (41%)]	Loss: 0.125659
Train epoch: 723 [661600/25046 (82%)]	Loss: 0.108509
Make prediction for 5010 samples...
0.34814584 No improvement since epoch  697 ; best_mse,best_ci: 0.26544225 0.877861676503917 GCNNet davis
Training on 25046 samples...
Train epoch: 724 [0/25046 (0%)]	Loss: 0.129634
Train epoch: 724 [327540/25046 (41%)]	Loss: 0.111035
Train epoch: 724 [644240/25046 (82%)]	Loss: 0.097800
Make prediction for 5010 samples...
0.29263145 No improvement since epoch  697 ; best_mse,best_ci: 0.26544225 0.877861676503917 GCNNet davis
Training on 25046 samples...
Train epoch: 725 [0/25046 (0%)]	Loss: 0.106573
Train epoch: 725 [328520/25046 (41%)]	Loss: 0.112074
Train epoch: 725 [656240/25046 (82%)]	Loss: 0.089789
Make prediction for 5010 samples...
0.2684332 No improvement since epoch  697 ; best_mse,best_ci: 0.26544225 0.877861676503917 GCNNet davis
Training on 25046 samples...
Train epoch: 726 [0/25046 (0%)]	Loss: 0.101159
Train epoch: 726 [325860/25046 (41%)]	Loss: 0.124744
Train epoch: 726 [648600/25046 (82%)]	Loss: 0.106290
Make prediction for 5010 samples...
0.27849653 No improvement since epoch  697 ; best_mse,best_ci: 0.26544225 0.877861676503917 GCNNet davis
Training on 25046 samples...
Train epoch: 727 [0/25046 (0%)]	Loss: 0.099275
Train epoch: 727 [327900/25046 (41%)]	Loss: 0.099304
Train epoch: 727 [652840/25046 (82%)]	Loss: 0.111067
Make prediction for 5010 samples...
0.2744268 No improvement since epoch  697 ; best_mse,best_ci: 0.26544225 0.877861676503917 GCNNet davis
Training on 25046 samples...
Train epoch: 728 [0/25046 (0%)]	Loss: 0.129669
Train epoch: 728 [335300/25046 (41%)]	Loss: 0.120144
Train epoch: 728 [657480/25046 (82%)]	Loss: 0.099635
Make prediction for 5010 samples...
0.27616826 No improvement since epoch  697 ; best_mse,best_ci: 0.26544225 0.877861676503917 GCNNet davis
Training on 25046 samples...
Train epoch: 729 [0/25046 (0%)]	Loss: 0.094075
Train epoch: 729 [330360/25046 (41%)]	Loss: 0.135698
Train epoch: 729 [645560/25046 (82%)]	Loss: 0.150254
Make prediction for 5010 samples...
0.28790534 No improvement since epoch  697 ; best_mse,best_ci: 0.26544225 0.877861676503917 GCNNet davis
Training on 25046 samples...
Train epoch: 730 [0/25046 (0%)]	Loss: 0.089653
Train epoch: 730 [329620/25046 (41%)]	Loss: 0.091359
Train epoch: 730 [657240/25046 (82%)]	Loss: 0.107227
Make prediction for 5010 samples...
0.27604964 No improvement since epoch  697 ; best_mse,best_ci: 0.26544225 0.877861676503917 GCNNet davis
Training on 25046 samples...
Train epoch: 731 [0/25046 (0%)]	Loss: 0.137576
Train epoch: 731 [331040/25046 (41%)]	Loss: 0.131295
Train epoch: 731 [658200/25046 (82%)]	Loss: 0.093235
Make prediction for 5010 samples...
0.30452597 No improvement since epoch  697 ; best_mse,best_ci: 0.26544225 0.877861676503917 GCNNet davis
Training on 25046 samples...
Train epoch: 732 [0/25046 (0%)]	Loss: 0.118021
Train epoch: 732 [328520/25046 (41%)]	Loss: 0.129064
Train epoch: 732 [655920/25046 (82%)]	Loss: 0.125248
Make prediction for 5010 samples...
0.27981862 No improvement since epoch  697 ; best_mse,best_ci: 0.26544225 0.877861676503917 GCNNet davis
Training on 25046 samples...
Train epoch: 733 [0/25046 (0%)]	Loss: 0.118790
Train epoch: 733 [329460/25046 (41%)]	Loss: 0.095377
Train epoch: 733 [669960/25046 (82%)]	Loss: 0.102022
Make prediction for 5010 samples...
0.28460228 No improvement since epoch  697 ; best_mse,best_ci: 0.26544225 0.877861676503917 GCNNet davis
Training on 25046 samples...
Train epoch: 734 [0/25046 (0%)]	Loss: 0.093226
Train epoch: 734 [326500/25046 (41%)]	Loss: 0.099738
Train epoch: 734 [650400/25046 (82%)]	Loss: 0.126103
Make prediction for 5010 samples...
0.269909 No improvement since epoch  697 ; best_mse,best_ci: 0.26544225 0.877861676503917 GCNNet davis
Training on 25046 samples...
Train epoch: 735 [0/25046 (0%)]	Loss: 0.106796
Train epoch: 735 [328100/25046 (41%)]	Loss: 0.120327
Train epoch: 735 [655000/25046 (82%)]	Loss: 0.122790
Make prediction for 5010 samples...
0.28189158 No improvement since epoch  697 ; best_mse,best_ci: 0.26544225 0.877861676503917 GCNNet davis
Training on 25046 samples...
Train epoch: 736 [0/25046 (0%)]	Loss: 0.099454
Train epoch: 736 [332440/25046 (41%)]	Loss: 0.101053
Train epoch: 736 [658240/25046 (82%)]	Loss: 0.107351
Make prediction for 5010 samples...
0.28535345 No improvement since epoch  697 ; best_mse,best_ci: 0.26544225 0.877861676503917 GCNNet davis
Training on 25046 samples...
Train epoch: 737 [0/25046 (0%)]	Loss: 0.109508
Train epoch: 737 [330200/25046 (41%)]	Loss: 0.069712
Train epoch: 737 [662200/25046 (82%)]	Loss: 0.113451
Make prediction for 5010 samples...
0.27485675 No improvement since epoch  697 ; best_mse,best_ci: 0.26544225 0.877861676503917 GCNNet davis
Training on 25046 samples...
Train epoch: 738 [0/25046 (0%)]	Loss: 0.119963
Train epoch: 738 [330020/25046 (41%)]	Loss: 0.099585
Train epoch: 738 [651920/25046 (82%)]	Loss: 0.124015
Make prediction for 5010 samples...
0.27614498 No improvement since epoch  697 ; best_mse,best_ci: 0.26544225 0.877861676503917 GCNNet davis
Training on 25046 samples...
Train epoch: 739 [0/25046 (0%)]	Loss: 0.097285
Train epoch: 739 [327320/25046 (41%)]	Loss: 0.127429
Train epoch: 739 [650400/25046 (82%)]	Loss: 0.152799
Make prediction for 5010 samples...
0.2924468 No improvement since epoch  697 ; best_mse,best_ci: 0.26544225 0.877861676503917 GCNNet davis
Training on 25046 samples...
Train epoch: 740 [0/25046 (0%)]	Loss: 0.126622
Train epoch: 740 [335100/25046 (41%)]	Loss: 0.108239
Train epoch: 740 [657160/25046 (82%)]	Loss: 0.098930
Make prediction for 5010 samples...
0.29927918 No improvement since epoch  697 ; best_mse,best_ci: 0.26544225 0.877861676503917 GCNNet davis
Training on 25046 samples...
Train epoch: 741 [0/25046 (0%)]	Loss: 0.102025
Train epoch: 741 [328320/25046 (41%)]	Loss: 0.140313
Train epoch: 741 [660800/25046 (82%)]	Loss: 0.108933
Make prediction for 5010 samples...
0.31435958 No improvement since epoch  697 ; best_mse,best_ci: 0.26544225 0.877861676503917 GCNNet davis
Training on 25046 samples...
Train epoch: 742 [0/25046 (0%)]	Loss: 0.142027
Train epoch: 742 [332600/25046 (41%)]	Loss: 0.117658
Train epoch: 742 [647720/25046 (82%)]	Loss: 0.107226
Make prediction for 5010 samples...
0.27666444 No improvement since epoch  697 ; best_mse,best_ci: 0.26544225 0.877861676503917 GCNNet davis
Training on 25046 samples...
Train epoch: 743 [0/25046 (0%)]	Loss: 0.084928
Train epoch: 743 [327280/25046 (41%)]	Loss: 0.088808
Train epoch: 743 [660080/25046 (82%)]	Loss: 0.111208
Make prediction for 5010 samples...
0.29718348 No improvement since epoch  697 ; best_mse,best_ci: 0.26544225 0.877861676503917 GCNNet davis
Training on 25046 samples...
Train epoch: 744 [0/25046 (0%)]	Loss: 0.104424
Train epoch: 744 [331720/25046 (41%)]	Loss: 0.095533
Train epoch: 744 [663920/25046 (82%)]	Loss: 0.116583
Make prediction for 5010 samples...
0.3084474 No improvement since epoch  697 ; best_mse,best_ci: 0.26544225 0.877861676503917 GCNNet davis
Training on 25046 samples...
Train epoch: 745 [0/25046 (0%)]	Loss: 0.110216
Train epoch: 745 [329160/25046 (41%)]	Loss: 0.110002
Train epoch: 745 [655640/25046 (82%)]	Loss: 0.092357
Make prediction for 5010 samples...
0.3048514 No improvement since epoch  697 ; best_mse,best_ci: 0.26544225 0.877861676503917 GCNNet davis
Training on 25046 samples...
Train epoch: 746 [0/25046 (0%)]	Loss: 0.105117
Train epoch: 746 [327900/25046 (41%)]	Loss: 0.112485
Train epoch: 746 [640360/25046 (82%)]	Loss: 0.126456
Make prediction for 5010 samples...
0.29587168 No improvement since epoch  697 ; best_mse,best_ci: 0.26544225 0.877861676503917 GCNNet davis
Training on 25046 samples...
Train epoch: 747 [0/25046 (0%)]	Loss: 0.093576
Train epoch: 747 [327980/25046 (41%)]	Loss: 0.137235
Train epoch: 747 [668480/25046 (82%)]	Loss: 0.108793
Make prediction for 5010 samples...
0.28589052 No improvement since epoch  697 ; best_mse,best_ci: 0.26544225 0.877861676503917 GCNNet davis
Training on 25046 samples...
Train epoch: 748 [0/25046 (0%)]	Loss: 0.091615
Train epoch: 748 [329300/25046 (41%)]	Loss: 0.090542
Train epoch: 748 [649880/25046 (82%)]	Loss: 0.109832
Make prediction for 5010 samples...
0.2676808 No improvement since epoch  697 ; best_mse,best_ci: 0.26544225 0.877861676503917 GCNNet davis
Training on 25046 samples...
Train epoch: 749 [0/25046 (0%)]	Loss: 0.111545
Train epoch: 749 [332020/25046 (41%)]	Loss: 0.084414
Train epoch: 749 [663520/25046 (82%)]	Loss: 0.105968
Make prediction for 5010 samples...
0.2815196 No improvement since epoch  697 ; best_mse,best_ci: 0.26544225 0.877861676503917 GCNNet davis
Training on 25046 samples...
Train epoch: 750 [0/25046 (0%)]	Loss: 0.093730
Train epoch: 750 [326440/25046 (41%)]	Loss: 0.106583
Train epoch: 750 [657600/25046 (82%)]	Loss: 0.165856
Make prediction for 5010 samples...
0.27802858 No improvement since epoch  697 ; best_mse,best_ci: 0.26544225 0.877861676503917 GCNNet davis
Training on 25046 samples...
Train epoch: 751 [0/25046 (0%)]	Loss: 0.139351
Train epoch: 751 [329860/25046 (41%)]	Loss: 0.095511
Train epoch: 751 [661240/25046 (82%)]	Loss: 0.114245
Make prediction for 5010 samples...
0.27502817 No improvement since epoch  697 ; best_mse,best_ci: 0.26544225 0.877861676503917 GCNNet davis
Training on 25046 samples...
Train epoch: 752 [0/25046 (0%)]	Loss: 0.130292
Train epoch: 752 [327020/25046 (41%)]	Loss: 0.108638
Train epoch: 752 [662800/25046 (82%)]	Loss: 0.141227
Make prediction for 5010 samples...
0.2851851 No improvement since epoch  697 ; best_mse,best_ci: 0.26544225 0.877861676503917 GCNNet davis
Training on 25046 samples...
Train epoch: 753 [0/25046 (0%)]	Loss: 0.101255
Train epoch: 753 [324880/25046 (41%)]	Loss: 0.091497
Train epoch: 753 [653480/25046 (82%)]	Loss: 0.096460
Make prediction for 5010 samples...
rmse improved at epoch  753 ; best_mse,best_ci: 0.26487908 0.8706036190278696 GCNNet davis
Training on 25046 samples...
Train epoch: 754 [0/25046 (0%)]	Loss: 0.106751
Train epoch: 754 [327960/25046 (41%)]	Loss: 0.130934
Train epoch: 754 [649840/25046 (82%)]	Loss: 0.137691
Make prediction for 5010 samples...
0.27790582 No improvement since epoch  753 ; best_mse,best_ci: 0.26487908 0.8706036190278696 GCNNet davis
Training on 25046 samples...
Train epoch: 755 [0/25046 (0%)]	Loss: 0.068181
Train epoch: 755 [329160/25046 (41%)]	Loss: 0.110909
Train epoch: 755 [645360/25046 (82%)]	Loss: 0.110363
Make prediction for 5010 samples...
0.27784532 No improvement since epoch  753 ; best_mse,best_ci: 0.26487908 0.8706036190278696 GCNNet davis
Training on 25046 samples...
Train epoch: 756 [0/25046 (0%)]	Loss: 0.066135
Train epoch: 756 [329140/25046 (41%)]	Loss: 0.115771
Train epoch: 756 [653880/25046 (82%)]	Loss: 0.085955
Make prediction for 5010 samples...
0.29359373 No improvement since epoch  753 ; best_mse,best_ci: 0.26487908 0.8706036190278696 GCNNet davis
Training on 25046 samples...
Train epoch: 757 [0/25046 (0%)]	Loss: 0.085372
Train epoch: 757 [324060/25046 (41%)]	Loss: 0.156996
Train epoch: 757 [665240/25046 (82%)]	Loss: 0.118447
Make prediction for 5010 samples...
0.29449603 No improvement since epoch  753 ; best_mse,best_ci: 0.26487908 0.8706036190278696 GCNNet davis
Training on 25046 samples...
Train epoch: 758 [0/25046 (0%)]	Loss: 0.095626
Train epoch: 758 [326260/25046 (41%)]	Loss: 0.095008
Train epoch: 758 [654800/25046 (82%)]	Loss: 0.087718
Make prediction for 5010 samples...
0.26534656 No improvement since epoch  753 ; best_mse,best_ci: 0.26487908 0.8706036190278696 GCNNet davis
Training on 25046 samples...
Train epoch: 759 [0/25046 (0%)]	Loss: 0.104272
Train epoch: 759 [327260/25046 (41%)]	Loss: 0.113283
Train epoch: 759 [663880/25046 (82%)]	Loss: 0.136261
Make prediction for 5010 samples...
0.294422 No improvement since epoch  753 ; best_mse,best_ci: 0.26487908 0.8706036190278696 GCNNet davis
Training on 25046 samples...
Train epoch: 760 [0/25046 (0%)]	Loss: 0.120838
Train epoch: 760 [329960/25046 (41%)]	Loss: 0.114821
Train epoch: 760 [661560/25046 (82%)]	Loss: 0.132399
Make prediction for 5010 samples...
0.27713138 No improvement since epoch  753 ; best_mse,best_ci: 0.26487908 0.8706036190278696 GCNNet davis
Training on 25046 samples...
Train epoch: 761 [0/25046 (0%)]	Loss: 0.085122
Train epoch: 761 [327540/25046 (41%)]	Loss: 0.102257
Train epoch: 761 [661360/25046 (82%)]	Loss: 0.135833
Make prediction for 5010 samples...
0.26941806 No improvement since epoch  753 ; best_mse,best_ci: 0.26487908 0.8706036190278696 GCNNet davis
Training on 25046 samples...
Train epoch: 762 [0/25046 (0%)]	Loss: 0.107093
Train epoch: 762 [326800/25046 (41%)]	Loss: 0.128921
Train epoch: 762 [644400/25046 (82%)]	Loss: 0.085277
Make prediction for 5010 samples...
0.2950733 No improvement since epoch  753 ; best_mse,best_ci: 0.26487908 0.8706036190278696 GCNNet davis
Training on 25046 samples...
Train epoch: 763 [0/25046 (0%)]	Loss: 0.108553
Train epoch: 763 [332560/25046 (41%)]	Loss: 0.129158
Train epoch: 763 [663720/25046 (82%)]	Loss: 0.116294
Make prediction for 5010 samples...
0.29436147 No improvement since epoch  753 ; best_mse,best_ci: 0.26487908 0.8706036190278696 GCNNet davis
Training on 25046 samples...
Train epoch: 764 [0/25046 (0%)]	Loss: 0.096192
Train epoch: 764 [325780/25046 (41%)]	Loss: 0.125338
Train epoch: 764 [661400/25046 (82%)]	Loss: 0.119749
Make prediction for 5010 samples...
0.26760513 No improvement since epoch  753 ; best_mse,best_ci: 0.26487908 0.8706036190278696 GCNNet davis
Training on 25046 samples...
Train epoch: 765 [0/25046 (0%)]	Loss: 0.126844
Train epoch: 765 [330780/25046 (41%)]	Loss: 0.102173
Train epoch: 765 [659760/25046 (82%)]	Loss: 0.115321
Make prediction for 5010 samples...
0.30078787 No improvement since epoch  753 ; best_mse,best_ci: 0.26487908 0.8706036190278696 GCNNet davis
Training on 25046 samples...
Train epoch: 766 [0/25046 (0%)]	Loss: 0.134459
Train epoch: 766 [321740/25046 (41%)]	Loss: 0.087891
Train epoch: 766 [653880/25046 (82%)]	Loss: 0.093640
Make prediction for 5010 samples...
0.2769148 No improvement since epoch  753 ; best_mse,best_ci: 0.26487908 0.8706036190278696 GCNNet davis
Training on 25046 samples...
Train epoch: 767 [0/25046 (0%)]	Loss: 0.117805
Train epoch: 767 [325060/25046 (41%)]	Loss: 0.085009
Train epoch: 767 [658560/25046 (82%)]	Loss: 0.099426
Make prediction for 5010 samples...
0.2730469 No improvement since epoch  753 ; best_mse,best_ci: 0.26487908 0.8706036190278696 GCNNet davis
Training on 25046 samples...
Train epoch: 768 [0/25046 (0%)]	Loss: 0.134026
Train epoch: 768 [329660/25046 (41%)]	Loss: 0.121740
Train epoch: 768 [654880/25046 (82%)]	Loss: 0.097002
Make prediction for 5010 samples...
0.27850306 No improvement since epoch  753 ; best_mse,best_ci: 0.26487908 0.8706036190278696 GCNNet davis
Training on 25046 samples...
Train epoch: 769 [0/25046 (0%)]	Loss: 0.088396
Train epoch: 769 [333800/25046 (41%)]	Loss: 0.109308
Train epoch: 769 [658720/25046 (82%)]	Loss: 0.194986
Make prediction for 5010 samples...
0.27518487 No improvement since epoch  753 ; best_mse,best_ci: 0.26487908 0.8706036190278696 GCNNet davis
Training on 25046 samples...
Train epoch: 770 [0/25046 (0%)]	Loss: 0.116758
Train epoch: 770 [331840/25046 (41%)]	Loss: 0.121493
Train epoch: 770 [658680/25046 (82%)]	Loss: 0.090420
Make prediction for 5010 samples...
0.27854627 No improvement since epoch  753 ; best_mse,best_ci: 0.26487908 0.8706036190278696 GCNNet davis
Training on 25046 samples...
Train epoch: 771 [0/25046 (0%)]	Loss: 0.094806
Train epoch: 771 [324840/25046 (41%)]	Loss: 0.108704
Train epoch: 771 [644000/25046 (82%)]	Loss: 0.113598
Make prediction for 5010 samples...
0.28738633 No improvement since epoch  753 ; best_mse,best_ci: 0.26487908 0.8706036190278696 GCNNet davis
Training on 25046 samples...
Train epoch: 772 [0/25046 (0%)]	Loss: 0.103099
Train epoch: 772 [330360/25046 (41%)]	Loss: 0.090366
Train epoch: 772 [657520/25046 (82%)]	Loss: 0.110586
Make prediction for 5010 samples...
0.2844594 No improvement since epoch  753 ; best_mse,best_ci: 0.26487908 0.8706036190278696 GCNNet davis
Training on 25046 samples...
Train epoch: 773 [0/25046 (0%)]	Loss: 0.078672
Train epoch: 773 [330360/25046 (41%)]	Loss: 0.095243
Train epoch: 773 [645240/25046 (82%)]	Loss: 0.120716
Make prediction for 5010 samples...
rmse improved at epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 774 [0/25046 (0%)]	Loss: 0.122152
Train epoch: 774 [328140/25046 (41%)]	Loss: 0.123929
Train epoch: 774 [649160/25046 (82%)]	Loss: 0.101863
Make prediction for 5010 samples...
0.29034773 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 775 [0/25046 (0%)]	Loss: 0.093111
Train epoch: 775 [326600/25046 (41%)]	Loss: 0.124677
Train epoch: 775 [656120/25046 (82%)]	Loss: 0.090337
Make prediction for 5010 samples...
0.2999425 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 776 [0/25046 (0%)]	Loss: 0.102830
Train epoch: 776 [328540/25046 (41%)]	Loss: 0.090606
Train epoch: 776 [662680/25046 (82%)]	Loss: 0.123474
Make prediction for 5010 samples...
0.2692463 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 777 [0/25046 (0%)]	Loss: 0.125849
Train epoch: 777 [330720/25046 (41%)]	Loss: 0.110249
Train epoch: 777 [659080/25046 (82%)]	Loss: 0.113342
Make prediction for 5010 samples...
0.28331175 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 778 [0/25046 (0%)]	Loss: 0.087880
Train epoch: 778 [330680/25046 (41%)]	Loss: 0.124049
Train epoch: 778 [657920/25046 (82%)]	Loss: 0.106903
Make prediction for 5010 samples...
0.33496514 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 779 [0/25046 (0%)]	Loss: 0.145048
Train epoch: 779 [331160/25046 (41%)]	Loss: 0.100259
Train epoch: 779 [657800/25046 (82%)]	Loss: 0.109090
Make prediction for 5010 samples...
0.28151086 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 780 [0/25046 (0%)]	Loss: 0.081055
Train epoch: 780 [326280/25046 (41%)]	Loss: 0.105547
Train epoch: 780 [662400/25046 (82%)]	Loss: 0.152308
Make prediction for 5010 samples...
0.3005098 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 781 [0/25046 (0%)]	Loss: 0.105483
Train epoch: 781 [330500/25046 (41%)]	Loss: 0.101211
Train epoch: 781 [653320/25046 (82%)]	Loss: 0.103386
Make prediction for 5010 samples...
0.278717 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 782 [0/25046 (0%)]	Loss: 0.069176
Train epoch: 782 [320860/25046 (41%)]	Loss: 0.081601
Train epoch: 782 [650520/25046 (82%)]	Loss: 0.131415
Make prediction for 5010 samples...
0.2942044 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 783 [0/25046 (0%)]	Loss: 0.102820
Train epoch: 783 [328480/25046 (41%)]	Loss: 0.150714
Train epoch: 783 [652960/25046 (82%)]	Loss: 0.156612
Make prediction for 5010 samples...
0.2939697 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 784 [0/25046 (0%)]	Loss: 0.094051
Train epoch: 784 [323360/25046 (41%)]	Loss: 0.107816
Train epoch: 784 [647400/25046 (82%)]	Loss: 0.113898
Make prediction for 5010 samples...
0.26493648 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 785 [0/25046 (0%)]	Loss: 0.110210
Train epoch: 785 [324900/25046 (41%)]	Loss: 0.088032
Train epoch: 785 [653520/25046 (82%)]	Loss: 0.105208
Make prediction for 5010 samples...
0.3078232 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 786 [0/25046 (0%)]	Loss: 0.098324
Train epoch: 786 [325180/25046 (41%)]	Loss: 0.109610
Train epoch: 786 [655920/25046 (82%)]	Loss: 0.121678
Make prediction for 5010 samples...
0.27291253 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 787 [0/25046 (0%)]	Loss: 0.114619
Train epoch: 787 [327520/25046 (41%)]	Loss: 0.137454
Train epoch: 787 [655520/25046 (82%)]	Loss: 0.115798
Make prediction for 5010 samples...
0.27459076 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 788 [0/25046 (0%)]	Loss: 0.114352
Train epoch: 788 [326360/25046 (41%)]	Loss: 0.085601
Train epoch: 788 [650320/25046 (82%)]	Loss: 0.094273
Make prediction for 5010 samples...
0.28297725 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 789 [0/25046 (0%)]	Loss: 0.120813
Train epoch: 789 [331420/25046 (41%)]	Loss: 0.145100
Train epoch: 789 [654000/25046 (82%)]	Loss: 0.100399
Make prediction for 5010 samples...
0.2913863 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 790 [0/25046 (0%)]	Loss: 0.085540
Train epoch: 790 [328800/25046 (41%)]	Loss: 0.087644
Train epoch: 790 [651320/25046 (82%)]	Loss: 0.127620
Make prediction for 5010 samples...
0.30297804 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 791 [0/25046 (0%)]	Loss: 0.089128
Train epoch: 791 [322680/25046 (41%)]	Loss: 0.096847
Train epoch: 791 [667760/25046 (82%)]	Loss: 0.096295
Make prediction for 5010 samples...
0.2666699 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 792 [0/25046 (0%)]	Loss: 0.111797
Train epoch: 792 [329940/25046 (41%)]	Loss: 0.120460
Train epoch: 792 [660440/25046 (82%)]	Loss: 0.102331
Make prediction for 5010 samples...
0.29460314 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 793 [0/25046 (0%)]	Loss: 0.099981
Train epoch: 793 [328940/25046 (41%)]	Loss: 0.108317
Train epoch: 793 [655280/25046 (82%)]	Loss: 0.079246
Make prediction for 5010 samples...
0.2956035 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 794 [0/25046 (0%)]	Loss: 0.101132
Train epoch: 794 [327800/25046 (41%)]	Loss: 0.103005
Train epoch: 794 [649760/25046 (82%)]	Loss: 0.122050
Make prediction for 5010 samples...
0.36729357 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 795 [0/25046 (0%)]	Loss: 0.170445
Train epoch: 795 [323060/25046 (41%)]	Loss: 0.117031
Train epoch: 795 [660280/25046 (82%)]	Loss: 0.105247
Make prediction for 5010 samples...
0.2710726 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 796 [0/25046 (0%)]	Loss: 0.107770
Train epoch: 796 [330620/25046 (41%)]	Loss: 0.097363
Train epoch: 796 [655600/25046 (82%)]	Loss: 0.154472
Make prediction for 5010 samples...
0.27042258 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 797 [0/25046 (0%)]	Loss: 0.125827
Train epoch: 797 [325380/25046 (41%)]	Loss: 0.115874
Train epoch: 797 [657640/25046 (82%)]	Loss: 0.093863
Make prediction for 5010 samples...
0.2688222 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 798 [0/25046 (0%)]	Loss: 0.082715
Train epoch: 798 [322800/25046 (41%)]	Loss: 0.086823
Train epoch: 798 [659800/25046 (82%)]	Loss: 0.120193
Make prediction for 5010 samples...
0.2802787 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 799 [0/25046 (0%)]	Loss: 0.112687
Train epoch: 799 [327120/25046 (41%)]	Loss: 0.094173
Train epoch: 799 [658680/25046 (82%)]	Loss: 0.121269
Make prediction for 5010 samples...
0.26979765 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 800 [0/25046 (0%)]	Loss: 0.095479
Train epoch: 800 [325940/25046 (41%)]	Loss: 0.109708
Train epoch: 800 [650200/25046 (82%)]	Loss: 0.114543
Make prediction for 5010 samples...
0.27107266 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 801 [0/25046 (0%)]	Loss: 0.090519
Train epoch: 801 [327840/25046 (41%)]	Loss: 0.066769
Train epoch: 801 [659320/25046 (82%)]	Loss: 0.096889
Make prediction for 5010 samples...
0.27085707 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 802 [0/25046 (0%)]	Loss: 0.130514
Train epoch: 802 [330440/25046 (41%)]	Loss: 0.096947
Train epoch: 802 [659880/25046 (82%)]	Loss: 0.085828
Make prediction for 5010 samples...
0.27191794 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 803 [0/25046 (0%)]	Loss: 0.097347
Train epoch: 803 [332800/25046 (41%)]	Loss: 0.123740
Train epoch: 803 [658880/25046 (82%)]	Loss: 0.149668
Make prediction for 5010 samples...
0.34169918 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 804 [0/25046 (0%)]	Loss: 0.138989
Train epoch: 804 [330000/25046 (41%)]	Loss: 0.126308
Train epoch: 804 [656000/25046 (82%)]	Loss: 0.139371
Make prediction for 5010 samples...
0.30914527 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 805 [0/25046 (0%)]	Loss: 0.163006
Train epoch: 805 [326760/25046 (41%)]	Loss: 0.143190
Train epoch: 805 [655200/25046 (82%)]	Loss: 0.090065
Make prediction for 5010 samples...
0.28234312 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 806 [0/25046 (0%)]	Loss: 0.101884
Train epoch: 806 [324000/25046 (41%)]	Loss: 0.154595
Train epoch: 806 [659800/25046 (82%)]	Loss: 0.075741
Make prediction for 5010 samples...
0.27301994 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 807 [0/25046 (0%)]	Loss: 0.078770
Train epoch: 807 [326400/25046 (41%)]	Loss: 0.120013
Train epoch: 807 [649600/25046 (82%)]	Loss: 0.109247
Make prediction for 5010 samples...
0.28435192 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 808 [0/25046 (0%)]	Loss: 0.080702
Train epoch: 808 [328420/25046 (41%)]	Loss: 0.103668
Train epoch: 808 [651560/25046 (82%)]	Loss: 0.136535
Make prediction for 5010 samples...
0.32956165 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 809 [0/25046 (0%)]	Loss: 0.140319
Train epoch: 809 [325520/25046 (41%)]	Loss: 0.119051
Train epoch: 809 [651400/25046 (82%)]	Loss: 0.105072
Make prediction for 5010 samples...
0.29717395 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 810 [0/25046 (0%)]	Loss: 0.128866
Train epoch: 810 [324160/25046 (41%)]	Loss: 0.101214
Train epoch: 810 [657760/25046 (82%)]	Loss: 0.078492
Make prediction for 5010 samples...
0.26727107 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 811 [0/25046 (0%)]	Loss: 0.128511
Train epoch: 811 [328100/25046 (41%)]	Loss: 0.125955
Train epoch: 811 [658520/25046 (82%)]	Loss: 0.100231
Make prediction for 5010 samples...
0.2652121 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 812 [0/25046 (0%)]	Loss: 0.101866
Train epoch: 812 [328780/25046 (41%)]	Loss: 0.098394
Train epoch: 812 [651960/25046 (82%)]	Loss: 0.082534
Make prediction for 5010 samples...
0.28287455 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 813 [0/25046 (0%)]	Loss: 0.094606
Train epoch: 813 [328280/25046 (41%)]	Loss: 0.154685
Train epoch: 813 [658600/25046 (82%)]	Loss: 0.107491
Make prediction for 5010 samples...
0.26671582 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 814 [0/25046 (0%)]	Loss: 0.083981
Train epoch: 814 [331400/25046 (41%)]	Loss: 0.086918
Train epoch: 814 [659840/25046 (82%)]	Loss: 0.089330
Make prediction for 5010 samples...
0.28207386 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 815 [0/25046 (0%)]	Loss: 0.086873
Train epoch: 815 [323640/25046 (41%)]	Loss: 0.109699
Train epoch: 815 [657640/25046 (82%)]	Loss: 0.073441
Make prediction for 5010 samples...
0.2723171 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 816 [0/25046 (0%)]	Loss: 0.092198
Train epoch: 816 [331160/25046 (41%)]	Loss: 0.117618
Train epoch: 816 [653080/25046 (82%)]	Loss: 0.103200
Make prediction for 5010 samples...
0.298226 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 817 [0/25046 (0%)]	Loss: 0.088902
Train epoch: 817 [325240/25046 (41%)]	Loss: 0.110844
Train epoch: 817 [644200/25046 (82%)]	Loss: 0.099538
Make prediction for 5010 samples...
0.2729457 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 818 [0/25046 (0%)]	Loss: 0.101992
Train epoch: 818 [327500/25046 (41%)]	Loss: 0.089892
Train epoch: 818 [666000/25046 (82%)]	Loss: 0.076882
Make prediction for 5010 samples...
0.29427388 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 819 [0/25046 (0%)]	Loss: 0.101064
Train epoch: 819 [329720/25046 (41%)]	Loss: 0.105898
Train epoch: 819 [660560/25046 (82%)]	Loss: 0.114646
Make prediction for 5010 samples...
0.27212387 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 820 [0/25046 (0%)]	Loss: 0.116196
Train epoch: 820 [327220/25046 (41%)]	Loss: 0.123783
Train epoch: 820 [660360/25046 (82%)]	Loss: 0.091910
Make prediction for 5010 samples...
0.28337714 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 821 [0/25046 (0%)]	Loss: 0.095139
Train epoch: 821 [328760/25046 (41%)]	Loss: 0.113305
Train epoch: 821 [646800/25046 (82%)]	Loss: 0.084665
Make prediction for 5010 samples...
0.2666186 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 822 [0/25046 (0%)]	Loss: 0.079237
Train epoch: 822 [325840/25046 (41%)]	Loss: 0.106828
Train epoch: 822 [664640/25046 (82%)]	Loss: 0.128250
Make prediction for 5010 samples...
0.27332804 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 823 [0/25046 (0%)]	Loss: 0.081677
Train epoch: 823 [331500/25046 (41%)]	Loss: 0.098925
Train epoch: 823 [643280/25046 (82%)]	Loss: 0.076274
Make prediction for 5010 samples...
0.2692338 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 824 [0/25046 (0%)]	Loss: 0.135419
Train epoch: 824 [325120/25046 (41%)]	Loss: 0.078881
Train epoch: 824 [659680/25046 (82%)]	Loss: 0.082505
Make prediction for 5010 samples...
0.2836064 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 825 [0/25046 (0%)]	Loss: 0.094069
Train epoch: 825 [332660/25046 (41%)]	Loss: 0.111141
Train epoch: 825 [654240/25046 (82%)]	Loss: 0.138977
Make prediction for 5010 samples...
0.27490333 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 826 [0/25046 (0%)]	Loss: 0.098116
Train epoch: 826 [327200/25046 (41%)]	Loss: 0.082955
Train epoch: 826 [656960/25046 (82%)]	Loss: 0.093353
Make prediction for 5010 samples...
0.27836028 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 827 [0/25046 (0%)]	Loss: 0.117208
Train epoch: 827 [331900/25046 (41%)]	Loss: 0.119595
Train epoch: 827 [648120/25046 (82%)]	Loss: 0.103764
Make prediction for 5010 samples...
0.275273 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 828 [0/25046 (0%)]	Loss: 0.088760
Train epoch: 828 [326700/25046 (41%)]	Loss: 0.124783
Train epoch: 828 [654520/25046 (82%)]	Loss: 0.087441
Make prediction for 5010 samples...
0.27402455 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 829 [0/25046 (0%)]	Loss: 0.109916
Train epoch: 829 [327380/25046 (41%)]	Loss: 0.083717
Train epoch: 829 [657160/25046 (82%)]	Loss: 0.092335
Make prediction for 5010 samples...
0.26803634 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 830 [0/25046 (0%)]	Loss: 0.092917
Train epoch: 830 [334640/25046 (41%)]	Loss: 0.112108
Train epoch: 830 [663720/25046 (82%)]	Loss: 0.112854
Make prediction for 5010 samples...
0.26847818 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 831 [0/25046 (0%)]	Loss: 0.078646
Train epoch: 831 [324280/25046 (41%)]	Loss: 0.131123
Train epoch: 831 [655280/25046 (82%)]	Loss: 0.106216
Make prediction for 5010 samples...
0.2665589 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 832 [0/25046 (0%)]	Loss: 0.095821
Train epoch: 832 [331140/25046 (41%)]	Loss: 0.080859
Train epoch: 832 [660280/25046 (82%)]	Loss: 0.107505
Make prediction for 5010 samples...
0.2843046 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 833 [0/25046 (0%)]	Loss: 0.094050
Train epoch: 833 [330000/25046 (41%)]	Loss: 0.086923
Train epoch: 833 [652760/25046 (82%)]	Loss: 0.094698
Make prediction for 5010 samples...
0.2788483 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 834 [0/25046 (0%)]	Loss: 0.085602
Train epoch: 834 [329000/25046 (41%)]	Loss: 0.125497
Train epoch: 834 [665440/25046 (82%)]	Loss: 0.145119
Make prediction for 5010 samples...
0.2960731 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 835 [0/25046 (0%)]	Loss: 0.152078
Train epoch: 835 [330720/25046 (41%)]	Loss: 0.141192
Train epoch: 835 [667640/25046 (82%)]	Loss: 0.127114
Make prediction for 5010 samples...
0.28355098 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 836 [0/25046 (0%)]	Loss: 0.071167
Train epoch: 836 [331580/25046 (41%)]	Loss: 0.104748
Train epoch: 836 [656800/25046 (82%)]	Loss: 0.166578
Make prediction for 5010 samples...
0.29448232 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 837 [0/25046 (0%)]	Loss: 0.099413
Train epoch: 837 [326800/25046 (41%)]	Loss: 0.089513
Train epoch: 837 [658680/25046 (82%)]	Loss: 0.087627
Make prediction for 5010 samples...
0.26397339 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 838 [0/25046 (0%)]	Loss: 0.066385
Train epoch: 838 [329280/25046 (41%)]	Loss: 0.078465
Train epoch: 838 [659360/25046 (82%)]	Loss: 0.102557
Make prediction for 5010 samples...
0.3007594 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 839 [0/25046 (0%)]	Loss: 0.091745
Train epoch: 839 [323020/25046 (41%)]	Loss: 0.109553
Train epoch: 839 [657000/25046 (82%)]	Loss: 0.088118
Make prediction for 5010 samples...
0.29407477 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 840 [0/25046 (0%)]	Loss: 0.091052
Train epoch: 840 [331840/25046 (41%)]	Loss: 0.137635
Train epoch: 840 [660000/25046 (82%)]	Loss: 0.118791
Make prediction for 5010 samples...
0.27829847 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 841 [0/25046 (0%)]	Loss: 0.095254
Train epoch: 841 [329200/25046 (41%)]	Loss: 0.132173
Train epoch: 841 [668960/25046 (82%)]	Loss: 0.127335
Make prediction for 5010 samples...
0.2649752 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 842 [0/25046 (0%)]	Loss: 0.105771
Train epoch: 842 [329160/25046 (41%)]	Loss: 0.107366
Train epoch: 842 [657400/25046 (82%)]	Loss: 0.066227
Make prediction for 5010 samples...
0.27139407 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 843 [0/25046 (0%)]	Loss: 0.111957
Train epoch: 843 [329360/25046 (41%)]	Loss: 0.084128
Train epoch: 843 [655200/25046 (82%)]	Loss: 0.137703
Make prediction for 5010 samples...
0.28708595 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 844 [0/25046 (0%)]	Loss: 0.119494
Train epoch: 844 [326960/25046 (41%)]	Loss: 0.105635
Train epoch: 844 [661120/25046 (82%)]	Loss: 0.091287
Make prediction for 5010 samples...
0.26591384 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 845 [0/25046 (0%)]	Loss: 0.070921
Train epoch: 845 [332060/25046 (41%)]	Loss: 0.105175
Train epoch: 845 [647920/25046 (82%)]	Loss: 0.154698
Make prediction for 5010 samples...
0.26558658 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 846 [0/25046 (0%)]	Loss: 0.068873
Train epoch: 846 [325200/25046 (41%)]	Loss: 0.087963
Train epoch: 846 [653320/25046 (82%)]	Loss: 0.085132
Make prediction for 5010 samples...
0.2650249 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 847 [0/25046 (0%)]	Loss: 0.097911
Train epoch: 847 [326340/25046 (41%)]	Loss: 0.107565
Train epoch: 847 [648200/25046 (82%)]	Loss: 0.141875
Make prediction for 5010 samples...
0.38311175 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 848 [0/25046 (0%)]	Loss: 0.148268
Train epoch: 848 [327560/25046 (41%)]	Loss: 0.090168
Train epoch: 848 [664920/25046 (82%)]	Loss: 0.099900
Make prediction for 5010 samples...
0.27089664 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 849 [0/25046 (0%)]	Loss: 0.086962
Train epoch: 849 [328780/25046 (41%)]	Loss: 0.092983
Train epoch: 849 [659720/25046 (82%)]	Loss: 0.103693
Make prediction for 5010 samples...
0.2721796 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 850 [0/25046 (0%)]	Loss: 0.108843
Train epoch: 850 [327040/25046 (41%)]	Loss: 0.096004
Train epoch: 850 [653760/25046 (82%)]	Loss: 0.108474
Make prediction for 5010 samples...
0.28028995 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 851 [0/25046 (0%)]	Loss: 0.168668
Train epoch: 851 [330080/25046 (41%)]	Loss: 0.099394
Train epoch: 851 [662360/25046 (82%)]	Loss: 0.108306
Make prediction for 5010 samples...
0.27469403 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 852 [0/25046 (0%)]	Loss: 0.123675
Train epoch: 852 [329400/25046 (41%)]	Loss: 0.104165
Train epoch: 852 [652400/25046 (82%)]	Loss: 0.103666
Make prediction for 5010 samples...
0.2774188 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 853 [0/25046 (0%)]	Loss: 0.082939
Train epoch: 853 [328720/25046 (41%)]	Loss: 0.098882
Train epoch: 853 [654840/25046 (82%)]	Loss: 0.130206
Make prediction for 5010 samples...
0.2851915 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 854 [0/25046 (0%)]	Loss: 0.091611
Train epoch: 854 [329400/25046 (41%)]	Loss: 0.115254
Train epoch: 854 [661320/25046 (82%)]	Loss: 0.082087
Make prediction for 5010 samples...
0.26734293 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 855 [0/25046 (0%)]	Loss: 0.132044
Train epoch: 855 [324280/25046 (41%)]	Loss: 0.091498
Train epoch: 855 [655600/25046 (82%)]	Loss: 0.107065
Make prediction for 5010 samples...
0.2815613 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 856 [0/25046 (0%)]	Loss: 0.082513
Train epoch: 856 [327640/25046 (41%)]	Loss: 0.102965
Train epoch: 856 [660880/25046 (82%)]	Loss: 0.093759
Make prediction for 5010 samples...
0.2749248 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 857 [0/25046 (0%)]	Loss: 0.094733
Train epoch: 857 [323580/25046 (41%)]	Loss: 0.102444
Train epoch: 857 [653240/25046 (82%)]	Loss: 0.111915
Make prediction for 5010 samples...
0.2649297 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 858 [0/25046 (0%)]	Loss: 0.113211
Train epoch: 858 [328120/25046 (41%)]	Loss: 0.087827
Train epoch: 858 [650920/25046 (82%)]	Loss: 0.080570
Make prediction for 5010 samples...
0.27869743 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 859 [0/25046 (0%)]	Loss: 0.092922
Train epoch: 859 [327620/25046 (41%)]	Loss: 0.100576
Train epoch: 859 [665040/25046 (82%)]	Loss: 0.123775
Make prediction for 5010 samples...
0.26758152 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 860 [0/25046 (0%)]	Loss: 0.139717
Train epoch: 860 [334960/25046 (41%)]	Loss: 0.101835
Train epoch: 860 [659800/25046 (82%)]	Loss: 0.111529
Make prediction for 5010 samples...
0.27090588 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 861 [0/25046 (0%)]	Loss: 0.084305
Train epoch: 861 [333120/25046 (41%)]	Loss: 0.079528
Train epoch: 861 [654080/25046 (82%)]	Loss: 0.076382
Make prediction for 5010 samples...
0.2622589 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 862 [0/25046 (0%)]	Loss: 0.072449
Train epoch: 862 [328060/25046 (41%)]	Loss: 0.093677
Train epoch: 862 [656080/25046 (82%)]	Loss: 0.068719
Make prediction for 5010 samples...
0.27076966 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 863 [0/25046 (0%)]	Loss: 0.097790
Train epoch: 863 [329160/25046 (41%)]	Loss: 0.091211
Train epoch: 863 [650600/25046 (82%)]	Loss: 0.087775
Make prediction for 5010 samples...
0.27746865 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 864 [0/25046 (0%)]	Loss: 0.104388
Train epoch: 864 [331620/25046 (41%)]	Loss: 0.126238
Train epoch: 864 [656480/25046 (82%)]	Loss: 0.084288
Make prediction for 5010 samples...
0.26185948 No improvement since epoch  773 ; best_mse,best_ci: 0.2617976 0.8758668631717332 GCNNet davis
Training on 25046 samples...
Train epoch: 865 [0/25046 (0%)]	Loss: 0.066585
Train epoch: 865 [327880/25046 (41%)]	Loss: 0.084985
Train epoch: 865 [653760/25046 (82%)]	Loss: 0.121358
Make prediction for 5010 samples...
rmse improved at epoch  865 ; best_mse,best_ci: 0.2590503 0.8706174027668252 GCNNet davis
Training on 25046 samples...
Train epoch: 866 [0/25046 (0%)]	Loss: 0.101131
Train epoch: 866 [329100/25046 (41%)]	Loss: 0.084646
Train epoch: 866 [664000/25046 (82%)]	Loss: 0.117503
Make prediction for 5010 samples...
0.2732245 No improvement since epoch  865 ; best_mse,best_ci: 0.2590503 0.8706174027668252 GCNNet davis
Training on 25046 samples...
Train epoch: 867 [0/25046 (0%)]	Loss: 0.090196
Train epoch: 867 [323020/25046 (41%)]	Loss: 0.098748
Train epoch: 867 [655920/25046 (82%)]	Loss: 0.116680
Make prediction for 5010 samples...
0.28443244 No improvement since epoch  865 ; best_mse,best_ci: 0.2590503 0.8706174027668252 GCNNet davis
Training on 25046 samples...
Train epoch: 868 [0/25046 (0%)]	Loss: 0.070095
Train epoch: 868 [332140/25046 (41%)]	Loss: 0.086771
Train epoch: 868 [647960/25046 (82%)]	Loss: 0.081634
Make prediction for 5010 samples...
0.25941047 No improvement since epoch  865 ; best_mse,best_ci: 0.2590503 0.8706174027668252 GCNNet davis
Training on 25046 samples...
Train epoch: 869 [0/25046 (0%)]	Loss: 0.073690
Train epoch: 869 [330460/25046 (41%)]	Loss: 0.087948
Train epoch: 869 [661640/25046 (82%)]	Loss: 0.104941
Make prediction for 5010 samples...
0.26672798 No improvement since epoch  865 ; best_mse,best_ci: 0.2590503 0.8706174027668252 GCNNet davis
Training on 25046 samples...
Train epoch: 870 [0/25046 (0%)]	Loss: 0.113630
Train epoch: 870 [331540/25046 (41%)]	Loss: 0.086609
Train epoch: 870 [665960/25046 (82%)]	Loss: 0.093687
Make prediction for 5010 samples...
0.28570598 No improvement since epoch  865 ; best_mse,best_ci: 0.2590503 0.8706174027668252 GCNNet davis
Training on 25046 samples...
Train epoch: 871 [0/25046 (0%)]	Loss: 0.068757
Train epoch: 871 [329620/25046 (41%)]	Loss: 0.108015
Train epoch: 871 [649800/25046 (82%)]	Loss: 0.117851
Make prediction for 5010 samples...
0.27289474 No improvement since epoch  865 ; best_mse,best_ci: 0.2590503 0.8706174027668252 GCNNet davis
Training on 25046 samples...
Train epoch: 872 [0/25046 (0%)]	Loss: 0.084371
Train epoch: 872 [325480/25046 (41%)]	Loss: 0.104984
Train epoch: 872 [659920/25046 (82%)]	Loss: 0.098332
Make prediction for 5010 samples...
0.26505893 No improvement since epoch  865 ; best_mse,best_ci: 0.2590503 0.8706174027668252 GCNNet davis
Training on 25046 samples...
Train epoch: 873 [0/25046 (0%)]	Loss: 0.108905
Train epoch: 873 [328200/25046 (41%)]	Loss: 0.083716
Train epoch: 873 [644240/25046 (82%)]	Loss: 0.110387
Make prediction for 5010 samples...
0.26112875 No improvement since epoch  865 ; best_mse,best_ci: 0.2590503 0.8706174027668252 GCNNet davis
Training on 25046 samples...
Train epoch: 874 [0/25046 (0%)]	Loss: 0.112791
Train epoch: 874 [329780/25046 (41%)]	Loss: 0.078861
Train epoch: 874 [661160/25046 (82%)]	Loss: 0.121016
Make prediction for 5010 samples...
0.2632248 No improvement since epoch  865 ; best_mse,best_ci: 0.2590503 0.8706174027668252 GCNNet davis
Training on 25046 samples...
Train epoch: 875 [0/25046 (0%)]	Loss: 0.118103
Train epoch: 875 [322480/25046 (41%)]	Loss: 0.102418
Train epoch: 875 [669200/25046 (82%)]	Loss: 0.111041
Make prediction for 5010 samples...
0.29550397 No improvement since epoch  865 ; best_mse,best_ci: 0.2590503 0.8706174027668252 GCNNet davis
Training on 25046 samples...
Train epoch: 876 [0/25046 (0%)]	Loss: 0.139288
Train epoch: 876 [330800/25046 (41%)]	Loss: 0.090743
Train epoch: 876 [649280/25046 (82%)]	Loss: 0.081990
Make prediction for 5010 samples...
0.27872893 No improvement since epoch  865 ; best_mse,best_ci: 0.2590503 0.8706174027668252 GCNNet davis
Training on 25046 samples...
Train epoch: 877 [0/25046 (0%)]	Loss: 0.087023
Train epoch: 877 [327500/25046 (41%)]	Loss: 0.088465
Train epoch: 877 [664040/25046 (82%)]	Loss: 0.112030
Make prediction for 5010 samples...
0.29256222 No improvement since epoch  865 ; best_mse,best_ci: 0.2590503 0.8706174027668252 GCNNet davis
Training on 25046 samples...
Train epoch: 878 [0/25046 (0%)]	Loss: 0.097916
Train epoch: 878 [325020/25046 (41%)]	Loss: 0.131745
Train epoch: 878 [645400/25046 (82%)]	Loss: 0.111219
Make prediction for 5010 samples...
0.29776707 No improvement since epoch  865 ; best_mse,best_ci: 0.2590503 0.8706174027668252 GCNNet davis
Training on 25046 samples...
Train epoch: 879 [0/25046 (0%)]	Loss: 0.081374
Train epoch: 879 [330880/25046 (41%)]	Loss: 0.102587
Train epoch: 879 [650560/25046 (82%)]	Loss: 0.104791
Make prediction for 5010 samples...
0.2818064 No improvement since epoch  865 ; best_mse,best_ci: 0.2590503 0.8706174027668252 GCNNet davis
Training on 25046 samples...
Train epoch: 880 [0/25046 (0%)]	Loss: 0.109983
Train epoch: 880 [331620/25046 (41%)]	Loss: 0.093208
Train epoch: 880 [655960/25046 (82%)]	Loss: 0.076975
Make prediction for 5010 samples...
0.2664398 No improvement since epoch  865 ; best_mse,best_ci: 0.2590503 0.8706174027668252 GCNNet davis
Training on 25046 samples...
Train epoch: 881 [0/25046 (0%)]	Loss: 0.097371
Train epoch: 881 [327100/25046 (41%)]	Loss: 0.117585
Train epoch: 881 [655200/25046 (82%)]	Loss: 0.092661
Make prediction for 5010 samples...
0.26176128 No improvement since epoch  865 ; best_mse,best_ci: 0.2590503 0.8706174027668252 GCNNet davis
Training on 25046 samples...
Train epoch: 882 [0/25046 (0%)]	Loss: 0.090074
Train epoch: 882 [325580/25046 (41%)]	Loss: 0.095205
Train epoch: 882 [653440/25046 (82%)]	Loss: 0.092991
Make prediction for 5010 samples...
0.26859662 No improvement since epoch  865 ; best_mse,best_ci: 0.2590503 0.8706174027668252 GCNNet davis
Training on 25046 samples...
Train epoch: 883 [0/25046 (0%)]	Loss: 0.082352
Train epoch: 883 [325100/25046 (41%)]	Loss: 0.089004
Train epoch: 883 [656800/25046 (82%)]	Loss: 0.094916
Make prediction for 5010 samples...
0.26602995 No improvement since epoch  865 ; best_mse,best_ci: 0.2590503 0.8706174027668252 GCNNet davis
Training on 25046 samples...
Train epoch: 884 [0/25046 (0%)]	Loss: 0.072135
Train epoch: 884 [324500/25046 (41%)]	Loss: 0.129200
Train epoch: 884 [659280/25046 (82%)]	Loss: 0.132165
Make prediction for 5010 samples...
0.28280497 No improvement since epoch  865 ; best_mse,best_ci: 0.2590503 0.8706174027668252 GCNNet davis
Training on 25046 samples...
Train epoch: 885 [0/25046 (0%)]	Loss: 0.063739
Train epoch: 885 [329460/25046 (41%)]	Loss: 0.079834
Train epoch: 885 [653440/25046 (82%)]	Loss: 0.122131
Make prediction for 5010 samples...
0.27184826 No improvement since epoch  865 ; best_mse,best_ci: 0.2590503 0.8706174027668252 GCNNet davis
Training on 25046 samples...
Train epoch: 886 [0/25046 (0%)]	Loss: 0.127428
Train epoch: 886 [326440/25046 (41%)]	Loss: 0.089270
Train epoch: 886 [652720/25046 (82%)]	Loss: 0.076216
Make prediction for 5010 samples...
0.27101874 No improvement since epoch  865 ; best_mse,best_ci: 0.2590503 0.8706174027668252 GCNNet davis
Training on 25046 samples...
Train epoch: 887 [0/25046 (0%)]	Loss: 0.075784
Train epoch: 887 [327300/25046 (41%)]	Loss: 0.080513
Train epoch: 887 [653040/25046 (82%)]	Loss: 0.096272
Make prediction for 5010 samples...
0.28609583 No improvement since epoch  865 ; best_mse,best_ci: 0.2590503 0.8706174027668252 GCNNet davis
Training on 25046 samples...
Train epoch: 888 [0/25046 (0%)]	Loss: 0.080729
Train epoch: 888 [331480/25046 (41%)]	Loss: 0.091509
Train epoch: 888 [658560/25046 (82%)]	Loss: 0.080034
Make prediction for 5010 samples...
0.27056697 No improvement since epoch  865 ; best_mse,best_ci: 0.2590503 0.8706174027668252 GCNNet davis
Training on 25046 samples...
Train epoch: 889 [0/25046 (0%)]	Loss: 0.092189
Train epoch: 889 [329860/25046 (41%)]	Loss: 0.089786
Train epoch: 889 [658920/25046 (82%)]	Loss: 0.094186
Make prediction for 5010 samples...
0.26877442 No improvement since epoch  865 ; best_mse,best_ci: 0.2590503 0.8706174027668252 GCNNet davis
Training on 25046 samples...
Train epoch: 890 [0/25046 (0%)]	Loss: 0.103059
Train epoch: 890 [324200/25046 (41%)]	Loss: 0.084273
Train epoch: 890 [655000/25046 (82%)]	Loss: 0.082644
Make prediction for 5010 samples...
0.27451664 No improvement since epoch  865 ; best_mse,best_ci: 0.2590503 0.8706174027668252 GCNNet davis
Training on 25046 samples...
Train epoch: 891 [0/25046 (0%)]	Loss: 0.107998
Train epoch: 891 [329200/25046 (41%)]	Loss: 0.113552
Train epoch: 891 [650360/25046 (82%)]	Loss: 0.077399
Make prediction for 5010 samples...
0.26574755 No improvement since epoch  865 ; best_mse,best_ci: 0.2590503 0.8706174027668252 GCNNet davis
Training on 25046 samples...
Train epoch: 892 [0/25046 (0%)]	Loss: 0.095021
Train epoch: 892 [330800/25046 (41%)]	Loss: 0.103372
Train epoch: 892 [661280/25046 (82%)]	Loss: 0.092087
Make prediction for 5010 samples...
0.2662393 No improvement since epoch  865 ; best_mse,best_ci: 0.2590503 0.8706174027668252 GCNNet davis
Training on 25046 samples...
Train epoch: 893 [0/25046 (0%)]	Loss: 0.091637
Train epoch: 893 [329020/25046 (41%)]	Loss: 0.074825
Train epoch: 893 [659240/25046 (82%)]	Loss: 0.095253
Make prediction for 5010 samples...
0.30024785 No improvement since epoch  865 ; best_mse,best_ci: 0.2590503 0.8706174027668252 GCNNet davis
Training on 25046 samples...
Train epoch: 894 [0/25046 (0%)]	Loss: 0.130030
Train epoch: 894 [324980/25046 (41%)]	Loss: 0.081080
Train epoch: 894 [656720/25046 (82%)]	Loss: 0.173883
Make prediction for 5010 samples...
0.28001064 No improvement since epoch  865 ; best_mse,best_ci: 0.2590503 0.8706174027668252 GCNNet davis
Training on 25046 samples...
Train epoch: 895 [0/25046 (0%)]	Loss: 0.109186
Train epoch: 895 [328740/25046 (41%)]	Loss: 0.112844
Train epoch: 895 [652560/25046 (82%)]	Loss: 0.088159
Make prediction for 5010 samples...
0.26655936 No improvement since epoch  865 ; best_mse,best_ci: 0.2590503 0.8706174027668252 GCNNet davis
Training on 25046 samples...
Train epoch: 896 [0/25046 (0%)]	Loss: 0.096010
Train epoch: 896 [331280/25046 (41%)]	Loss: 0.107262
Train epoch: 896 [660400/25046 (82%)]	Loss: 0.100540
Make prediction for 5010 samples...
0.2724634 No improvement since epoch  865 ; best_mse,best_ci: 0.2590503 0.8706174027668252 GCNNet davis
Training on 25046 samples...
Train epoch: 897 [0/25046 (0%)]	Loss: 0.106653
Train epoch: 897 [328800/25046 (41%)]	Loss: 0.112218
Train epoch: 897 [644000/25046 (82%)]	Loss: 0.078922
Make prediction for 5010 samples...
0.2789895 No improvement since epoch  865 ; best_mse,best_ci: 0.2590503 0.8706174027668252 GCNNet davis
Training on 25046 samples...
Train epoch: 898 [0/25046 (0%)]	Loss: 0.080042
Train epoch: 898 [328040/25046 (41%)]	Loss: 0.079458
Train epoch: 898 [651600/25046 (82%)]	Loss: 0.111314
Make prediction for 5010 samples...
0.32853636 No improvement since epoch  865 ; best_mse,best_ci: 0.2590503 0.8706174027668252 GCNNet davis
Training on 25046 samples...
Train epoch: 899 [0/25046 (0%)]	Loss: 0.105828
Train epoch: 899 [322300/25046 (41%)]	Loss: 0.109214
Train epoch: 899 [657040/25046 (82%)]	Loss: 0.101240
Make prediction for 5010 samples...
0.2683009 No improvement since epoch  865 ; best_mse,best_ci: 0.2590503 0.8706174027668252 GCNNet davis
Training on 25046 samples...
Train epoch: 900 [0/25046 (0%)]	Loss: 0.094247
Train epoch: 900 [330300/25046 (41%)]	Loss: 0.114981
Train epoch: 900 [656360/25046 (82%)]	Loss: 0.075413
Make prediction for 5010 samples...
0.28863478 No improvement since epoch  865 ; best_mse,best_ci: 0.2590503 0.8706174027668252 GCNNet davis
Training on 25046 samples...
Train epoch: 901 [0/25046 (0%)]	Loss: 0.132457
Train epoch: 901 [329100/25046 (41%)]	Loss: 0.095216
Train epoch: 901 [668760/25046 (82%)]	Loss: 0.110591
Make prediction for 5010 samples...
0.28595117 No improvement since epoch  865 ; best_mse,best_ci: 0.2590503 0.8706174027668252 GCNNet davis
Training on 25046 samples...
Train epoch: 902 [0/25046 (0%)]	Loss: 0.162457
Train epoch: 902 [338280/25046 (41%)]	Loss: 0.116796
Train epoch: 902 [663000/25046 (82%)]	Loss: 0.093139
Make prediction for 5010 samples...
0.26596197 No improvement since epoch  865 ; best_mse,best_ci: 0.2590503 0.8706174027668252 GCNNet davis
Training on 25046 samples...
Train epoch: 903 [0/25046 (0%)]	Loss: 0.076127
Train epoch: 903 [330060/25046 (41%)]	Loss: 0.070149
Train epoch: 903 [659560/25046 (82%)]	Loss: 0.088990
Make prediction for 5010 samples...
0.26249558 No improvement since epoch  865 ; best_mse,best_ci: 0.2590503 0.8706174027668252 GCNNet davis
Training on 25046 samples...
Train epoch: 904 [0/25046 (0%)]	Loss: 0.084376
Train epoch: 904 [331320/25046 (41%)]	Loss: 0.088046
Train epoch: 904 [663320/25046 (82%)]	Loss: 0.101797
Make prediction for 5010 samples...
0.2675578 No improvement since epoch  865 ; best_mse,best_ci: 0.2590503 0.8706174027668252 GCNNet davis
Training on 25046 samples...
Train epoch: 905 [0/25046 (0%)]	Loss: 0.104179
Train epoch: 905 [330380/25046 (41%)]	Loss: 0.071248
Train epoch: 905 [656400/25046 (82%)]	Loss: 0.096125
Make prediction for 5010 samples...
0.2771099 No improvement since epoch  865 ; best_mse,best_ci: 0.2590503 0.8706174027668252 GCNNet davis
Training on 25046 samples...
Train epoch: 906 [0/25046 (0%)]	Loss: 0.121199
Train epoch: 906 [328380/25046 (41%)]	Loss: 0.107179
Train epoch: 906 [663520/25046 (82%)]	Loss: 0.094782
Make prediction for 5010 samples...
0.2722926 No improvement since epoch  865 ; best_mse,best_ci: 0.2590503 0.8706174027668252 GCNNet davis
Training on 25046 samples...
Train epoch: 907 [0/25046 (0%)]	Loss: 0.080464
Train epoch: 907 [328620/25046 (41%)]	Loss: 0.082349
Train epoch: 907 [658720/25046 (82%)]	Loss: 0.108319
Make prediction for 5010 samples...
0.26746747 No improvement since epoch  865 ; best_mse,best_ci: 0.2590503 0.8706174027668252 GCNNet davis
Training on 25046 samples...
Train epoch: 908 [0/25046 (0%)]	Loss: 0.147585
Train epoch: 908 [326060/25046 (41%)]	Loss: 0.090891
Train epoch: 908 [646560/25046 (82%)]	Loss: 0.084839
Make prediction for 5010 samples...
0.27477 No improvement since epoch  865 ; best_mse,best_ci: 0.2590503 0.8706174027668252 GCNNet davis
Training on 25046 samples...
Train epoch: 909 [0/25046 (0%)]	Loss: 0.094307
Train epoch: 909 [330300/25046 (41%)]	Loss: 0.103911
Train epoch: 909 [656720/25046 (82%)]	Loss: 0.097814
Make prediction for 5010 samples...
0.31744698 No improvement since epoch  865 ; best_mse,best_ci: 0.2590503 0.8706174027668252 GCNNet davis
Training on 25046 samples...
Train epoch: 910 [0/25046 (0%)]	Loss: 0.100603
Train epoch: 910 [327360/25046 (41%)]	Loss: 0.092927
Train epoch: 910 [658400/25046 (82%)]	Loss: 0.086571
Make prediction for 5010 samples...
0.2750269 No improvement since epoch  865 ; best_mse,best_ci: 0.2590503 0.8706174027668252 GCNNet davis
Training on 25046 samples...
Train epoch: 911 [0/25046 (0%)]	Loss: 0.088913
Train epoch: 911 [327440/25046 (41%)]	Loss: 0.092249
Train epoch: 911 [652800/25046 (82%)]	Loss: 0.106047
Make prediction for 5010 samples...
0.2646317 No improvement since epoch  865 ; best_mse,best_ci: 0.2590503 0.8706174027668252 GCNNet davis
Training on 25046 samples...
Train epoch: 912 [0/25046 (0%)]	Loss: 0.109906
Train epoch: 912 [328080/25046 (41%)]	Loss: 0.080707
Train epoch: 912 [651680/25046 (82%)]	Loss: 0.086680
Make prediction for 5010 samples...
0.26365337 No improvement since epoch  865 ; best_mse,best_ci: 0.2590503 0.8706174027668252 GCNNet davis
Training on 25046 samples...
Train epoch: 913 [0/25046 (0%)]	Loss: 0.144907
Train epoch: 913 [328360/25046 (41%)]	Loss: 0.090520
Train epoch: 913 [660760/25046 (82%)]	Loss: 0.100124
Make prediction for 5010 samples...
0.27860978 No improvement since epoch  865 ; best_mse,best_ci: 0.2590503 0.8706174027668252 GCNNet davis
Training on 25046 samples...
Train epoch: 914 [0/25046 (0%)]	Loss: 0.100603
Train epoch: 914 [333600/25046 (41%)]	Loss: 0.088336
Train epoch: 914 [646800/25046 (82%)]	Loss: 0.090641
Make prediction for 5010 samples...
0.3035989 No improvement since epoch  865 ; best_mse,best_ci: 0.2590503 0.8706174027668252 GCNNet davis
Training on 25046 samples...
Train epoch: 915 [0/25046 (0%)]	Loss: 0.112891
Train epoch: 915 [325540/25046 (41%)]	Loss: 0.091240
Train epoch: 915 [654320/25046 (82%)]	Loss: 0.082788
Make prediction for 5010 samples...
0.27347073 No improvement since epoch  865 ; best_mse,best_ci: 0.2590503 0.8706174027668252 GCNNet davis
Training on 25046 samples...
Train epoch: 916 [0/25046 (0%)]	Loss: 0.100815
Train epoch: 916 [328440/25046 (41%)]	Loss: 0.119261
Train epoch: 916 [660480/25046 (82%)]	Loss: 0.116967
Make prediction for 5010 samples...
0.26874834 No improvement since epoch  865 ; best_mse,best_ci: 0.2590503 0.8706174027668252 GCNNet davis
Training on 25046 samples...
Train epoch: 917 [0/25046 (0%)]	Loss: 0.099545
Train epoch: 917 [328100/25046 (41%)]	Loss: 0.072253
Train epoch: 917 [656560/25046 (82%)]	Loss: 0.096727
Make prediction for 5010 samples...
0.2963855 No improvement since epoch  865 ; best_mse,best_ci: 0.2590503 0.8706174027668252 GCNNet davis
Training on 25046 samples...
Train epoch: 918 [0/25046 (0%)]	Loss: 0.106455
Train epoch: 918 [324620/25046 (41%)]	Loss: 0.079636
Train epoch: 918 [665880/25046 (82%)]	Loss: 0.085217
Make prediction for 5010 samples...
0.26309872 No improvement since epoch  865 ; best_mse,best_ci: 0.2590503 0.8706174027668252 GCNNet davis
Training on 25046 samples...
Train epoch: 919 [0/25046 (0%)]	Loss: 0.098020
Train epoch: 919 [330760/25046 (41%)]	Loss: 0.085520
Train epoch: 919 [655160/25046 (82%)]	Loss: 0.128871
Make prediction for 5010 samples...
0.30106458 No improvement since epoch  865 ; best_mse,best_ci: 0.2590503 0.8706174027668252 GCNNet davis
Training on 25046 samples...
Train epoch: 920 [0/25046 (0%)]	Loss: 0.076021
Train epoch: 920 [331500/25046 (41%)]	Loss: 0.086142
Train epoch: 920 [651760/25046 (82%)]	Loss: 0.117546
Make prediction for 5010 samples...
0.27506378 No improvement since epoch  865 ; best_mse,best_ci: 0.2590503 0.8706174027668252 GCNNet davis
Training on 25046 samples...
Train epoch: 921 [0/25046 (0%)]	Loss: 0.081750
Train epoch: 921 [331300/25046 (41%)]	Loss: 0.090719
Train epoch: 921 [662680/25046 (82%)]	Loss: 0.123378
Make prediction for 5010 samples...
0.28215292 No improvement since epoch  865 ; best_mse,best_ci: 0.2590503 0.8706174027668252 GCNNet davis
Training on 25046 samples...
Train epoch: 922 [0/25046 (0%)]	Loss: 0.075241
Train epoch: 922 [323340/25046 (41%)]	Loss: 0.099716
Train epoch: 922 [658880/25046 (82%)]	Loss: 0.087098
Make prediction for 5010 samples...
0.2651882 No improvement since epoch  865 ; best_mse,best_ci: 0.2590503 0.8706174027668252 GCNNet davis
Training on 25046 samples...
Train epoch: 923 [0/25046 (0%)]	Loss: 0.094395
Train epoch: 923 [325440/25046 (41%)]	Loss: 0.078155
Train epoch: 923 [661320/25046 (82%)]	Loss: 0.083855
Make prediction for 5010 samples...
0.2742867 No improvement since epoch  865 ; best_mse,best_ci: 0.2590503 0.8706174027668252 GCNNet davis
Training on 25046 samples...
Train epoch: 924 [0/25046 (0%)]	Loss: 0.075676
Train epoch: 924 [329680/25046 (41%)]	Loss: 0.091096
Train epoch: 924 [662880/25046 (82%)]	Loss: 0.081520
Make prediction for 5010 samples...
0.26425043 No improvement since epoch  865 ; best_mse,best_ci: 0.2590503 0.8706174027668252 GCNNet davis
Training on 25046 samples...
Train epoch: 925 [0/25046 (0%)]	Loss: 0.067159
Train epoch: 925 [328920/25046 (41%)]	Loss: 0.068083
Train epoch: 925 [656880/25046 (82%)]	Loss: 0.121737
Make prediction for 5010 samples...
0.26974723 No improvement since epoch  865 ; best_mse,best_ci: 0.2590503 0.8706174027668252 GCNNet davis
Training on 25046 samples...
Train epoch: 926 [0/25046 (0%)]	Loss: 0.081161
Train epoch: 926 [329060/25046 (41%)]	Loss: 0.105594
Train epoch: 926 [658600/25046 (82%)]	Loss: 0.085637
Make prediction for 5010 samples...
0.2870768 No improvement since epoch  865 ; best_mse,best_ci: 0.2590503 0.8706174027668252 GCNNet davis
Training on 25046 samples...
Train epoch: 927 [0/25046 (0%)]	Loss: 0.113175
Train epoch: 927 [329680/25046 (41%)]	Loss: 0.092347
Train epoch: 927 [656000/25046 (82%)]	Loss: 0.089222
Make prediction for 5010 samples...
0.26603502 No improvement since epoch  865 ; best_mse,best_ci: 0.2590503 0.8706174027668252 GCNNet davis
Training on 25046 samples...
Train epoch: 928 [0/25046 (0%)]	Loss: 0.110212
Train epoch: 928 [329880/25046 (41%)]	Loss: 0.097917
Train epoch: 928 [657920/25046 (82%)]	Loss: 0.080898
Make prediction for 5010 samples...
0.27663702 No improvement since epoch  865 ; best_mse,best_ci: 0.2590503 0.8706174027668252 GCNNet davis
Training on 25046 samples...
Train epoch: 929 [0/25046 (0%)]	Loss: 0.072155
Train epoch: 929 [328060/25046 (41%)]	Loss: 0.102008
Train epoch: 929 [663880/25046 (82%)]	Loss: 0.101698
Make prediction for 5010 samples...
0.27811843 No improvement since epoch  865 ; best_mse,best_ci: 0.2590503 0.8706174027668252 GCNNet davis
Training on 25046 samples...
Train epoch: 930 [0/25046 (0%)]	Loss: 0.084494
Train epoch: 930 [327300/25046 (41%)]	Loss: 0.120323
Train epoch: 930 [655880/25046 (82%)]	Loss: 0.079371
Make prediction for 5010 samples...
0.29112342 No improvement since epoch  865 ; best_mse,best_ci: 0.2590503 0.8706174027668252 GCNNet davis
Training on 25046 samples...
Train epoch: 931 [0/25046 (0%)]	Loss: 0.130613
Train epoch: 931 [329420/25046 (41%)]	Loss: 0.096492
Train epoch: 931 [655600/25046 (82%)]	Loss: 0.105317
Make prediction for 5010 samples...
0.2726146 No improvement since epoch  865 ; best_mse,best_ci: 0.2590503 0.8706174027668252 GCNNet davis
Training on 25046 samples...
Train epoch: 932 [0/25046 (0%)]	Loss: 0.103541
Train epoch: 932 [330600/25046 (41%)]	Loss: 0.103375
Train epoch: 932 [662880/25046 (82%)]	Loss: 0.092745
Make prediction for 5010 samples...
0.26666403 No improvement since epoch  865 ; best_mse,best_ci: 0.2590503 0.8706174027668252 GCNNet davis
Training on 25046 samples...
Train epoch: 933 [0/25046 (0%)]	Loss: 0.101606
Train epoch: 933 [326320/25046 (41%)]	Loss: 0.147126
Train epoch: 933 [655880/25046 (82%)]	Loss: 0.085143
Make prediction for 5010 samples...
0.26784053 No improvement since epoch  865 ; best_mse,best_ci: 0.2590503 0.8706174027668252 GCNNet davis
Training on 25046 samples...
Train epoch: 934 [0/25046 (0%)]	Loss: 0.065510
Train epoch: 934 [331400/25046 (41%)]	Loss: 0.101844
Train epoch: 934 [667680/25046 (82%)]	Loss: 0.076258
Make prediction for 5010 samples...
0.30210462 No improvement since epoch  865 ; best_mse,best_ci: 0.2590503 0.8706174027668252 GCNNet davis
Training on 25046 samples...
Train epoch: 935 [0/25046 (0%)]	Loss: 0.141795
Train epoch: 935 [326260/25046 (41%)]	Loss: 0.105214
Train epoch: 935 [662680/25046 (82%)]	Loss: 0.079833
Make prediction for 5010 samples...
0.26962408 No improvement since epoch  865 ; best_mse,best_ci: 0.2590503 0.8706174027668252 GCNNet davis
Training on 25046 samples...
Train epoch: 936 [0/25046 (0%)]	Loss: 0.090245
Train epoch: 936 [330880/25046 (41%)]	Loss: 0.143060
Train epoch: 936 [659480/25046 (82%)]	Loss: 0.088615
Make prediction for 5010 samples...
0.2706821 No improvement since epoch  865 ; best_mse,best_ci: 0.2590503 0.8706174027668252 GCNNet davis
Training on 25046 samples...
Train epoch: 937 [0/25046 (0%)]	Loss: 0.083729
Train epoch: 937 [327180/25046 (41%)]	Loss: 0.140104
Train epoch: 937 [650840/25046 (82%)]	Loss: 0.117664
Make prediction for 5010 samples...
0.26577824 No improvement since epoch  865 ; best_mse,best_ci: 0.2590503 0.8706174027668252 GCNNet davis
Training on 25046 samples...
Train epoch: 938 [0/25046 (0%)]	Loss: 0.094076
Train epoch: 938 [327100/25046 (41%)]	Loss: 0.109898
Train epoch: 938 [661360/25046 (82%)]	Loss: 0.087426
Make prediction for 5010 samples...
0.28060046 No improvement since epoch  865 ; best_mse,best_ci: 0.2590503 0.8706174027668252 GCNNet davis
Training on 25046 samples...
Train epoch: 939 [0/25046 (0%)]	Loss: 0.081331
Train epoch: 939 [329380/25046 (41%)]	Loss: 0.125267
Train epoch: 939 [655440/25046 (82%)]	Loss: 0.086729
Make prediction for 5010 samples...
0.27141508 No improvement since epoch  865 ; best_mse,best_ci: 0.2590503 0.8706174027668252 GCNNet davis
Training on 25046 samples...
Train epoch: 940 [0/25046 (0%)]	Loss: 0.097678
Train epoch: 940 [325760/25046 (41%)]	Loss: 0.086200
Train epoch: 940 [653640/25046 (82%)]	Loss: 0.104758
Make prediction for 5010 samples...
0.27778155 No improvement since epoch  865 ; best_mse,best_ci: 0.2590503 0.8706174027668252 GCNNet davis
Training on 25046 samples...
Train epoch: 941 [0/25046 (0%)]	Loss: 0.102739
Train epoch: 941 [327700/25046 (41%)]	Loss: 0.097407
Train epoch: 941 [649640/25046 (82%)]	Loss: 0.076941
Make prediction for 5010 samples...
0.26061872 No improvement since epoch  865 ; best_mse,best_ci: 0.2590503 0.8706174027668252 GCNNet davis
Training on 25046 samples...
Train epoch: 942 [0/25046 (0%)]	Loss: 0.071342
Train epoch: 942 [328160/25046 (41%)]	Loss: 0.079023
Train epoch: 942 [653480/25046 (82%)]	Loss: 0.098591
Make prediction for 5010 samples...
0.27465624 No improvement since epoch  865 ; best_mse,best_ci: 0.2590503 0.8706174027668252 GCNNet davis
Training on 25046 samples...
Train epoch: 943 [0/25046 (0%)]	Loss: 0.096892
Train epoch: 943 [331480/25046 (41%)]	Loss: 0.100888
Train epoch: 943 [651400/25046 (82%)]	Loss: 0.067804
Make prediction for 5010 samples...
rmse improved at epoch  943 ; best_mse,best_ci: 0.25881538 0.8821720814043118 GCNNet davis
Training on 25046 samples...
Train epoch: 944 [0/25046 (0%)]	Loss: 0.095678
Train epoch: 944 [325260/25046 (41%)]	Loss: 0.104253
Train epoch: 944 [650440/25046 (82%)]	Loss: 0.092864
Make prediction for 5010 samples...
0.2924444 No improvement since epoch  943 ; best_mse,best_ci: 0.25881538 0.8821720814043118 GCNNet davis
Training on 25046 samples...
Train epoch: 945 [0/25046 (0%)]	Loss: 0.121520
Train epoch: 945 [327640/25046 (41%)]	Loss: 0.078556
Train epoch: 945 [656560/25046 (82%)]	Loss: 0.091854
Make prediction for 5010 samples...
0.27330363 No improvement since epoch  943 ; best_mse,best_ci: 0.25881538 0.8821720814043118 GCNNet davis
Training on 25046 samples...
Train epoch: 946 [0/25046 (0%)]	Loss: 0.090478
Train epoch: 946 [328880/25046 (41%)]	Loss: 0.069798
Train epoch: 946 [651920/25046 (82%)]	Loss: 0.076651
Make prediction for 5010 samples...
0.26473504 No improvement since epoch  943 ; best_mse,best_ci: 0.25881538 0.8821720814043118 GCNNet davis
Training on 25046 samples...
Train epoch: 947 [0/25046 (0%)]	Loss: 0.071920
Train epoch: 947 [325860/25046 (41%)]	Loss: 0.109582
Train epoch: 947 [664760/25046 (82%)]	Loss: 0.078549
Make prediction for 5010 samples...
0.27271175 No improvement since epoch  943 ; best_mse,best_ci: 0.25881538 0.8821720814043118 GCNNet davis
Training on 25046 samples...
Train epoch: 948 [0/25046 (0%)]	Loss: 0.074445
Train epoch: 948 [329640/25046 (41%)]	Loss: 0.087575
Train epoch: 948 [657560/25046 (82%)]	Loss: 0.084180
Make prediction for 5010 samples...
0.29727226 No improvement since epoch  943 ; best_mse,best_ci: 0.25881538 0.8821720814043118 GCNNet davis
Training on 25046 samples...
Train epoch: 949 [0/25046 (0%)]	Loss: 0.124312
Train epoch: 949 [324800/25046 (41%)]	Loss: 0.088299
Train epoch: 949 [655680/25046 (82%)]	Loss: 0.089640
Make prediction for 5010 samples...
0.2834175 No improvement since epoch  943 ; best_mse,best_ci: 0.25881538 0.8821720814043118 GCNNet davis
Training on 25046 samples...
Train epoch: 950 [0/25046 (0%)]	Loss: 0.091696
Train epoch: 950 [335760/25046 (41%)]	Loss: 0.097172
Train epoch: 950 [650320/25046 (82%)]	Loss: 0.080848
Make prediction for 5010 samples...
rmse improved at epoch  950 ; best_mse,best_ci: 0.25860506 0.8762476006722176 GCNNet davis
Training on 25046 samples...
Train epoch: 951 [0/25046 (0%)]	Loss: 0.104485
Train epoch: 951 [325260/25046 (41%)]	Loss: 0.087987
Train epoch: 951 [653400/25046 (82%)]	Loss: 0.093702
Make prediction for 5010 samples...
0.25916356 No improvement since epoch  950 ; best_mse,best_ci: 0.25860506 0.8762476006722176 GCNNet davis
Training on 25046 samples...
Train epoch: 952 [0/25046 (0%)]	Loss: 0.112950
Train epoch: 952 [334800/25046 (41%)]	Loss: 0.109195
Train epoch: 952 [653000/25046 (82%)]	Loss: 0.103924
Make prediction for 5010 samples...
0.28829938 No improvement since epoch  950 ; best_mse,best_ci: 0.25860506 0.8762476006722176 GCNNet davis
Training on 25046 samples...
Train epoch: 953 [0/25046 (0%)]	Loss: 0.087504
Train epoch: 953 [329600/25046 (41%)]	Loss: 0.135493
Train epoch: 953 [652680/25046 (82%)]	Loss: 0.085203
Make prediction for 5010 samples...
rmse improved at epoch  953 ; best_mse,best_ci: 0.25787678 0.884343326595127 GCNNet davis
Training on 25046 samples...
Train epoch: 954 [0/25046 (0%)]	Loss: 0.139172
Train epoch: 954 [324940/25046 (41%)]	Loss: 0.083455
Train epoch: 954 [650440/25046 (82%)]	Loss: 0.092823
Make prediction for 5010 samples...
0.2581808 No improvement since epoch  953 ; best_mse,best_ci: 0.25787678 0.884343326595127 GCNNet davis
Training on 25046 samples...
Train epoch: 955 [0/25046 (0%)]	Loss: 0.134154
Train epoch: 955 [328680/25046 (41%)]	Loss: 0.084832
Train epoch: 955 [656000/25046 (82%)]	Loss: 0.109785
Make prediction for 5010 samples...
0.2660668 No improvement since epoch  953 ; best_mse,best_ci: 0.25787678 0.884343326595127 GCNNet davis
Training on 25046 samples...
Train epoch: 956 [0/25046 (0%)]	Loss: 0.084441
Train epoch: 956 [326880/25046 (41%)]	Loss: 0.099840
Train epoch: 956 [659440/25046 (82%)]	Loss: 0.093359
Make prediction for 5010 samples...
0.26115483 No improvement since epoch  953 ; best_mse,best_ci: 0.25787678 0.884343326595127 GCNNet davis
Training on 25046 samples...
Train epoch: 957 [0/25046 (0%)]	Loss: 0.138667
Train epoch: 957 [331800/25046 (41%)]	Loss: 0.120466
Train epoch: 957 [651320/25046 (82%)]	Loss: 0.105254
Make prediction for 5010 samples...
0.26343048 No improvement since epoch  953 ; best_mse,best_ci: 0.25787678 0.884343326595127 GCNNet davis
Training on 25046 samples...
Train epoch: 958 [0/25046 (0%)]	Loss: 0.097537
Train epoch: 958 [328640/25046 (41%)]	Loss: 0.099355
Train epoch: 958 [656560/25046 (82%)]	Loss: 0.108172
Make prediction for 5010 samples...
0.2684169 No improvement since epoch  953 ; best_mse,best_ci: 0.25787678 0.884343326595127 GCNNet davis
Training on 25046 samples...
Train epoch: 959 [0/25046 (0%)]	Loss: 0.091347
Train epoch: 959 [326920/25046 (41%)]	Loss: 0.088087
Train epoch: 959 [652720/25046 (82%)]	Loss: 0.098874
Make prediction for 5010 samples...
0.26285344 No improvement since epoch  953 ; best_mse,best_ci: 0.25787678 0.884343326595127 GCNNet davis
Training on 25046 samples...
Train epoch: 960 [0/25046 (0%)]	Loss: 0.098482
Train epoch: 960 [333320/25046 (41%)]	Loss: 0.075238
Train epoch: 960 [658720/25046 (82%)]	Loss: 0.107057
Make prediction for 5010 samples...
0.2696188 No improvement since epoch  953 ; best_mse,best_ci: 0.25787678 0.884343326595127 GCNNet davis
Training on 25046 samples...
Train epoch: 961 [0/25046 (0%)]	Loss: 0.101121
Train epoch: 961 [330440/25046 (41%)]	Loss: 0.077312
Train epoch: 961 [656360/25046 (82%)]	Loss: 0.089151
Make prediction for 5010 samples...
0.2624958 No improvement since epoch  953 ; best_mse,best_ci: 0.25787678 0.884343326595127 GCNNet davis
Training on 25046 samples...
Train epoch: 962 [0/25046 (0%)]	Loss: 0.084272
Train epoch: 962 [328160/25046 (41%)]	Loss: 0.096576
Train epoch: 962 [659920/25046 (82%)]	Loss: 0.080372
Make prediction for 5010 samples...
rmse improved at epoch  962 ; best_mse,best_ci: 0.25333843 0.8826969355532096 GCNNet davis
Training on 25046 samples...
Train epoch: 963 [0/25046 (0%)]	Loss: 0.090485
Train epoch: 963 [330860/25046 (41%)]	Loss: 0.116954
Train epoch: 963 [645440/25046 (82%)]	Loss: 0.078410
Make prediction for 5010 samples...
0.2680631 No improvement since epoch  962 ; best_mse,best_ci: 0.25333843 0.8826969355532096 GCNNet davis
Training on 25046 samples...
Train epoch: 964 [0/25046 (0%)]	Loss: 0.080332
Train epoch: 964 [328740/25046 (41%)]	Loss: 0.095887
Train epoch: 964 [655360/25046 (82%)]	Loss: 0.109720
Make prediction for 5010 samples...
0.26792556 No improvement since epoch  962 ; best_mse,best_ci: 0.25333843 0.8826969355532096 GCNNet davis
Training on 25046 samples...
Train epoch: 965 [0/25046 (0%)]	Loss: 0.094180
Train epoch: 965 [327260/25046 (41%)]	Loss: 0.094402
Train epoch: 965 [665920/25046 (82%)]	Loss: 0.083374
Make prediction for 5010 samples...
0.26775566 No improvement since epoch  962 ; best_mse,best_ci: 0.25333843 0.8826969355532096 GCNNet davis
Training on 25046 samples...
Train epoch: 966 [0/25046 (0%)]	Loss: 0.091389
Train epoch: 966 [333740/25046 (41%)]	Loss: 0.104026
Train epoch: 966 [658200/25046 (82%)]	Loss: 0.113166
Make prediction for 5010 samples...
0.29778752 No improvement since epoch  962 ; best_mse,best_ci: 0.25333843 0.8826969355532096 GCNNet davis
Training on 25046 samples...
Train epoch: 967 [0/25046 (0%)]	Loss: 0.102783
Train epoch: 967 [330920/25046 (41%)]	Loss: 0.128135
Train epoch: 967 [646920/25046 (82%)]	Loss: 0.076329
Make prediction for 5010 samples...
0.30839294 No improvement since epoch  962 ; best_mse,best_ci: 0.25333843 0.8826969355532096 GCNNet davis
Training on 25046 samples...
Train epoch: 968 [0/25046 (0%)]	Loss: 0.091394
Train epoch: 968 [327220/25046 (41%)]	Loss: 0.077082
Train epoch: 968 [651200/25046 (82%)]	Loss: 0.114996
Make prediction for 5010 samples...
0.26336023 No improvement since epoch  962 ; best_mse,best_ci: 0.25333843 0.8826969355532096 GCNNet davis
Training on 25046 samples...
Train epoch: 969 [0/25046 (0%)]	Loss: 0.092663
Train epoch: 969 [330640/25046 (41%)]	Loss: 0.083935
Train epoch: 969 [648160/25046 (82%)]	Loss: 0.066954
Make prediction for 5010 samples...
0.27158526 No improvement since epoch  962 ; best_mse,best_ci: 0.25333843 0.8826969355532096 GCNNet davis
Training on 25046 samples...
Train epoch: 970 [0/25046 (0%)]	Loss: 0.115412
Train epoch: 970 [332640/25046 (41%)]	Loss: 0.071165
Train epoch: 970 [656680/25046 (82%)]	Loss: 0.095822
Make prediction for 5010 samples...
0.2644777 No improvement since epoch  962 ; best_mse,best_ci: 0.25333843 0.8826969355532096 GCNNet davis
Training on 25046 samples...
Train epoch: 971 [0/25046 (0%)]	Loss: 0.109129
Train epoch: 971 [324720/25046 (41%)]	Loss: 0.095851
Train epoch: 971 [662320/25046 (82%)]	Loss: 0.100919
Make prediction for 5010 samples...
0.27837735 No improvement since epoch  962 ; best_mse,best_ci: 0.25333843 0.8826969355532096 GCNNet davis
Training on 25046 samples...
Train epoch: 972 [0/25046 (0%)]	Loss: 0.085253
Train epoch: 972 [325160/25046 (41%)]	Loss: 0.071497
Train epoch: 972 [661360/25046 (82%)]	Loss: 0.090236
Make prediction for 5010 samples...
0.26511484 No improvement since epoch  962 ; best_mse,best_ci: 0.25333843 0.8826969355532096 GCNNet davis
Training on 25046 samples...
Train epoch: 973 [0/25046 (0%)]	Loss: 0.089733
Train epoch: 973 [335100/25046 (41%)]	Loss: 0.069065
Train epoch: 973 [646440/25046 (82%)]	Loss: 0.125253
Make prediction for 5010 samples...
0.26055554 No improvement since epoch  962 ; best_mse,best_ci: 0.25333843 0.8826969355532096 GCNNet davis
Training on 25046 samples...
Train epoch: 974 [0/25046 (0%)]	Loss: 0.079478
Train epoch: 974 [326740/25046 (41%)]	Loss: 0.065081
Train epoch: 974 [656600/25046 (82%)]	Loss: 0.107456
Make prediction for 5010 samples...
0.27898315 No improvement since epoch  962 ; best_mse,best_ci: 0.25333843 0.8826969355532096 GCNNet davis
Training on 25046 samples...
Train epoch: 975 [0/25046 (0%)]	Loss: 0.123924
Train epoch: 975 [327600/25046 (41%)]	Loss: 0.094695
Train epoch: 975 [649960/25046 (82%)]	Loss: 0.083927
Make prediction for 5010 samples...
0.2754033 No improvement since epoch  962 ; best_mse,best_ci: 0.25333843 0.8826969355532096 GCNNet davis
Training on 25046 samples...
Train epoch: 976 [0/25046 (0%)]	Loss: 0.099779
Train epoch: 976 [331860/25046 (41%)]	Loss: 0.098566
Train epoch: 976 [659800/25046 (82%)]	Loss: 0.108194
Make prediction for 5010 samples...
0.29838514 No improvement since epoch  962 ; best_mse,best_ci: 0.25333843 0.8826969355532096 GCNNet davis
Training on 25046 samples...
Train epoch: 977 [0/25046 (0%)]	Loss: 0.104439
Train epoch: 977 [327500/25046 (41%)]	Loss: 0.105415
Train epoch: 977 [667360/25046 (82%)]	Loss: 0.062357
Make prediction for 5010 samples...
0.26931506 No improvement since epoch  962 ; best_mse,best_ci: 0.25333843 0.8826969355532096 GCNNet davis
Training on 25046 samples...
Train epoch: 978 [0/25046 (0%)]	Loss: 0.076065
Train epoch: 978 [325300/25046 (41%)]	Loss: 0.107551
Train epoch: 978 [658760/25046 (82%)]	Loss: 0.110103
Make prediction for 5010 samples...
0.26450893 No improvement since epoch  962 ; best_mse,best_ci: 0.25333843 0.8826969355532096 GCNNet davis
Training on 25046 samples...
Train epoch: 979 [0/25046 (0%)]	Loss: 0.113034
Train epoch: 979 [327040/25046 (41%)]	Loss: 0.108314
Train epoch: 979 [658880/25046 (82%)]	Loss: 0.091207
Make prediction for 5010 samples...
0.26392245 No improvement since epoch  962 ; best_mse,best_ci: 0.25333843 0.8826969355532096 GCNNet davis
Training on 25046 samples...
Train epoch: 980 [0/25046 (0%)]	Loss: 0.108962
Train epoch: 980 [331740/25046 (41%)]	Loss: 0.197183
Train epoch: 980 [656960/25046 (82%)]	Loss: 0.094091
Make prediction for 5010 samples...
0.27440092 No improvement since epoch  962 ; best_mse,best_ci: 0.25333843 0.8826969355532096 GCNNet davis
Training on 25046 samples...
Train epoch: 981 [0/25046 (0%)]	Loss: 0.068528
Train epoch: 981 [332320/25046 (41%)]	Loss: 0.097020
Train epoch: 981 [660240/25046 (82%)]	Loss: 0.076014
Make prediction for 5010 samples...
0.30548045 No improvement since epoch  962 ; best_mse,best_ci: 0.25333843 0.8826969355532096 GCNNet davis
Training on 25046 samples...
Train epoch: 982 [0/25046 (0%)]	Loss: 0.102740
Train epoch: 982 [327080/25046 (41%)]	Loss: 0.073416
Train epoch: 982 [660640/25046 (82%)]	Loss: 0.076927
Make prediction for 5010 samples...
0.27502796 No improvement since epoch  962 ; best_mse,best_ci: 0.25333843 0.8826969355532096 GCNNet davis
Training on 25046 samples...
Train epoch: 983 [0/25046 (0%)]	Loss: 0.084303
Train epoch: 983 [329060/25046 (41%)]	Loss: 0.075910
Train epoch: 983 [668720/25046 (82%)]	Loss: 0.080764
Make prediction for 5010 samples...
0.26205772 No improvement since epoch  962 ; best_mse,best_ci: 0.25333843 0.8826969355532096 GCNNet davis
Training on 25046 samples...
Train epoch: 984 [0/25046 (0%)]	Loss: 0.087556
Train epoch: 984 [330060/25046 (41%)]	Loss: 0.119517
Train epoch: 984 [663880/25046 (82%)]	Loss: 0.102310
Make prediction for 5010 samples...
0.26139975 No improvement since epoch  962 ; best_mse,best_ci: 0.25333843 0.8826969355532096 GCNNet davis
Training on 25046 samples...
Train epoch: 985 [0/25046 (0%)]	Loss: 0.115159
Train epoch: 985 [332880/25046 (41%)]	Loss: 0.123886
Train epoch: 985 [669560/25046 (82%)]	Loss: 0.110281
Make prediction for 5010 samples...
0.28026938 No improvement since epoch  962 ; best_mse,best_ci: 0.25333843 0.8826969355532096 GCNNet davis
Training on 25046 samples...
Train epoch: 986 [0/25046 (0%)]	Loss: 0.077915
Train epoch: 986 [325080/25046 (41%)]	Loss: 0.104221
Train epoch: 986 [649040/25046 (82%)]	Loss: 0.087736
Make prediction for 5010 samples...
0.26920238 No improvement since epoch  962 ; best_mse,best_ci: 0.25333843 0.8826969355532096 GCNNet davis
Training on 25046 samples...
Train epoch: 987 [0/25046 (0%)]	Loss: 0.086921
Train epoch: 987 [328120/25046 (41%)]	Loss: 0.105140
Train epoch: 987 [668200/25046 (82%)]	Loss: 0.118644
Make prediction for 5010 samples...
0.26629296 No improvement since epoch  962 ; best_mse,best_ci: 0.25333843 0.8826969355532096 GCNNet davis
Training on 25046 samples...
Train epoch: 988 [0/25046 (0%)]	Loss: 0.072748
Train epoch: 988 [332700/25046 (41%)]	Loss: 0.109221
Train epoch: 988 [655640/25046 (82%)]	Loss: 0.091361
Make prediction for 5010 samples...
0.29530364 No improvement since epoch  962 ; best_mse,best_ci: 0.25333843 0.8826969355532096 GCNNet davis
Training on 25046 samples...
Train epoch: 989 [0/25046 (0%)]	Loss: 0.098112
Train epoch: 989 [325800/25046 (41%)]	Loss: 0.069657
Train epoch: 989 [661240/25046 (82%)]	Loss: 0.096956
Make prediction for 5010 samples...
0.28237304 No improvement since epoch  962 ; best_mse,best_ci: 0.25333843 0.8826969355532096 GCNNet davis
Training on 25046 samples...
Train epoch: 990 [0/25046 (0%)]	Loss: 0.107956
Train epoch: 990 [332700/25046 (41%)]	Loss: 0.081396
Train epoch: 990 [642400/25046 (82%)]	Loss: 0.084525
Make prediction for 5010 samples...
0.2651152 No improvement since epoch  962 ; best_mse,best_ci: 0.25333843 0.8826969355532096 GCNNet davis
Training on 25046 samples...
Train epoch: 991 [0/25046 (0%)]	Loss: 0.073118
Train epoch: 991 [329460/25046 (41%)]	Loss: 0.121154
Train epoch: 991 [662200/25046 (82%)]	Loss: 0.074425
Make prediction for 5010 samples...
0.26940763 No improvement since epoch  962 ; best_mse,best_ci: 0.25333843 0.8826969355532096 GCNNet davis
Training on 25046 samples...
Train epoch: 992 [0/25046 (0%)]	Loss: 0.090080
Train epoch: 992 [325940/25046 (41%)]	Loss: 0.111578
Train epoch: 992 [656760/25046 (82%)]	Loss: 0.106931
Make prediction for 5010 samples...
0.26821232 No improvement since epoch  962 ; best_mse,best_ci: 0.25333843 0.8826969355532096 GCNNet davis
Training on 25046 samples...
Train epoch: 993 [0/25046 (0%)]	Loss: 0.077696
Train epoch: 993 [323680/25046 (41%)]	Loss: 0.081359
Train epoch: 993 [649920/25046 (82%)]	Loss: 0.094603
Make prediction for 5010 samples...
0.26892665 No improvement since epoch  962 ; best_mse,best_ci: 0.25333843 0.8826969355532096 GCNNet davis
Training on 25046 samples...
Train epoch: 994 [0/25046 (0%)]	Loss: 0.079159
Train epoch: 994 [327400/25046 (41%)]	Loss: 0.073213
Train epoch: 994 [656200/25046 (82%)]	Loss: 0.078433
Make prediction for 5010 samples...
0.2629807 No improvement since epoch  962 ; best_mse,best_ci: 0.25333843 0.8826969355532096 GCNNet davis
Training on 25046 samples...
Train epoch: 995 [0/25046 (0%)]	Loss: 0.085130
Train epoch: 995 [335200/25046 (41%)]	Loss: 0.090250
Train epoch: 995 [660160/25046 (82%)]	Loss: 0.066109
Make prediction for 5010 samples...
0.27360353 No improvement since epoch  962 ; best_mse,best_ci: 0.25333843 0.8826969355532096 GCNNet davis
Training on 25046 samples...
Train epoch: 996 [0/25046 (0%)]	Loss: 0.069006
Train epoch: 996 [329180/25046 (41%)]	Loss: 0.120425
Train epoch: 996 [656360/25046 (82%)]	Loss: 0.081526
Make prediction for 5010 samples...
0.27476317 No improvement since epoch  962 ; best_mse,best_ci: 0.25333843 0.8826969355532096 GCNNet davis
Training on 25046 samples...
Train epoch: 997 [0/25046 (0%)]	Loss: 0.105862
Train epoch: 997 [329040/25046 (41%)]	Loss: 0.112022
Train epoch: 997 [666480/25046 (82%)]	Loss: 0.078158
Make prediction for 5010 samples...
0.27383527 No improvement since epoch  962 ; best_mse,best_ci: 0.25333843 0.8826969355532096 GCNNet davis
Training on 25046 samples...
Train epoch: 998 [0/25046 (0%)]	Loss: 0.083270
Train epoch: 998 [331460/25046 (41%)]	Loss: 0.105502
Train epoch: 998 [656560/25046 (82%)]	Loss: 0.098712
Make prediction for 5010 samples...
0.27514002 No improvement since epoch  962 ; best_mse,best_ci: 0.25333843 0.8826969355532096 GCNNet davis
Training on 25046 samples...
Train epoch: 999 [0/25046 (0%)]	Loss: 0.098253
Train epoch: 999 [328700/25046 (41%)]	Loss: 0.107127
Train epoch: 999 [654960/25046 (82%)]	Loss: 0.099481
Make prediction for 5010 samples...
0.2654219 No improvement since epoch  962 ; best_mse,best_ci: 0.25333843 0.8826969355532096 GCNNet davis
Training on 25046 samples...
Train epoch: 1000 [0/25046 (0%)]	Loss: 0.080662
Train epoch: 1000 [332160/25046 (41%)]	Loss: 0.085624
Train epoch: 1000 [655200/25046 (82%)]	Loss: 0.077559
Make prediction for 5010 samples...
0.29691938 No improvement since epoch  962 ; best_mse,best_ci: 0.25333843 0.8826969355532096 GCNNet davis
