cuda_name: cuda:0
Learning rate:  0.0005
Epochs:  1000

running on  GINConvNet_davis
Pre-processed data found: data/processed/davis_train.pt, loading ...
Pre-processed data found: data/processed/davis_test.pt, loading ...
Device:  cpu cuda name: cpu
Training epoch 1... Time: Sun Jun  9 16:36:57 2024
Training on 25046 samples...
Train epoch: 1 [0/25046 (0%)]	Loss: 30.828764
Train epoch: 1 [331360/25046 (41%)]	Loss: 1.077733
Train epoch: 1 [652640/25046 (82%)]	Loss: 0.817770
Make prediction for 5010 samples...
rmse improved at epoch  1 ; best_mse,best_ci: 1.9247338 0.5913150498672702 GINConvNet davis
Training epoch 2... Time: Sun Jun  9 16:37:33 2024
Training on 25046 samples...
Train epoch: 2 [0/25046 (0%)]	Loss: 0.707912
Train epoch: 2 [329420/25046 (41%)]	Loss: 0.783314
Train epoch: 2 [659080/25046 (82%)]	Loss: 0.847011
Make prediction for 5010 samples...
rmse improved at epoch  2 ; best_mse,best_ci: 0.8422559 0.7617711216272531 GINConvNet davis
Training epoch 3... Time: Sun Jun  9 16:38:05 2024
Training on 25046 samples...
Train epoch: 3 [0/25046 (0%)]	Loss: 0.715166
Train epoch: 3 [330940/25046 (41%)]	Loss: 0.748891
Train epoch: 3 [661640/25046 (82%)]	Loss: 0.642226
Make prediction for 5010 samples...
rmse improved at epoch  3 ; best_mse,best_ci: 0.73837376 0.7899638452527195 GINConvNet davis
Training epoch 4... Time: Sun Jun  9 16:38:37 2024
Training on 25046 samples...
Train epoch: 4 [0/25046 (0%)]	Loss: 0.642782
Train epoch: 4 [325440/25046 (41%)]	Loss: 0.611457
Train epoch: 4 [666080/25046 (82%)]	Loss: 0.665051
Make prediction for 5010 samples...
rmse improved at epoch  4 ; best_mse,best_ci: 0.57953894 0.7970176736632415 GINConvNet davis
Training epoch 5... Time: Sun Jun  9 16:39:07 2024
Training on 25046 samples...
Train epoch: 5 [0/25046 (0%)]	Loss: 0.663069
Train epoch: 5 [329920/25046 (41%)]	Loss: 0.632777
Train epoch: 5 [659960/25046 (82%)]	Loss: 0.641076
Make prediction for 5010 samples...
0.57953894 No improvement since epoch  4 ; best_mse,best_ci: 0.57953894 0.7970176736632415 GINConvNet davis
Training epoch 6... Time: Sun Jun  9 16:39:22 2024
Training on 25046 samples...
Train epoch: 6 [0/25046 (0%)]	Loss: 0.539178
Train epoch: 6 [327140/25046 (41%)]	Loss: 0.538176
Train epoch: 6 [657000/25046 (82%)]	Loss: 0.539639
Make prediction for 5010 samples...
0.57953894 No improvement since epoch  4 ; best_mse,best_ci: 0.57953894 0.7970176736632415 GINConvNet davis
Training epoch 7... Time: Sun Jun  9 16:39:38 2024
Training on 25046 samples...
Train epoch: 7 [0/25046 (0%)]	Loss: 0.599108
Train epoch: 7 [324980/25046 (41%)]	Loss: 0.535936
Train epoch: 7 [660360/25046 (82%)]	Loss: 0.484054
Make prediction for 5010 samples...
rmse improved at epoch  7 ; best_mse,best_ci: 0.55206716 0.7960898748788754 GINConvNet davis
Training epoch 8... Time: Sun Jun  9 16:40:08 2024
Training on 25046 samples...
Train epoch: 8 [0/25046 (0%)]	Loss: 0.498323
Train epoch: 8 [329420/25046 (41%)]	Loss: 0.445218
Train epoch: 8 [656400/25046 (82%)]	Loss: 0.542907
Make prediction for 5010 samples...
0.55206716 No improvement since epoch  7 ; best_mse,best_ci: 0.55206716 0.7960898748788754 GINConvNet davis
Training epoch 9... Time: Sun Jun  9 16:40:24 2024
Training on 25046 samples...
Train epoch: 9 [0/25046 (0%)]	Loss: 0.423215
Train epoch: 9 [326860/25046 (41%)]	Loss: 0.440062
Train epoch: 9 [656760/25046 (82%)]	Loss: 0.541114
Make prediction for 5010 samples...
0.55206716 No improvement since epoch  7 ; best_mse,best_ci: 0.55206716 0.7960898748788754 GINConvNet davis
Training epoch 10... Time: Sun Jun  9 16:40:39 2024
Training on 25046 samples...
Train epoch: 10 [0/25046 (0%)]	Loss: 0.405137
Train epoch: 10 [329340/25046 (41%)]	Loss: 0.455405
Train epoch: 10 [653440/25046 (82%)]	Loss: 0.506847
Make prediction for 5010 samples...
rmse improved at epoch  10 ; best_mse,best_ci: 0.50405973 0.8244757240023751 GINConvNet davis
Training epoch 11... Time: Sun Jun  9 16:41:09 2024
Training on 25046 samples...
Train epoch: 11 [0/25046 (0%)]	Loss: 0.479982
Train epoch: 11 [333280/25046 (41%)]	Loss: 0.594268
Train epoch: 11 [652120/25046 (82%)]	Loss: 0.412865
Make prediction for 5010 samples...
rmse improved at epoch  11 ; best_mse,best_ci: 0.50018233 0.8308650996189102 GINConvNet davis
Training epoch 12... Time: Sun Jun  9 16:41:39 2024
Training on 25046 samples...
Train epoch: 12 [0/25046 (0%)]	Loss: 0.424714
Train epoch: 12 [326000/25046 (41%)]	Loss: 0.430360
Train epoch: 12 [661040/25046 (82%)]	Loss: 0.446049
Make prediction for 5010 samples...
rmse improved at epoch  12 ; best_mse,best_ci: 0.46947837 0.8463846707669717 GINConvNet davis
Training epoch 13... Time: Sun Jun  9 16:42:08 2024
Training on 25046 samples...
Train epoch: 13 [0/25046 (0%)]	Loss: 0.345975
Train epoch: 13 [325720/25046 (41%)]	Loss: 0.442911
Train epoch: 13 [647120/25046 (82%)]	Loss: 0.402446
Make prediction for 5010 samples...
0.46947837 No improvement since epoch  12 ; best_mse,best_ci: 0.46947837 0.8463846707669717 GINConvNet davis
Training epoch 14... Time: Sun Jun  9 16:42:23 2024
Training on 25046 samples...
Train epoch: 14 [0/25046 (0%)]	Loss: 0.400218
Train epoch: 14 [333160/25046 (41%)]	Loss: 0.380533
Train epoch: 14 [653800/25046 (82%)]	Loss: 0.535254
Make prediction for 5010 samples...
0.46947837 No improvement since epoch  12 ; best_mse,best_ci: 0.46947837 0.8463846707669717 GINConvNet davis
Training epoch 15... Time: Sun Jun  9 16:42:38 2024
Training on 25046 samples...
Train epoch: 15 [0/25046 (0%)]	Loss: 0.375697
Train epoch: 15 [331000/25046 (41%)]	Loss: 0.453652
Train epoch: 15 [651960/25046 (82%)]	Loss: 0.428994
Make prediction for 5010 samples...
rmse improved at epoch  15 ; best_mse,best_ci: 0.40929195 0.8253702886605927 GINConvNet davis
Training epoch 16... Time: Sun Jun  9 16:43:07 2024
Training on 25046 samples...
Train epoch: 16 [0/25046 (0%)]	Loss: 0.441565
Train epoch: 16 [331520/25046 (41%)]	Loss: 0.378459
Train epoch: 16 [653240/25046 (82%)]	Loss: 0.375084
Make prediction for 5010 samples...
0.40929195 No improvement since epoch  15 ; best_mse,best_ci: 0.40929195 0.8253702886605927 GINConvNet davis
Training epoch 17... Time: Sun Jun  9 16:43:23 2024
Training on 25046 samples...
Train epoch: 17 [0/25046 (0%)]	Loss: 0.419505
Train epoch: 17 [326040/25046 (41%)]	Loss: 0.392806
Train epoch: 17 [658200/25046 (82%)]	Loss: 0.426250
Make prediction for 5010 samples...
rmse improved at epoch  17 ; best_mse,best_ci: 0.37797835 0.8302788312553326 GINConvNet davis
Training epoch 18... Time: Sun Jun  9 16:43:53 2024
Training on 25046 samples...
Train epoch: 18 [0/25046 (0%)]	Loss: 0.412582
Train epoch: 18 [328720/25046 (41%)]	Loss: 0.416933
Train epoch: 18 [653880/25046 (82%)]	Loss: 0.429294
Make prediction for 5010 samples...
0.37797835 No improvement since epoch  17 ; best_mse,best_ci: 0.37797835 0.8302788312553326 GINConvNet davis
Training epoch 19... Time: Sun Jun  9 16:44:08 2024
Training on 25046 samples...
Train epoch: 19 [0/25046 (0%)]	Loss: 0.417467
Train epoch: 19 [323860/25046 (41%)]	Loss: 0.366274
Train epoch: 19 [650120/25046 (82%)]	Loss: 0.375054
Make prediction for 5010 samples...
0.37797835 No improvement since epoch  17 ; best_mse,best_ci: 0.37797835 0.8302788312553326 GINConvNet davis
Training epoch 20... Time: Sun Jun  9 16:44:23 2024
Training on 25046 samples...
Train epoch: 20 [0/25046 (0%)]	Loss: 0.411485
Train epoch: 20 [330480/25046 (41%)]	Loss: 0.354396
Train epoch: 20 [655240/25046 (82%)]	Loss: 0.405898
Make prediction for 5010 samples...
0.37797835 No improvement since epoch  17 ; best_mse,best_ci: 0.37797835 0.8302788312553326 GINConvNet davis
Training epoch 21... Time: Sun Jun  9 16:44:38 2024
Training on 25046 samples...
Train epoch: 21 [0/25046 (0%)]	Loss: 0.361084
Train epoch: 21 [331320/25046 (41%)]	Loss: 0.383649
Train epoch: 21 [650360/25046 (82%)]	Loss: 0.378841
Make prediction for 5010 samples...
0.37797835 No improvement since epoch  17 ; best_mse,best_ci: 0.37797835 0.8302788312553326 GINConvNet davis
Training epoch 22... Time: Sun Jun  9 16:44:53 2024
Training on 25046 samples...
Train epoch: 22 [0/25046 (0%)]	Loss: 0.386659
Train epoch: 22 [331020/25046 (41%)]	Loss: 0.484499
Train epoch: 22 [655680/25046 (82%)]	Loss: 0.348193
Make prediction for 5010 samples...
0.37797835 No improvement since epoch  17 ; best_mse,best_ci: 0.37797835 0.8302788312553326 GINConvNet davis
Training epoch 23... Time: Sun Jun  9 16:45:08 2024
Training on 25046 samples...
Train epoch: 23 [0/25046 (0%)]	Loss: 0.381658
Train epoch: 23 [328200/25046 (41%)]	Loss: 0.374788
Train epoch: 23 [655920/25046 (82%)]	Loss: 0.350818
Make prediction for 5010 samples...
0.37797835 No improvement since epoch  17 ; best_mse,best_ci: 0.37797835 0.8302788312553326 GINConvNet davis
Training epoch 24... Time: Sun Jun  9 16:45:24 2024
Training on 25046 samples...
Train epoch: 24 [0/25046 (0%)]	Loss: 0.376321
Train epoch: 24 [331280/25046 (41%)]	Loss: 0.296903
Train epoch: 24 [657200/25046 (82%)]	Loss: 0.331049
Make prediction for 5010 samples...
rmse improved at epoch  24 ; best_mse,best_ci: 0.35288385 0.8499452402681825 GINConvNet davis
Training epoch 25... Time: Sun Jun  9 16:45:54 2024
Training on 25046 samples...
Train epoch: 25 [0/25046 (0%)]	Loss: 0.356608
Train epoch: 25 [327500/25046 (41%)]	Loss: 0.334375
Train epoch: 25 [656200/25046 (82%)]	Loss: 0.311007
Make prediction for 5010 samples...
0.35288385 No improvement since epoch  24 ; best_mse,best_ci: 0.35288385 0.8499452402681825 GINConvNet davis
Training epoch 26... Time: Sun Jun  9 16:46:09 2024
Training on 25046 samples...
Train epoch: 26 [0/25046 (0%)]	Loss: 0.290633
Train epoch: 26 [328980/25046 (41%)]	Loss: 0.321593
Train epoch: 26 [656320/25046 (82%)]	Loss: 0.383553
Make prediction for 5010 samples...
0.35288385 No improvement since epoch  24 ; best_mse,best_ci: 0.35288385 0.8499452402681825 GINConvNet davis
Training epoch 27... Time: Sun Jun  9 16:46:24 2024
Training on 25046 samples...
Train epoch: 27 [0/25046 (0%)]	Loss: 0.342330
Train epoch: 27 [331600/25046 (41%)]	Loss: 0.383157
Train epoch: 27 [661920/25046 (82%)]	Loss: 0.321072
Make prediction for 5010 samples...
0.35288385 No improvement since epoch  24 ; best_mse,best_ci: 0.35288385 0.8499452402681825 GINConvNet davis
Training epoch 28... Time: Sun Jun  9 16:46:39 2024
Training on 25046 samples...
Train epoch: 28 [0/25046 (0%)]	Loss: 0.367145
Train epoch: 28 [326280/25046 (41%)]	Loss: 0.292104
Train epoch: 28 [654880/25046 (82%)]	Loss: 0.350105
Make prediction for 5010 samples...
0.35288385 No improvement since epoch  24 ; best_mse,best_ci: 0.35288385 0.8499452402681825 GINConvNet davis
Training epoch 29... Time: Sun Jun  9 16:46:54 2024
Training on 25046 samples...
Train epoch: 29 [0/25046 (0%)]	Loss: 0.294199
Train epoch: 29 [326060/25046 (41%)]	Loss: 0.351311
Train epoch: 29 [657840/25046 (82%)]	Loss: 0.310483
Make prediction for 5010 samples...
0.35288385 No improvement since epoch  24 ; best_mse,best_ci: 0.35288385 0.8499452402681825 GINConvNet davis
Training epoch 30... Time: Sun Jun  9 16:47:09 2024
Training on 25046 samples...
Train epoch: 30 [0/25046 (0%)]	Loss: 0.308299
